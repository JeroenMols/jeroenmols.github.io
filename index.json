[{"content":" ","date":"24 July 2023","externalUrl":null,"permalink":"/","section":"","summary":" ","title":"","type":"page"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/blog/","section":"Blogs","summary":"","title":"Blogs","type":"blog"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/tags/fullstack/","section":"Tags","summary":"","title":"Fullstack","type":"tags"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/tags/server/","section":"Tags","summary":"","title":"Server","type":"tags"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/tags/tips/","section":"Tags","summary":"","title":"Tips","type":"tags"},{"content":"Are you using a VPN on your mobile device? Do you need to disable that to access your development web server over MDNS on your mobile device? Well\u0026hellip; read on to simplify your workflow.\nProblem # While using a mobile VPN, you might get a DNS error when trying to access your computer over MDNS (.local domain).\nThis happens because the jmols.local domain isn\u0026rsquo;t an actual domain and hence the DNS server on the VPN cannot resolve it.\nSolution # A way to solve this is to use split tunneling, which allows to exclude certain apps from the VPN.\nIn my case, I decided to use two different browsers:\none for my normal use with VPN (Brave) one for development without VPN (Chrome) This allows me to access development URLs, whilst still securing all my personal internet usage.\nHowever, this falls apart when I send myself a development URL or when I scan a QR code that links to my development server. This is because Android will use your default browser to open URLs and for personal use that should be a VPN-protected one.\nFortunately, I\u0026rsquo;ve built a solution for that: an open-source app that intercepts all links to your local domain and redirects them to a browser of choice!\nHere\u0026rsquo;s how to get started:\nClone the URLInterceptor Github repository Fill in your development url Set the package name of your development browser Install the app and follow the instructions to start intercepting URLs. That\u0026rsquo;s it!\nThere is a little bit of setup involved. This is because Android for security reasons first has to verify deep links using a .well-known hosted file on your server. Since this would be tricky to do on a development server, I\u0026rsquo;ve opted to manually inform Android to trust our app to handle these links instead.\nWrap up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. Using my URL interceptor app you can combine the best of both worlds: access .local domains without VPN and have all your other traffic protected by a VPN.\nIf this was helpful to you, consider buying me a coffee.\n","date":"24 July 2023","externalUrl":null,"permalink":"/blog/2023/07/24/vpn-development/","section":"Blogs","summary":"Are you using a VPN on your mobile device? Do you need to disable that to access your development web server over MDNS on your mobile device?","title":"Using VPN during MDNS server development","type":"blog"},{"content":"","date":"24 July 2023","externalUrl":null,"permalink":"/tags/vpn/","section":"Tags","summary":"","title":"Vpn","type":"tags"},{"content":"","date":"26 June 2023","externalUrl":null,"permalink":"/tags/commit/","section":"Tags","summary":"","title":"Commit","type":"tags"},{"content":"","date":"26 June 2023","externalUrl":null,"permalink":"/tags/engineering/","section":"Tags","summary":"","title":"Engineering","type":"tags"},{"content":"As developers, we love to build cool things and ship them as fast as reasonably possible. And to get that done, here are a few things you can do to \u0026ldquo;game the system\u0026rdquo;.\nPull requests # Put yourself in the shoes of the reviewer, how would you like your pull requests (PR) to be served?\nI like mine:\nnice and small, so they\u0026rsquo;re less intimidating to review and hence will be reviewed faster with a great description, context about why it\u0026rsquo;s built this way, and considered alternatives help to understand and learn visual with a screenshot (before/after visual change) or a graph (conversion change) or table (comparison) already reviewed, comments by the author add extra context and helpful insights to review the code Doing all the above is extra work, but will speed up reviews, reduce rework and improve the feedback loop.\nSo be selfish and put in the extra work to craft stellar PRs!\nThis won\u0026rsquo;t just make you happier and more productive, but it will also increase your overall impact by helping to inform others and creating an excellent historical reference.\nCommits # Much of the above is also valid for commit messages:\nsmall commits are easier to review since changes are more correlated and have extra context (i.e. commit message) great commit messages add extra context and reasoning behind commit changes (optimize for Git bisect) However, at my current company, we squash all commits before merging.\nSo I\u0026rsquo;ve personally given up on my commit size and message hygiene and moved my efforts to the PR level instead.\nWrap up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. Sometimes it\u0026rsquo;s good to be a little selfish! Optimize your pull requests to be reviewed as quickly as possible and increase your overall impact and happiness.\nIf this was helpful to you, consider buying me a coffee.\n","date":"26 June 2023","externalUrl":null,"permalink":"/blog/2023/06/26/prs-and-commits/","section":"Blogs","summary":"As developers, we love to build cool things and ship them as fast as reasonably possible. And to get that done, here are a few things you can do to \u0026ldquo;game the system\u0026rdquo;.","title":"Gaming the pull request review system","type":"blog"},{"content":"","date":"26 June 2023","externalUrl":null,"permalink":"/tags/pullrequest/","section":"Tags","summary":"","title":"Pullrequest","type":"tags"},{"content":"","date":"9 June 2023","externalUrl":null,"permalink":"/tags/architecture/","section":"Tags","summary":"","title":"Architecture","type":"tags"},{"content":"","date":"9 June 2023","externalUrl":null,"permalink":"/tags/diagram/","section":"Tags","summary":"","title":"Diagram","type":"tags"},{"content":"","date":"9 June 2023","externalUrl":null,"permalink":"/tags/graphviz/","section":"Tags","summary":"","title":"Graphviz","type":"tags"},{"content":"","date":"9 June 2023","externalUrl":null,"permalink":"/tags/html/","section":"Tags","summary":"","title":"Html","type":"tags"},{"content":"Tired of building un-versionable, lifeless architecture diagrams? Wouldn\u0026rsquo;t it be great if you could add your diagram to Git, embed it in your documentation, and have clickable elements?\nWell, look no further! In this blog post, we will explore how to generate an interactive system architecture diagram using Graphviz and HTML. Get ready to bring your diagrams to life!\nCurious? # Can\u0026rsquo;t wait to see the result of what we\u0026rsquo;re going to build, get a sneak peak of the result here:\n👉 Interactive system architecture diagram.\nBuilding a Diagram with Graphviz # Graphviz is a powerful graph visualization tool that offers higher flexibility than alternatives like Mermaid. It allows us to export graphs to Scalable Vector Graphics (SVG) files, which are ideal for embedding in HTML documents. Additionally, Graphviz supports embedding URLs into the graph elements, enabling interactivity.\nTo start, you\u0026rsquo;ll need to install Graphviz on your system.\nbrew install graphviz Once installed, create a Graphviz file (with a .dot extension) that defines the architecture diagram. You can specify nodes, edges, and their properties using the DOT language.\nHere\u0026rsquo;s a brief example of a Graphviz file:\ndigraph architecture { FrontendApp BackendApp FrontendApp -\u0026gt; BackendApp } To export the DOT file to an SVG file, use the following command:\n$ dot -Tsvg diagram.dot -o diagram.svg Which will yield the following diagram:\nWhile this is a very simple example of a Graphviz diagram, it is possible to create more complex and better-looking ones.\nFor the sake of example, let\u0026rsquo;s take the diagram defined here and build an interactive version of that.\nHere are my pro tips for Graphviz to create the layout you want:\nHave the diagram lay itself out from left to right Add an invisible column on the left with elements that define your rows (use rank=same to lay out the linked nodes under each other) Link each alignment row to the element you want to appear first on that row Link elements on different rows with an edge that has a `[constraint=\u0026ldquo;false\u0026rdquo;] attribute Use invisible elements to add spacers or to force edges along a certain path By following the suggestions above you can essentially lay out architecture blocks on a grid.\nCreating an HTML File to Embed the Diagram # To include the generated SVG in an HTML page, you can use the following code:\n\u0026lt;img src=\u0026#34;diagram.svg\u0026#34; alt=\u0026#34;Architecture diagram\u0026#34; /\u0026gt; However, simply using an \u0026lt;img\u0026gt; tag to include the SVG won\u0026rsquo;t allow the hyperlinks to link to the hosting page. So unfortunately, we have to directly include the SVG code between the \u0026lt;svg\u0026gt; and \u0026lt;/svg\u0026gt; tags.\n\u0026lt;svg ...\u0026gt; \u0026lt;!-- SVG content goes here --\u0026gt; \u0026lt;/svg\u0026gt; A few changes need to be made before embedding the SVG code to ensure compatibility with HTML:\nRemove all comments from the SVG file (comments start with \u0026lt;!-- and end with --\u0026gt;). Remove the xmlns:xlink=\u0026quot;http://www.w3.org/1999/xlink\u0026quot; attribute from the root \u0026lt;svg\u0026gt; tag. Remove any xlink prefixes used throughout the SVG code. Next, let\u0026rsquo;s talk about building the HTML page that will contain the diagram.\nFor each architecture component, we want to link from, we will need to add a section with an anchor link. A way to do this is to add a \u0026lt;h2\u0026gt; tag with an id attribute.\nAs an example, the following section:\n\u0026lt;h2 id=\u0026#34;frontend-app\u0026#34;\u0026gt;Frontend App\u0026lt;/h2\u0026gt; Can be linked to from the diagram by adding the following URL (notice the added #):\ndigraph architecture { FrontendApp [URL=\u0026#34;#frontend-app\u0026#34;] BackendApp FrontendApp -\u0026gt; BackendApp } Bringing It All Together: The Final Example # Now that we know how to prepare the SVG and create the HTML file, let\u0026rsquo;s add sections and URLs for all diagram components. You can admire result here.\nPretty dope, isn\u0026rsquo;t it? 😎\nIn this example, we have manually written the HTML file, but you could also use Markdown and have the HTML generated for you. I\u0026rsquo;m pretty confident this will work with whatever documentation tool you are currently using!\nThe advantages are numerous:\ndiagram can be seamlessly added to your existing documentation pages interactivity allows users to navigate the system easily diagram is fully versionable under Git so you can keep track of changes and collaborate efficiently. Here\u0026rsquo;s the Github repository with the diagram source code.\nWrap up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. By leveraging Graphviz and directly embedding an SVG diagram in an HTML document, you can create visually appealing diagrams that are interactive.\nIf this was helpful to you, consider buying me a coffee.\n","date":"9 June 2023","externalUrl":null,"permalink":"/blog/2023/06/09/interactive-architecture-diagram/","section":"Blogs","summary":"Tired of building un-versionable, lifeless architecture diagrams? Wouldn\u0026rsquo;t it be great if you could add your diagram to Git, embed it in your documentation, and have clickable elements?","title":"Interactive versionable architecture diagrams","type":"blog"},{"content":"Planning an event can be stressful, and the last thing you need is worrying about your guests\u0026rsquo; privacy. But don\u0026rsquo;t worry, I\u0026rsquo;ve got you covered with a privacy-friendly RSVP option.\nOpportunity # There exist plenty of online services (like rsvpify) that offer a slick looking interface and a powerful dashboard to track who\u0026rsquo;s coming to your event.\nHowever, such online services require guests to provide personal information such as their name, email, phone number, and sometimes even their address.\nWhile they may be convenient for managing responses, they can also put your guests\u0026rsquo; privacy at risk or may even use their information for marketing purposes.\nInsight # But there is a better way: good plain old email.\nNo middleman Senders control when and if to send Email No fees Let\u0026rsquo;s create a simple HTML website that offers such a privacy-friendly RSVP option.\nFirst, create an HTML file with the following code:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Privacy-Friendly RSVP\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button onclick=\u0026#34;sendEmail()\u0026#34;\u0026gt;RSVP\u0026lt;/button\u0026gt; \u0026lt;script\u0026gt; function sendEmail() { window.location.href = \u0026#39;mailto:name.lastname+rsvp@gmail.com?subject=RSVP\u0026amp;body=I will be attending!\u0026#39;; } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; This code creates a basic HTML page with a single button. When the button is clicked, it will invoke a JavaScript function that directs the user to their email application and prefills the email receiver address, subject and body.\nNotice how we leverage the +rsvp suffix in a gmail address to allow to easily filter or label RSVP emails in your mailbox.\nOff course, you can customize this code to fit your specific event by changing the email address, subject, and body text.\nGuests decide what, when and whether to send. All without having to provide any personal information to a third-party service. It\u0026rsquo;s simple, easy, and most importantly, respectful of your guests\u0026rsquo; privacy.\nFull example # Let\u0026rsquo;s build a slightly more attractive looking RSVP page:\nThat looks on mobile like:\nThis can be achieved by starting from the following HTML:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body background=\u0026#34;background.jpg\u0026#34; style=\u0026#34; background-size: cover; background-position: center; display: flex; align-items: center; justify-content: center; \u0026#34; \u0026gt; \u0026lt;div style=\u0026#34; display: flex; flex-direction: column; align-items: center; justify-content: start; max-width: 800px; width: 90%; height: 90%; background-color: rgba(0, 0, 0, 0.2); border-radius: 20px; padding: 20px; \u0026#34; \u0026gt; \u0026lt;div style=\u0026#34;display: flex; flex-direction: column; align-items: center\u0026#34;\u0026gt; \u0026lt;h1 style=\u0026#34; color: white; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 8em; margin: 0px; \u0026#34; \u0026gt; Party \u0026lt;/h1\u0026gt; \u0026lt;h2 style=\u0026#34; color: white; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 2em; margin: -25 0 0 0; \u0026#34; \u0026gt; description \u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style=\u0026#34;flex-grow: 1\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div style=\u0026#34;display: flex; align-items: flex-start; flex-direction: column\u0026#34; \u0026gt; \u0026lt;p style=\u0026#34; color: white; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 1.5em; margin: 0px; padding: 0 20; \u0026#34; \u0026gt; Come celebrate with me \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34; color: white; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 1.5em; margin: 0px; padding: 0 20; \u0026#34; \u0026gt; 🗓️ date + hour \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34; color: white; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 1.5em; margin: 0 0 20 0; padding: 0 20; \u0026#34; \u0026gt; 🍻 and 🍟 to enjoy \u0026lt;/p\u0026gt; \u0026lt;iframe src=\u0026#34;https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2246.3233326624286!2d9.124615916552427!3d55.73551088054884!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x464b717428bfa99b%3A0xfba38e2c20ba313a!2sLEGOLAND%C2%AE%20Billund%20Resort!5e0!3m2!1sen!2sbe!4v1680002007769!5m2!1sen!2sbe\u0026#34; width=\u0026#34;100%\u0026#34; height=\u0026#34;150\u0026#34; style=\u0026#34;border: 0\u0026#34; allowfullscreen=\u0026#34;\u0026#34; loading=\u0026#34;lazy\u0026#34; referrerpolicy=\u0026#34;no-referrer-when-downgrade\u0026#34; \u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;button style=\u0026#34; padding: 8 30; font-family: \u0026#39;Courier New\u0026#39;, Courier, monospace; font-size: 1.5em; margin-top: 20; background: white; border: white; align-self: center; \u0026#34; id=\u0026#34;btn-rsvp\u0026#34; \u0026gt; RSVP? \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; document .getElementById(\u0026#39;btn-rsvp\u0026#39;) .addEventListener(\u0026#39;click\u0026#39;, function () { var link = \u0026#39;mailto:name.lastname+rsvp@gmail.com\u0026#39; + \u0026#39;?subject=\u0026#39; + encodeURIComponent(\u0026#39;RSVP - My party\u0026#39;) + \u0026#39;\u0026amp;body=\u0026#39; + encodeURIComponent(\u0026#39;We will be there!\u0026#39;); window.location.href = link; }); \u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Just save the code above in index.html and add a background.jpg to the same folder to set your desired background.\nParty on! 🎉\nWrap up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. You don\u0026rsquo;t have to sacrifice privacy for convenience when it comes to event planning. A simple HTML website with a button to send an email is a privacy-friendly RSVP alternative!\nIf this was helpful to you, consider buying me a coffee.\n","date":"28 March 2023","externalUrl":null,"permalink":"/blog/2023/03/28/privacy-friendly-rsvp/","section":"Blogs","summary":"Planning an event can be stressful, and the last thing you need is worrying about your guests\u0026rsquo; privacy. But don\u0026rsquo;t worry, I\u0026rsquo;ve got you covered with a privacy-friendly RSVP option.","title":"A privacy friendly RSVP for events","type":"blog"},{"content":"","date":"28 March 2023","externalUrl":null,"permalink":"/tags/javascript/","section":"Tags","summary":"","title":"Javascript","type":"tags"},{"content":"","date":"28 March 2023","externalUrl":null,"permalink":"/tags/privacy/","section":"Tags","summary":"","title":"Privacy","type":"tags"},{"content":"","date":"28 March 2023","externalUrl":null,"permalink":"/tags/rsvp/","section":"Tags","summary":"","title":"Rsvp","type":"tags"},{"content":"","date":"6 February 2023","externalUrl":null,"permalink":"/tags/ssh/","section":"Tags","summary":"","title":"Ssh","type":"tags"},{"content":"","date":"6 February 2023","externalUrl":null,"permalink":"/tags/terminal/","section":"Tags","summary":"","title":"Terminal","type":"tags"},{"content":"Looking to configure multiple SSH keys on the same computer? For instance to use a different SSH key for your public and enterprise Github contributions.\nThis quick little post will show you how to do that.\nSteps # In this I\u0026rsquo;m assuming you already have an SSH key setup for your enterprise Github account.\nCreate a new SSH key and add it to the ssh-agent Update your ~/.ssh/config file and add a new host: Host * AddKeysToAgent yes UseKeychain yes Host github.com IdentityFile ~/.ssh/id_github_rsa UseKeychain yes Host github.mycompany.com IdentityFile ~/.ssh/id_rsa UseKeychain yes I\u0026rsquo;m explicitly defining each host, but you could also assign a SSH key to all remaining hosts using Host *.\nThat\u0026rsquo;s it!\nThis site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. If this was helpful to you, consider buying me a coffee.\n","date":"6 February 2023","externalUrl":null,"permalink":"/blog/2023/02/06/multiple-ssh-keys/","section":"Blogs","summary":"Looking to configure multiple SSH keys on the same computer? For instance to use a different SSH key for your public and enterprise Github contributions.","title":"Using multiple SSH keys for Github and Github enterprise","type":"blog"},{"content":"These past years I\u0026rsquo;ve grown to be more privacy-aware. And while this post isn\u0026rsquo;t about how I\u0026rsquo;m increasing my personal privacy, I\u0026rsquo;d like to talk about how I\u0026rsquo;m increasing yours.\nMy website had three services integrated:\nGoogle Analytics gave me insights into how much people read my content and what topics were popular to write about. Google Adsense showed ads underneath every blog post and enabled me to monetize my content. With this I received two payments (70.84 euro in 2019 and 74.20 euro in 2020), covering the expenses for my domain name for about 14 years. Disqus comments allowed people to comment on my content, but since I didn\u0026rsquo;t pay for the service Disqus was also serving advertisements. And while these services were adding some value to my website, they were doing so at the cost of your privacy. By default (!!!), they not only track your interaction with my website, but also detailed information about you (gender, age, approximate location,\u0026hellip;) and they even track you across different websites.\nBut should I really be collecting all that data about you?\nShould I really hand off all that data to those services?\nHave I ever asked your consent about any of this?\nWell, I no longer believe it is \u0026ldquo;normal\u0026rdquo; for websites or products to engage in these practices. That every experience needs to be personalized. Or that we should give away our privacy so easily.\nTherefore I\u0026rsquo;ve decided to strip all such services. Now my website is a safe space where you can enjoy (hopefully) my content without worrying about advertisements or tracker blockers.\nHowever, I do still care about your opinion!\nSo moving forward you can:\nLet me know you\u0026rsquo;ve read this by liking one of my social posts Talk about my content on Reddit or Hacker News Send me feedback/questions on Mastodon You\u0026rsquo;re in full control whether you decide to reach out or not!\nI\u0026rsquo;ll keep doing my best to provide you with interesting content (which is a ton of work) and hence appreciate every single like or shoutout.\nWrap-up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. My website is now fully tracker and advertisement free, I\u0026rsquo;ll do my best to guarantee your privacy moving forward.\nIf this was helpful to you, please let me know on Mastodon!\n","date":"29 January 2023","externalUrl":null,"permalink":"/blog/2023/01/29/remove-trackers/","section":"Blogs","summary":"These past years I\u0026rsquo;ve grown to be more privacy-aware. And while this post isn\u0026rsquo;t about how I\u0026rsquo;m increasing my personal privacy, I\u0026rsquo;d like to talk about how I\u0026rsquo;m increasing yours.","title":"Removing all trackers from my website","type":"blog"},{"content":"","date":"29 January 2023","externalUrl":null,"permalink":"/tags/trackers/","section":"Tags","summary":"","title":"Trackers","type":"tags"},{"content":"","date":"29 January 2023","externalUrl":null,"permalink":"/tags/website/","section":"Tags","summary":"","title":"Website","type":"tags"},{"content":"","date":"25 January 2023","externalUrl":null,"permalink":"/tags/adb/","section":"Tags","summary":"","title":"Adb","type":"tags"},{"content":"","date":"25 January 2023","externalUrl":null,"permalink":"/tags/android/","section":"Tags","summary":"","title":"Android","type":"tags"},{"content":"How can you connect your app on an Android emulator to a development server running on the localhost of your computer?\nThe problem # Since Android emulators create their own virtual network, they cannot access devices on your local network.\nThis means:\nlocalhost refers to the emulator, not your laptop local MDNS addresses jmols.local are not accessible So accessing our development server at https://jmols.local:3000 results in the following error:\nMethod 1: use your computers IP address # Huge thanks to Eduard-Cristian Boloș for suggesting this solution.\nSince Android emulators can access IP addresses on your network, you can directly point to the IP address of your computer.\nInstead of loading https://jmols.local:3000, you can load https://\u0026lt;YOUR_COMPUTER_IP\u0026gt;:3000 (e.g. https://192.168.1.123).\nThis works on both emulators and Android phones!\nHowever you may have to update the IP after connecting to a different network or when your IP lease expires.\nMethod 2: the loopback address # Another approach is to change the server URL in your app and point it to 10.0.2.2. This is a special alias to your host loopback interface (127.0.0.1 on your development machine).\nSo instead of loading https://jmols.local:3000, our app will load https://10.0.2.2:3000 instead.\nThat fixes the emulator, but now our app no longer works on real devices. (since the loopback IP doesn\u0026rsquo;t exist there).\nCan we find a single solution that works on both emulators and devices?\nMethod 3: redirect the emulator # In this solution, we\u0026rsquo;ll instruct the emulator to redirect the IP address from the host machine to the loopback IP address automatically. We\u0026rsquo;ll do this by editing the etc/hosts file on the Android emulator.\nFirst, we need to ensure the etc/hosts file is writable:\nCreate a new emulator (non Google Play services, so we have access to root) Find the emulator AVD name of the emulator emulator -list-avds Start your emulator from the command line with the option to enable a writable system emulator -avd \u0026#34;\u0026lt;AVD_NAME_HERE\u0026gt;\u0026#34; -writable-system Run ADB as root adb root Disable verified boot adb disable-verity Reboot the device adb reboot Wait for the device to be rebooted (ready when adb shell works) Run ADB as root (again) adb root Remount partitions as read-write adb remount Now we can overwrite the etc/hosts file!\nFirst get the existing hosts file adb pull etc/hosts Add an entry to direct your local server domain to the loopback address: 10.0.2.2 \u0026lt;YOUR_LOCAL_HOSTNAME\u0026gt;. Your hostfile should look like this: 127.0.0.1 localhost ::1 ip6-localhost 10.0.2.2 jmols.local Save and push the file back to the emulator: adb push hosts etc/hosts Now our emulator can access our development server at https://jmols.local:3000!\nNotice how this solution can easily be generalized to any IP address on your local network.\nBonus: ADB reverse # Huge thanks to Jeff Lewis for suggesting this solution.\nReact native uses ADB reverse to bind an emulator port to a port on your computer.\nadb reverse tcp:3000 tcp:3000 Similarly to the loopback address, this solution isn\u0026rsquo;t suitable for a physical device.\nWrap-up # This site is 100% tracker free, \u0026#x2764;\u0026#xfe0f; for liking my post on Mastodon or Linkedin to let me know you\u0026rsquo;ve read this. Depending on your situation, there are several ways to connect an emulator to a local server. A universal - though complicated way - is to make etc/hosts writable so you can access your development server using your local MDNS name.\nIf this was helpful to you, please let me know on Mastodon!\n","date":"25 January 2023","externalUrl":null,"permalink":"/blog/2023/01/25/development-server-emulator/","section":"Blogs","summary":"How can you connect your app on an Android emulator to a development server running on the localhost of your computer?\nThe problem # Since Android emulators create their own virtual network, they cannot access devices on your local network.","title":"Android emulator access to local server","type":"blog"},{"content":"","date":"25 January 2023","externalUrl":null,"permalink":"/tags/emulator/","section":"Tags","summary":"","title":"Emulator","type":"tags"},{"content":"","date":"25 January 2023","externalUrl":null,"permalink":"/tags/localhost/","section":"Tags","summary":"","title":"Localhost","type":"tags"},{"content":"","date":"17 December 2022","externalUrl":null,"permalink":"/tags/backup/","section":"Tags","summary":"","title":"Backup","type":"tags"},{"content":"","date":"17 December 2022","externalUrl":null,"permalink":"/tags/files/","section":"Tags","summary":"","title":"Files","type":"tags"},{"content":"Trying to get a large number of files from your Android phone, but Android File Transfer freezing up?\nHere\u0026rsquo;s what I learned trying to pull ~170 Gb from my Pixel phone.\nPulling files from your phone # For this to work you need to have ADB installed on your computer and developer options enabled on your Android phone.\nFirst, check how large the directory you\u0026rsquo;re trying to pull is. Let\u0026rsquo;s assume we want to pull the Camera folder:\nadb shell du -sh sdcard/DCIM # Output: 171.8G\tsdcard/DCIM Don\u0026rsquo;t forget to run exit to leave the ADB shell.\nIf you have enough disk space, you can pull the entire folder to your computer using adb pull.\nadb pull -p sdcard/DCIM/ . Notice the -p option to show transfer progress\nUnfortunately, I didn\u0026rsquo;t have enough disk space\u0026hellip; So instead, let\u0026rsquo;s pull the files in batches, by using find to search for files.\nFor instance to find all video files:\nadb shell find `sdcard/DCIM/Camera/*.mp4` The result of find can then be piped into adb pull to transfer the files one by one to your computer.\nSome possibly handy variants are:\n# Pull all video files adb shell find \u0026#39;sdcard/DCIM/Camera/*.mp4\u0026#39; | xargs -n1 adb pull # Pull all image files adb shell find \u0026#39;sdcard/DCIM/Camera/*.jpg\u0026#39; | xargs -n1 adb pull # Pull al files from the past year adb shell find \u0026#39;sdcard/DCIM/Camera/PXL_2022*\u0026#39; # Pull all files from the past month adb shell find \u0026#39;sdcard/DCIM/Camera/PXL_202212*\u0026#39; Deleting pulled files # Now that the files are pulled from your phone, you probably also want to delete them to free up phone storage.\nThe easiest way to do so is to delete the entire folder from your phone:\n# Caution: this permanently deletes all your files! adb shell rm \u0026lt;folder-name-here\u0026gt; However, if you hadn\u0026rsquo;t pulled all files from that folder yet, you will include data loss.\nSo instead of deleting the folder, we\u0026rsquo;ll only delete the files that we just synced to our computer.\nFirst list all of the files in the synced folder on your computer using find:\nfind . -name \u0026#39;*\u0026#39; However, you can also be more granular here if you want:\n# List all images find . -name \u0026#39;*.jpg\u0026#39; Next, for each listed file, reconstruct the original file path on your phone using sed:\nfind . -name \u0026#39;*\u0026#39; | sed \u0026#39;s:.:sdcard/DCIM/Camera:\u0026#39; And finally, delete those files from your phone by piping the result into adb shell rm:\nfind . -name \u0026#39;*\u0026#39; | sed \u0026#39;s:.:sdcard/DCIM/Camera:\u0026#39; | xargs -n1 adb shell rm $1 Note I highly recommend doing a dry run first to check what files will be deleted by using adb shell ls -l:\nfind . -name \u0026#39;*\u0026#39; | sed \u0026#39;s:.:sdcard/DCIM/Camera:\u0026#39; | xargs -n1 adb shell ls -l $1 Finally, some possibly handy variants are:\n# Delete all video files from the current folder from your phone find . -name \u0026#39;*.mp4\u0026#39; | sed \u0026#39;s:.:sdcard/DCIM/Camera:\u0026#39; | xargs -n1 adb shell rm $1 # Delete all image files from the current folder from your phone find . -name \u0026#39;*.jpg\u0026#39; | sed \u0026#39;s:.:sdcard/DCIM/Camera:\u0026#39; | xargs -n1 adb shell rm $1 Wrap-up # Android file transfer unfortunately isn\u0026rsquo;t the most reliable solution to transfer files from your phone to your computer. However, thanks to adb there is a fast and reliable way to get (a subset of) files from your Android device.\nIf this was helpful to you, consider buying me a coffee or thanking me on Mastodon or Twitter!\n","date":"17 December 2022","externalUrl":null,"permalink":"/blog/2022/12/17/pull-files-android/","section":"Blogs","summary":"Trying to get a large number of files from your Android phone, but Android File Transfer freezing up?\nHere\u0026rsquo;s what I learned trying to pull ~170 Gb from my Pixel phone.","title":"Transfer many large files from Android","type":"blog"},{"content":"","date":"26 November 2022","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"Github","type":"tags"},{"content":"","date":"26 November 2022","externalUrl":null,"permalink":"/tags/mastodon/","section":"Tags","summary":"","title":"Mastodon","type":"tags"},{"content":"Looking to get a fancy verified checkmark on Mastodon for your Github account?\nThis post details how I made this work.\nSteps # Before I get started, huge thanks to Simon Wilson for inspiring me with the original idea.\nIn his excellent post Simon details how to leverage the your-username.github.io static webpage to prove Github domain ownership.\nThe idea is that proving I own jeroenmols.github.io is equivalent to proving ownership of github.com/jeroenmols.\nHowever, I can\u0026rsquo;t simply redirect jeroenmols.github.io to my Github profile as I already host my my personal website on that domain. (I use a CNAME record to make both domains equivalent).\nConsequently, Simon\u0026rsquo;s approach didn\u0026rsquo;t work for me. Now what?\nWell instead of redirecting the entire domain, I decided to redirect a sub-page. To do this, I:\nAdded a new page https://jeroenmols.com/github Included the Mastodon verification tag: \u0026lt;link href=\u0026quot;https://androiddev.social/@jeroenmols\u0026quot; rel=\u0026quot;me\u0026quot;\u0026gt; Have the page redirect to my Github profile Use the domain jeroenmols.github.io/github on my Mastodon profile The webpage content looks like this:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Redirecting to github.com/jeroenmols /\u0026lt;/title\u0026gt; \u0026lt;meta http-equiv=\u0026#34;refresh\u0026#34; content=\u0026#34;0; URL=https://github.com/jeroenmols\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://github.com/jeroenmols\u0026#34; rel=\u0026#34;me\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://jeroenmols.com\u0026#34; rel=\u0026#34;me\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://androiddev.social/@jeroenmols\u0026#34; rel=\u0026#34;me\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body /\u0026gt; \u0026lt;/html\u0026gt; And my Mastodon profile, now looks like this:\nThat\u0026rsquo;s it!\nIf this was helpful to you, consider buying me a coffee or thanking me on Mastodon or Twitter!\n","date":"26 November 2022","externalUrl":null,"permalink":"/blog/2022/11/26/mastodon-verify-github/","section":"Blogs","summary":"Looking to get a fancy verified checkmark on Mastodon for your Github account?\nThis post details how I made this work.\nSteps # Before I get started, huge thanks to Simon Wilson for inspiring me with the original idea.","title":"Verify Github profile link on Mastodon","type":"blog"},{"content":"","date":"19 November 2022","externalUrl":null,"permalink":"/tags/offline/","section":"Tags","summary":"","title":"Offline","type":"tags"},{"content":"","date":"19 November 2022","externalUrl":null,"permalink":"/tags/react/","section":"Tags","summary":"","title":"React","type":"tags"},{"content":"Traveling by train or plane and want to test your react app on your mobile phone? This quick post explains how to access your react development server from your phone without a Wi-Fi connection.\nSteps # Connect your phone to your laptop using a USB cable Enable USB tethering Android: System settings \u0026gt; Network \u0026amp; internet \u0026gt; Hotspot \u0026amp; tethering \u0026gt; USB tethering Start your react server on your laptop npm start Open your servers ip:port on your phone That\u0026rsquo;s it!\nIf this was helpful to you, consider buying me a coffee or thanking me on Mastodon or Twitter!\n","date":"19 November 2022","externalUrl":null,"permalink":"/blog/2022/11/19/react-local-development/","section":"Blogs","summary":"Traveling by train or plane and want to test your react app on your mobile phone? This quick post explains how to access your react development server from your phone without a Wi-Fi connection.","title":"Test React app on mobile without Wi-Fi","type":"blog"},{"content":"","date":"27 April 2022","externalUrl":null,"permalink":"/tags/crash/","section":"Tags","summary":"","title":"Crash","type":"tags"},{"content":"WorkManager is great to schedule background work on Android. However, since scheduled work lives outside of the app lifecycle, you might run into unexpected crashes.\nRead on to learn why and how to prevent this.\nHow to crash WorkManager # Reading the documentation, it is clear that WorkManager is a worry-free solution to background work:\nWorkManager is the recommended solution for persistent work. Work is persistent when it remains scheduled through app restarts and system reboots.\nThat\u0026rsquo;s very neat!\nSo if we schedule some work, for instance upload a crash:\nval workerClass = CrashUploadWorker::class.java WorkManager.getInstance(application) .enqueue(OneTimeWorkRequest.Builder(workerClass).build()) We can be sure that WorkManager will handle it for us, even when the app closes it self immediately after the crash.\nHowever, WorkManager assumes that the Worker class will always exist in our application. So if we ship a new version of our application that either:\nremoves the CrashUploadWorker renames the CrashUploadWorker to CrashReportWorker moves the CrashUploadWorker to a new package We might get a ClassNotFoundException crash after installing the update!\njava.lang.Error: java.lang.ClassNotFoundException: com.example.CrashUploadWorker at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1119) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588) at java.lang.Thread.run(Thread.java:818) This happens, because WorkManager lives in a separate process (Google Play Services) and will always try to complete its work. It will try to instantiate CrashUploadWorker, but that no longer exists in our application.\nUnfortunately I had to learn this the hard way.\nNotice the usage of \u0026ldquo;might\u0026rdquo;: a crash isn\u0026rsquo;t guaranteed and will only happen if there was unfinished work pending while the app got updated.\nHow not to crash WorkManager # The first thing you can try is to cancel all pending work for the Worker you removed/renamed:\nworkManager.cancelAllWorkByTag(\u0026#34;crash_upload\u0026#34;) This approach can be subject to race conditions as Workmanager might still retry to execute the scheduled work before you had the chance to cancel. (depending on where you call this)\nAnother downside of this approach is that this will drop scheduled work, causing data loss. Depending on your unique use case that may or may not be acceptable.\nAn alternative approach is to keep the original CrashUploadWorker class and modify that to handle the changing requirements:\ndrop the work (empty implementation) migrate and schedule the new worker class internal class CrashUploadWorker( appContext: Context, workerParams: WorkerParameters ) : CoroutineWorker(appContext, workerParams) { override suspend fun doWork(): Result { // Schedule new worker class val workerClass = CrashReportWorker::class.java WorkManager.getInstance(appContext) .enqueue(OneTimeWorkRequest.Builder(workerClass).build()) return Result.success() } } Once you stop scheduling work using the old Worker, you can mark it to be removed after all your customers have updated and migrated.\nFinally, here\u0026rsquo;s what a migration plan could look like:\nRelease 1: Add new worker and migrate all work Release 5: Cancel all remaining work using old Worker (causes data loss!) Release 10: Remove old Worker (causes crashes!) Using WorkerFactory # An alternative approach is to provide a custom WorkerFactory to handle the migration to the new class.\nThanks to Pietro Maggi and Steffan Davies for suggesting this approach\nTo do so, first disable automatic WorkManager initialization:\n\u0026lt;provider android:name=\u0026#34;androidx.startup.InitializationProvider\u0026#34; android:authorities=\u0026#34;${applicationId}.androidx-startup\u0026#34; android:exported=\u0026#34;false\u0026#34; tools:node=\u0026#34;merge\u0026#34;\u0026gt; \u0026lt;!-- If you are using androidx.startup to initialize other components --\u0026gt; \u0026lt;meta-data android:name=\u0026#34;androidx.work.WorkManagerInitializer\u0026#34; android:value=\u0026#34;androidx.startup\u0026#34; tools:node=\u0026#34;remove\u0026#34; /\u0026gt; \u0026lt;/provider\u0026gt; Then initialize the WorkManager in your Application#onCreate or ContentProvider:\nval configuration = Configuration.Builder() .setWorkerFactory(MigrateWorkerFactory()) .build() WorkManager.initialize(appContext, configuration) And create your own WorkerFactory that schedules the new worker:\nclass MigrateWorkerFactory() : WorkerFactory() { override fun createWorker( appContext: Context, workerClassName: String, workerParameters: WorkerParameters ): ListenableWorker? { if (workerClassName = \u0026#34;com.example.CrashUploadWorker\u0026#34;) { return CrashReportWorker(appContext, workerParameters) } ... } } This has the upside of not needing to keep the old Worker class around, but comes with some extra complexity of manual WorkManager initialization.\nWrap-up # WorkManager is a very handy tool to handle background work, but be careful with removing or renaming Workers.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"27 April 2022","externalUrl":null,"permalink":"/blog/2022/04/27/workmanager-crash/","section":"Blogs","summary":"WorkManager is great to schedule background work on Android. However, since scheduled work lives outside of the app lifecycle, you might run into unexpected crashes.","title":"The curious case of crashing Workers","type":"blog"},{"content":"","date":"27 April 2022","externalUrl":null,"permalink":"/tags/workmanager/","section":"Tags","summary":"","title":"Workmanager","type":"tags"},{"content":"","date":"23 February 2022","externalUrl":null,"permalink":"/tags/code-review/","section":"Tags","summary":"","title":"Code Review","type":"tags"},{"content":"In the past years, my thoughts on pull request reviews have evolved considerably. Given that creating and reviewing pull requests are a core part of our work, let\u0026rsquo;s talk about those.\nThis post will detail when to craft a pull request and what pull requests require a code review.\nWhen to craft a pull request # Always.\nStarting with the easiest part: every code change requires a pull request. This is mainly for two reasons:\nCode quality Provide additional context 1. Code quality # Your team likely wants to establish a common baseline of quality.\nFor this most teams use a set of automated checks that are executed on every pull request. These can verify that the code builds, tests pass, test coverage does not decrease, app size is within certain limits, …\nHowever, some checks can also be manual, such as a checklist on the pull request template. These nudge developers to avoid unrelated changes, do a self-review, add clear descriptions, steps to test the changes, \u0026hellip;\n2. Provide additional context # Writing a pull request is a useful form of documentation. It allows additional context to code changes such as why the changes are required and what alternatives were considered.\nFor bugs, you can elaborate on the steps to reproduce, a stack trace of the issue, and what steps others can follow to verify the proposed solution. Adding before/after screenshots can be incredibly helpful in reviewing UI changes.\nFinally, draft pull requests can be a tool to compare alternatives or an effective way to convey your design ideas to others.\nWhen your pull request requires a review # For all significant, non-critical code changes.\nWhile you might have expected an always here, I can at least think of two scenarios where pull request reviews might be skipped:\nTrivial code High urgency changes 1. Trivial code # Some code changes are straightforward, such as bumping the app version. Would you want to hold off your release until a team member finds the time to review the following?\ndefaultConfig { - versionName \u0026#34;1.3.0\u0026#34; + versionName \u0026#34;1.3.1\u0026#34; ... } But why stop there?\nHow about committing the output of automatic scripts? Examples are adding new translations, updating the Protobuf definitions, or tweaking assets.\nFar too often have I had to disrupt a colleague\u0026rsquo;s \u0026ldquo;flow\u0026rdquo; for a \u0026ldquo;quick stamp\u0026rdquo; on a particular pull request. Whereas in reality, our default automated checks would have been sufficient.\n2. High urgency changes # What if, despite all processes, main is suddenly broken?\nA common scenario for me is that end-to-end tests suddenly start failing. Either due to a backend change or due to a change on Firebase tests lab. In this case, main will still compile, but the builds for all open pull requests would fail.\nAn even worse situation is when two incompatible changes are merged, breaking main compilation as a result. That is even more impactful as it also breaks compilation for all developers starting from or rebasing onto the latest main.\nGiven such an impact, should you wait for approval before merging the fix?\nLet\u0026rsquo;s think about the worst-case scenario:\nmain breaks someone on the team implements a very hacky fix person opens pull request (mandatory!) all automated checks pass merge the fix into main and builds turn green Now there\u0026rsquo;s a very hacky fix in main, but builds are green. Did that fix improve the situation? Yes. Should that fix stay in main forever? Of course not.\nWe need to accept that software is never finished, and it will always continue to evolve. So after the quick patch, other team members can chime in, offer suggestions and follow up with another pull request containing a more sustainable solution.\nCompounding factors # In some situations, requiring reviews can be especially frustrating:\nremote work: unable to tap a colleague on her shoulder for a quick review asynchronous work: my colleagues are 9 (!) time zones apart from me foundational tasks: e.g. update protobufs, so you can build your new feature on top Interesting idea, but it won’t work at our scale # That might be true, I haven’t tested this out on a 100+ people project. And given that my proposal relies more on developer trust, I could see some scaling challenges.\nHowever, I would question whether your scale challenges are unique.\nDon’t all processes run into scaling issues as teams grow? Can\u0026rsquo;t we just apply our usual solutions?\nFew ideas:\nTools can determine whether a PR needs a review based on predefined requirements Tools can enforce providing a rationale when a PR is merged without review. This can even be broadcasted (Slack) to all team members Some trivial changes could be fully automated: e.g. continuously integrating new translations or assets Code ownership can restrict who can skip reviews for certain parts of the code base,\u0026hellip; \u0026hellip; Regardless of my suggestions, removing frustrations from your development process is one of the most impactful things you can do.\nWrap-up # All code changes require a pull request before they are merged. Code reviews are encouraged, but they can be skipped for trivial or highly urgent changes.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"23 February 2022","externalUrl":null,"permalink":"/blog/2022/02/23/pull-request-reviews/","section":"Blogs","summary":"In the past years, my thoughts on pull request reviews have evolved considerably. Given that creating and reviewing pull requests are a core part of our work, let\u0026rsquo;s talk about those.","title":"No, your pull request does not need a review","type":"blog"},{"content":"","date":"23 February 2022","externalUrl":null,"permalink":"/tags/process/","section":"Tags","summary":"","title":"Process","type":"tags"},{"content":"","date":"23 February 2022","externalUrl":null,"permalink":"/tags/pull-request/","section":"Tags","summary":"","title":"Pull Request","type":"tags"},{"content":"","date":"23 February 2022","externalUrl":null,"permalink":"/tags/team/","section":"Tags","summary":"","title":"Team","type":"tags"},{"content":"","date":"24 March 2021","externalUrl":null,"permalink":"/tags/jcenter/","section":"Tags","summary":"","title":"Jcenter","type":"tags"},{"content":"","date":"24 March 2021","externalUrl":null,"permalink":"/tags/maven/","section":"Tags","summary":"","title":"Maven","type":"tags"},{"content":"","date":"24 March 2021","externalUrl":null,"permalink":"/tags/mavencentral/","section":"Tags","summary":"","title":"MavenCentral","type":"tags"},{"content":"","date":"24 March 2021","externalUrl":null,"permalink":"/tags/migrate/","section":"Tags","summary":"","title":"Migrate","type":"tags"},{"content":"With JCenter shutting down, many are migrating to Maven Central. And while there are many posts on how to publish new artifacts, also all existing artifacts should be migrated away from JCenter.\nThis post will cover all steps required to migrate artifacts from JCenter to Maven Central. It will present a script to automatically perform such a migration so that it can be run on a CI and have the secrets injected.\nRequired before you start # To migrate an existing project to Maven Central involves two steps:\nUpdate (Gradle) scripts to publish to Maven Central Migrate all existing artifacts from JCenter to Maven Central This post will only cover the second step and hence assumes that the reader has a Sonatype account and GPG key available.\nIf you don\u0026rsquo;t have these yet, have a look at this great post by Márton Braun. It will also explain the required steps to make artifacts available after uploading on the Sonatype backend.\nMigration steps # These are the steps to migrate from JCenter to Maven Central:\nEnumerate all versions to migrate Configure GNU PG with a signing key Setup credentials to upload to Maven Central For each existing version: Download the artifact from JCenter Add all missing info to pom.xml Sign and upload the artifact to Maven Central If you\u0026rsquo;re impatient, feel free to jump ahead to the full script below.\nThough I encourage you to have a look at specific sections as your signing key may be in a different format, sections may be missing from your pom.xml,\u0026hellip;\n1. Enumerate all versions to migrate # To get all previously published versions from JCenter, navigate to the following url:\nhttps://dl.bintray.com/\u0026lt;bintray-org\u0026gt;/\u0026lt;bintray-repo\u0026gt;/\u0026lt;group-id-slash-separated\u0026gt;/\u0026lt;artifact-id\u0026gt;\nFor the Plaid Link Android SDK located:\n\u0026lt;bintray-org\u0026gt;: plaid - first part of url \u0026lt;bintray-repo\u0026gt;: link-android - second part of url \u0026lt;group-id-slash-separated\u0026gt;: com.plaid.link - group id with . replaced by / \u0026lt;artifact-id\u0026gt;: sdk-core - artifact id Resulting in the following url:\nBINTRAYURL=https://dl.bintray.com/plaid/link-android/com/plaid/link/sdk-core From this, all versions can be copy-pasted in plain text and converted into a space-separated array. Either using a text editor or command line (OSX only):\npbpaste | tr \u0026#39;/\u0026#39; \u0026#39; \u0026#39; | tr -d \u0026#39;\\n\u0026#39; Now the versions can be used as an input variable for the script:\nVERSIONS=(0.1.0 0.1.1 0.1.2 0.1.3 0.1.4 0.1.5 0.2.0 0.2.1 0.2.2 \\ 0.3.0 0.3.1 0.3.2 0.3.3 0.3.4 0.3.5 0.3.6 1.0.0 1.0.1 \\ 1.0.2 1.0.3 1.1.0 1.2.0 1.2.1 1.3.0 1.3.1 1.4.0 1.4.1 \\ 2.0.0 2.0.0-rc1 2.0.0-rc2 2.0.0-rc3 2.1.0 2.1.1 2.1.2 \\ 2.2.0 3.0.0 3.0.1 3.1.0 3.1.1 3.2.0 3.2.0-rc1 3.2.0-rc2 \\ 3.2.1 3.2.2 3.2.3 3.2.4) Finally, keep this URL somewhere as we\u0026rsquo;ll need it later on to download all artifacts.\n2. Configure GNU PG with a signing key # To sign the artifacts, we\u0026rsquo;ll use GNU PG.\nFirst, ensure GNU GPG is installed:\nOSX: $ brew install gnupg Docker: $ RUN apk add gnupg Now your private key can be imported by:\ngpg --import private.key Or if you\u0026rsquo;ll be running the script on your CI environment, you may want to inject a base64 encoded version of the private key:\n# Export base64 key gpg --export-secret-key --armor | base64 # Import base64 key echo $BASE64_SIGNING_KEY | base64 -d | gpg --import 3. Setup credentials for Maven Central upload # To make sure Maven can access your Sonatype credentials, a settings.xml needs to be created in the ~/.m2 folder with the username and password.\nFirst define a variable for username and password:\nSONATYPE_USERNAME=\u0026#34;\u0026lt;username_here\u0026gt;\u0026#34; SONATYPE_PASSWORD=\u0026#34;\u0026lt;password_here\u0026gt;\u0026#34; Note that these shouldn\u0026rsquo;t contain any characters that aren\u0026rsquo;t compatible with xml. Hence we better xml encode them before using:\nfunction xml_encode() { echo $1 | sed \u0026#39;s/\u0026amp;/\\\u0026amp;amp;/g; s/\u0026lt;/\\\u0026amp;lt;/g; s/\u0026gt;/\\\u0026amp;gt;/g; s/\u0026#34;/\\\u0026amp;quot;/g; s/\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;/\\\u0026amp;#39;/g\u0026#39; } SONATYPE_USERNAME=$(xml_encode \u0026#34;\u0026lt;username_here\u0026gt;\u0026#34;) SONATYPE_PASSWORD=$(xml_encode \u0026#34;\u0026lt;password_here\u0026gt;\u0026#34;) Next, make sure the ~/.m2 directory is created:\nmkdir -p ~/.m2 And finally create the settings.xml file with the credentials:\necho \u0026#34;\u0026lt;settings xmlns=\\\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\\\u0026#34; xmlns:xsi=\\\u0026#34;http://www.w3.org/2001/XMLSchema-instance\\\u0026#34; xsi:schemaLocation=\\\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\\\u0026#34;\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;server\u0026gt; \u0026lt;id\u0026gt;$MAVEN_CENTRAL_REPOID\u0026lt;/id\u0026gt; \u0026lt;username\u0026gt;$SONATYPE_USERNAME\u0026lt;/username\u0026gt; \u0026lt;password\u0026gt;$SONATYPE_PASSWORD\u0026lt;/password\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;/settings\u0026gt;\u0026#34; \u0026gt; ~/.m2/settings.xml 4.a Download artifacts # First, define the output directory where the downloaded files will be placed.\nOUTPUT_DIR=\u0026#34;output\u0026#34; Then for each version, create a new directory that will host the downloaded artifacts:\nfor v in ${VERSIONS[@]}; do mkdir -p $OUTPUT_DIR/$v done And finally, download all the artifacts using the base URL that we created in step 1:\nfor v in ${VERSIONS[@]}; do ... curl -L $BINTRAYURL/$v/$ARTIFACT_ID-$v.aar \\ -o $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.aar curl -L $BINTRAYURL/$v/$ARTIFACT_ID-$v.pom \\ -o $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom done This will represent a similar folder structure in the output directory as what is present in Maven.\nNote: if you deploy more artifacts (e.g. javadoc.jar), make sure to download them here. And when your artifact is a .jar, update the extension.\n4.b Add all missing info to pom.xml # Maven Central has more mandatory fields for the pom.xml and hence the pom.xml files may need to be amended before uploading.\nI had to add the following info:\nname description URL license developer organization SCM (link to source control) To add the information above, let\u0026rsquo;s replace an existing attribute in the pom.xml with a new XML snippet that contains all information. A good candidate to replace is the \u0026lt;packaging\u0026gt; attribute:\nPOM_PLACEHOLDER=\u0026#34;\u0026lt;packaging\u0026gt;.*\u0026gt;\u0026#34; This will be replaced with a new XML snippet that starts with the same attribute, but adds the other attributes to the pom.xml:\nPOM_REPLACEMENT=\u0026#34;\u0026lt;packaging\u0026gt;aar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;name here\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;description here\u0026lt;/description\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;licenses\u0026gt; \u0026lt;license\u0026gt; \u0026lt;name\u0026gt;license here\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;url to license\u0026lt;/url\u0026gt; \u0026lt;/license\u0026gt; \u0026lt;/licenses\u0026gt; \u0026lt;organization\u0026gt; \u0026lt;name\u0026gt;name here\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;/organization\u0026gt; \u0026lt;developers\u0026gt; \u0026lt;developer\u0026gt; \u0026lt;organization\u0026gt;name here\u0026lt;/organization\u0026gt; \u0026lt;organizationUrl\u0026gt;url here\u0026lt;/organizationUrl\u0026gt; \u0026lt;/developer\u0026gt; \u0026lt;/developers\u0026gt; \u0026lt;scm\u0026gt; \u0026lt;connection\u0026gt;url here\u0026lt;/connection\u0026gt; \u0026lt;developerConnection\u0026gt;url here\u0026lt;/developerConnection\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;/scm\u0026gt; \u0026#34; To learn what data to provide for each attribute, have a look a the sonatype documentation\nNote that your pom.xml might already have been defining some of these attributes, so you may not need to add all of these replacement attributes when migrating your project\nUsing sed we can replace the placeholder with the replacement text:\nsed -e \u0026#34;s/$POM_PLACEHOLDER/$POM_REPLACEMENT_ESCAPED/g\u0026#34; \\ $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom Unfortunately, that doesn\u0026rsquo;t work as all / in the replacement snippet need to be escaped or sed will consider them part of its command.\nTo fix this, preprocess the replacement snippet:\nPOM_REPLACEMENT_ESCAPED=$(echo \u0026#34;${POM_REPLACEMENT}\u0026#34; |\\ sed \u0026#39;s#/#\\\\/#g\u0026#39;) Almost there, but sed cannot handle multi-line replacements.\nThis can be solved by using tr to temporarily swap the /n characters with a unique character @ and swapping it back after the replacement:\nPOM_REPLACEMENT_ESCAPED=$(echo \u0026#34;${POM_REPLACEMENT}\u0026#34; |\\ sed \u0026#39;s#/#\\\\/#g\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;@\u0026#39;) sed -e \u0026#34;s/$POM_PLACEHOLDER/$POM_REPLACEMENT_ESCAPED/g\u0026#34; \\ $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom |\\ tr \u0026#39;@\u0026#39; \u0026#39;\\n\u0026#39; \u0026gt; temp.txt mv temp.txt $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom Notice how an intermediate file temp.txt is used to avoid reading and modifying the original file at the same time.\n4.c Sign and upload to Maven Central # To sign and upload the artifacts to Maven Central, what better tool to use than Maven itself?\nFirst, make sure Maven is installed:\nOSX: $ brew install maven Docker: $ RUN apk add maven Then define the repository id and staging URL constants:\n# Constants, no need to change these MAVEN_CENTRAL_STAGINGURL=\u0026#34;https://oss.sonatype.org/service/local/staging/deploy/maven2\u0026#34; MAVEN_CENTRAL_REPOID=\u0026#34;ossrh\u0026#34; Finally, invoke Maven with the GPG sign and deploy plugin:\nfor v in ${VERSIONS[@]}; do ... mvn gpg:sign-and-deploy-file \\ -Durl=$MAVEN_CENTRAL_STAGINGURL \\ -DrepositoryId=$MAVEN_CENTRAL_REPOID \\ -DpomFile=$OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom \\ -Dfile=$OUTPUT_DIR/$v/$ARTIFACT_ID-$v.aar done This will upload all your files to the staging environment on Maven Central.\nNote: If you want to upload additional artifacts (e.g. javadoc.jar), have a look at the Sonatype documentation.\nAfter, login to Sonatype to close the repository from future uploads and promote all artifacts to release. This process is well described in the your first release section by Márton Braun\nBringing it all together # Combined this results in the following script, that takes all required secrets as input parameters so it can easily be run on a CI:\n$ ./migrate_to_mavencentral.sh $BASE64_SIGNING_KEY $SONATYPE_USERNAME $SONATYPE_PASSWORD And the full script (including TODOs!) can be found on Github:\n#!/bin/bash set -euo pipefail # TODO: add versions e.g. (1.0.0 1.0.1 1.0.2) VERSIONS=() # TODO : add artifact Id ARTIFACT_ID=\u0026#34;\u0026#34; # TODO: https://dl.bintray.com/\u0026lt;bintray-org\u0026gt;/\u0026lt;bintray-repo\u0026gt;/\u0026lt;group-id-slash-separated\u0026gt;/\u0026lt;artifact-id\u0026gt; BINTRAYURL=\u0026#34;\u0026#34; # TODO: define placeholder and provide additional pom information (starting with placeholder!) ARTIFACT_EXTENSTION=\u0026#34;aar\u0026#34; POM_PLACEHOLDER=\u0026#34;\u0026lt;packaging\u0026gt;.*\u0026gt;\u0026#34; POM_REPLACEMENT=\u0026#34;\u0026lt;packaging\u0026gt;aar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;name here\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;description here\u0026lt;/description\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;licenses\u0026gt; \u0026lt;license\u0026gt; \u0026lt;name\u0026gt;license here\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;url to license\u0026lt;/url\u0026gt; \u0026lt;/license\u0026gt; \u0026lt;/licenses\u0026gt; \u0026lt;organization\u0026gt; \u0026lt;name\u0026gt;name here\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;/organization\u0026gt; \u0026lt;developers\u0026gt; \u0026lt;developer\u0026gt; \u0026lt;organization\u0026gt;name here\u0026lt;/organization\u0026gt; \u0026lt;organizationUrl\u0026gt;url here\u0026lt;/organizationUrl\u0026gt; \u0026lt;/developer\u0026gt; \u0026lt;/developers\u0026gt; \u0026lt;scm\u0026gt; \u0026lt;connection\u0026gt;url here\u0026lt;/connection\u0026gt; \u0026lt;developerConnection\u0026gt;url here\u0026lt;/developerConnection\u0026gt; \u0026lt;url\u0026gt;url here\u0026lt;/url\u0026gt; \u0026lt;/scm\u0026gt; \u0026#34; # Constants MAVEN_CENTRAL_STAGINGURL=\u0026#34;https://oss.sonatype.org/service/local/staging/deploy/maven2\u0026#34; MAVEN_CENTRAL_REPOID=\u0026#34;ossrh\u0026#34; OUTPUT_DIR=\u0026#34;output\u0026#34; # Utilities function escape_pom() { echo \u0026#34;$1\u0026#34; | sed \u0026#39;s#/#\\\\/#g\u0026#39; | tr \u0026#39;\\n\u0026#39; \u0026#39;@\u0026#39; } function xml_encode() { echo $1 | sed \u0026#39;s/\u0026amp;/\\\u0026amp;amp;/g; s/\u0026lt;/\\\u0026amp;lt;/g; s/\u0026gt;/\\\u0026amp;gt;/g; s/\u0026#34;/\\\u0026amp;quot;/g; s/\u0026#39;\u0026#34;\u0026#39;\u0026#34;\u0026#39;/\\\u0026amp;#39;/g\u0026#39; } echo \u0026#34;Loading script input\u0026#34; BASE64_SIGNING_KEY=$1 SONATYPE_USERNAME=$(xml_encode $2) SONATYPE_PASSWORD=$(xml_encode $3) echo $SONATYPE_PASSWORD if [ -z \u0026#34;${BASE64_SIGNING_KEY}\u0026#34; -o -z \u0026#34;${SONATYPE_USERNAME}\u0026#34; -o -z \u0026#34;${SONATYPE_PASSWORD}\u0026#34; ]; then echo \u0026#34;USAGE: migrate BASE64_SIGNING_KEY SONATYPE_USERNAME SONATYPE_PASSWORD\u0026#34; exit 1 fi echo \u0026#34;Setup signing key\u0026#34; echo $BASE64_SIGNING_KEY | base64 -d | gpg --import echo \u0026#34;Setup Maven credentials\u0026#34; mkdir -p ~/.m2 echo \u0026#34;\u0026lt;settings xmlns=\\\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\\\u0026#34; xmlns:xsi=\\\u0026#34;http://www.w3.org/2001/XMLSchema-instance\\\u0026#34; xsi:schemaLocation=\\\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\\\u0026#34;\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;server\u0026gt; \u0026lt;id\u0026gt;$MAVEN_CENTRAL_REPOID\u0026lt;/id\u0026gt; \u0026lt;username\u0026gt;$SONATYPE_USERNAME\u0026lt;/username\u0026gt; \u0026lt;password\u0026gt;$SONATYPE_PASSWORD\u0026lt;/password\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;/settings\u0026gt;\u0026#34; \u0026gt; ~/.m2/settings.xml echo \u0026#34;Migrate artifacts\u0026#34; for v in ${VERSIONS[@]}; do echo \u0026#34;Migrating version $v\u0026#34; mkdir -p $OUTPUT_DIR/$v curl -L $BINTRAYURL/$v/$ARTIFACT_ID-$v.$ARTIFACT_EXTENSTION \\ -o $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.$ARTIFACT_EXTENSTION curl -L $BINTRAYURL/$v/$ARTIFACT_ID-$v.pom \\ -o $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom # Add required metadata to pom.xml sed -e \u0026#34;s/$POM_PLACEHOLDER/$(escape_pom \u0026#34;$POM_REPLACEMENT\u0026#34;)/g\u0026#34; \\ $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom |\\ tr \u0026#39;@\u0026#39; \u0026#39;\\n\u0026#39; \u0026gt; temp.txt mv temp.txt $OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom mvn gpg:sign-and-deploy-file \\ -Durl=$MAVEN_CENTRAL_STAGINGURL \\ -DrepositoryId=$MAVEN_CENTRAL_REPOID \\ -DpomFile=$OUTPUT_DIR/$v/$ARTIFACT_ID-$v.pom \\ -Dfile=$OUTPUT_DIR/$v/$ARTIFACT_ID-$v.$ARTIFACT_EXTENSTION done Wrap-up # Migrating existing artifacts to Maven Central involves quite a few steps. Fortunately, the open source script presented in this blogpost can help with downloading all artifacts, updating their pom.xml, signing them, and uploading them to Maven Central.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"24 March 2021","externalUrl":null,"permalink":"/blog/2021/03/24/migrate-artifacts-mavencentral/","section":"Blogs","summary":"With JCenter shutting down, many are migrating to Maven Central. And while there are many posts on how to publish new artifacts, also all existing artifacts should be migrated away from JCenter.","title":"Migrate existing library artifacts from JCenter to Maven Central","type":"blog"},{"content":"","date":"24 March 2021","externalUrl":null,"permalink":"/tags/script/","section":"Tags","summary":"","title":"Script","type":"tags"},{"content":"","date":"17 March 2021","externalUrl":null,"permalink":"/tags/code-sharing/","section":"Tags","summary":"","title":"Code Sharing","type":"tags"},{"content":"","date":"17 March 2021","externalUrl":null,"permalink":"/tags/gradle/","section":"Tags","summary":"","title":"Gradle","type":"tags"},{"content":"","date":"17 March 2021","externalUrl":null,"permalink":"/tags/kotlin/","section":"Tags","summary":"","title":"Kotlin","type":"tags"},{"content":"","date":"17 March 2021","externalUrl":null,"permalink":"/tags/multiplatform/","section":"Tags","summary":"","title":"Multiplatform","type":"tags"},{"content":"While Android supports most Java language features, it doesn\u0026rsquo;t support every API that Java provides. On the other hand, Kotlin multiplatform only allows sharing code across all targets (commonMain), not a subset of targets (commonJvm).\nRead on to learn how to share part of your code between Android and Java (Jvm), while still providing platform-specific implementations of some classes.\nProblem description # In a typical Kotlin multiplatform project, there is a commonMain SourceSet (blue) which defines both common code and expected code for specific SourceSets (orange):\nBesides making use of the common code, the specific SourceSets also must provide actual implementations for the expected code.\nWhile this mechanism works great, it doesn\u0026rsquo;t allow to share code between specific SourceSets. Take for instance Android and Jvm, they have a lot of common API\u0026rsquo;s but some (e.g. Base64) are different.\nAs such Android has defined its own android.util.Base64 class which is different from the Jvm java.util.Base64 class. (Though API level 26 and higher also support java.util.Base64)\nSo the challenge at hand is to share most actual implementations across Android and Jvm, but provide platform-specific implementations for some functions.\nVisually speaking we would like to accomplish the following:\nApproach 1: New sourceset # Inspired by an example from Sergey Igushkin, let\u0026rsquo;s add a new sourceSet commonJvmAndroid that will have the shared actual implementations across Android and Jvm.\nThis requires the following:\ncreate a new folder commonJvmAndroid under src create a new SourceSet called commonJvmAndroid make androidMain and jvmMain depend on this new SourceSet And the resulting build.gradle.kts file will be:\nkotlin { ... sourceSets { ... // Must be defined before androidMain and jvmMain val commonJvmAndroid = create(\u0026#34;commonJvmAndroid\u0026#34;) { dependsOn(commonMain) } val androidMain by getting { dependsOn(commonJvmAndroid) dependencies { ... } } val jvmMain by getting { dependsOn(commonJvmAndroid) dependencies { ... } } } } While this solution works great from the command line, Intellij autocomplete unfortunately doesn\u0026rsquo;t work and all Java imports show up red.\nI suspect this is because Intellij doesn\u0026rsquo;t know what kind of SourceSet commonJvmAndroid is, whereas it can recognize the default multiplatform SourceSets.\nApproach 2: New srcDir # To ensure Intellij autocomplete works, a srcDir can be added to the existing SourceSets.\ncreate a new folder commonJvmAndroid under src add this new sourceSet to androidMain and jvmMain And the resulting build.gradle.kts file will be:\nkotlin { ... sourceSets { ... val androidMain by getting { kotlin.srcDir(\u0026#34;src/commonJvmAndroid/kotlin\u0026#34;) dependencies { ... } } val jvmMain by getting { kotlin.srcDir(\u0026#34;src/commonJvmAndroid/kotlin\u0026#34;) dependencies { ... } } } } Because there is no new sourceSet, Intellij will implicitly use the Android or Jvm one while browsing code in commonAndroidJvm, and hence autocomplete will work!\nReal-life example # Want a bigger example of this principle in action? Have a look at the awesome PbandK project, that provides a Kotlin code generator and runtime for Protocol Buffers. It is built to work across multiple Kotlin platforms.\nIn the runtime module, the build.gradle.kts adds the extra srcDir to androidMain/jvmMain and the src directory has the shared code in a commonAndroidJvm folder.\nWrap-up # While Android and Jvm projects share most APIs, not every Java API is available on Android. To share a subset of code across both platforms, it\u0026rsquo;s best to use a shared srcDir so Intellij autocomplete works as expected.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"17 March 2021","externalUrl":null,"permalink":"/blog/2021/03/17/share-code-kotlin-multiplatform/","section":"Blogs","summary":"While Android supports most Java language features, it doesn\u0026rsquo;t support every API that Java provides. On the other hand, Kotlin multiplatform only allows sharing code across all targets (commonMain), not a subset of targets (commonJvm).","title":"Share code between Android and Jvm in Kotlin multiplatform","type":"blog"},{"content":"","date":"4 February 2021","externalUrl":null,"permalink":"/tags/bintray/","section":"Tags","summary":"","title":"Bintray","type":"tags"},{"content":"","date":"4 February 2021","externalUrl":null,"permalink":"/tags/library/","section":"Tags","summary":"","title":"Library","type":"tags"},{"content":"This week JFrog - out of nowhere - announced to completely remove their Maven repository. Since they\u0026rsquo;ll pull it offline already by May 2021 (!!!) it\u0026rsquo;s time to urgently migrate away. This blogpost will guide how to get started.\nExpected migrations # After the jcenter/bintray shutdown announcement, there are two main migrations steps required:\nconsumed dependencies from Bintray/JCenter published artifacts to Bintray/JCenter Let\u0026rsquo;s have an in-depth look at both.\nConsumed dependencies from Bintray/JCenter # These are dependencies that your app or library directly uses in one of its dependencies blocks in build.gradle.\nTo understand what needs to happen, let\u0026rsquo;s first have a look to see how Gradle fetches dependencies. Imagine a project with multiple defined repositories in the top-level build.gradle file:\n// Top-level build.gradle file allprojects { repositories { google() jcenter() } } // App (or module) level build.gradle file dependencies { implementation \u0026#39;com.jeroenmols:mylibrary:1.0.0\u0026#39; } In this example, Gradle will first look for com.jeroenmols:mylibrary in the google() Maven repository. If it can\u0026rsquo;t find the artifact there, it will look in jcenter() instead.\nNote that jcenter is a superset of Maven Central. So when you request jcenter for a Maven artifact that it doesn\u0026rsquo;t host itself, it will go and fetch it from Maven Central for you.\nTwo things are important to note here:\nthe order in which repositories are defined matters most artifacts come from mavenCentral(), hosted through jcenter() To fully migrate away from jcenter(), all we need to do is replace all jcenter() occurrences with mavenCentral() in all build.gradle files.\nFor my projects this meant:\n// Top level build.gradle file buildscript { repositories { google() - jcenter() + mavenCentral() } } ... allprojects { repositories { - jcenter() + mavenCentral() } } // buildSrc level build.gradle file repositories { - jcenter() + mavenCentral() } After replacing all repositories, we can test if our build still passes by running the following command:\n./gradlew assemble assembleDebugUnitTest assembleAndroidTest --refresh-dependencies This will ensure all dependencies for every build type are downloaded again. Such a \u0026ldquo;clean\u0026rdquo; build will assess whether your app can be built independently of jcenter().\nIf this command passes, congratulations you\u0026rsquo;ve successfully migrated your dependencies away from jcenter. Nothing more to do.\nWhen this command fails, however, it will print out all issues you may have:\n* What went wrong: Could not determine the dependencies of task \u0026#39;:app:lintVitalRelease\u0026#39;. \u0026gt; Could not resolve all artifacts for configuration \u0026#39;:app:debugCompileClasspath\u0026#39;. \u0026gt; Could not find com.jeroenmols:mylibrary:1.0.0. Required by: project :app This doesn\u0026rsquo;t just mean we can\u0026rsquo;t remove jcenter() from our projects yet. But keeping jcenter() as a repository could cause us to add even more jcenter() only dependencies in the future!\nFortunately there is a way to restrict the usage of jcenter():\njcenter() { content { includeModule(\u0026#34;com.jeroenmols\u0026#34;, \u0026#34;mylibrary\u0026#34;) } } This will restrict Gradle to only use jcenter() for this single dependency. Note that you can define multiple lines of includeModule for each dependency that isn\u0026rsquo;t available on Maven Central yet.\nThe benefits of this are twofold:\nYou make it explicit which jcenter() dependencies you still have You prevent other jcenter() only dependencies from being added. For each jcenter() dependency you still have, I recommend opening a public Github issue to request the library author to migrate.\nBringing it all together yields:\n// Top level build.gradle file allprojects { repositories { google() mavenCentral() jcenter() { content { includeModule(\u0026#34;com.jeroenmols\u0026#34;, \u0026#34;mylibrary\u0026#34;) } } } } // App (or module) level build.gradle file dependencies { implementation \u0026#39;com.jeroenmols:mylibrary:1.0.0\u0026#39; } With this solution, Gradle will first look for the artifact in the google() repository, then in mavenCentral() and finally in jcenter() if the artifact is on the explicit allow list.\nPublished artifacts to Bintray/JCenter # These are artifacts you\u0026rsquo;ve published to jcenter() yourself.\nRoughly there are two things that you\u0026rsquo;ll need to do:\nChange your publishing pipeline to upload new library versions to Maven Central Migrate all your existing artifacts to Maven Central. To handle the first part, I recommend this guide by Waseef Akhtar on how to publish to Maven Central.\nFor the second part, I want to emphasize how important it is to also migrate your old artifacts. Not all your customers will be on the latest version of your library and upgrading might not be straightforward for them, especially with breaking API changes.\nUpdate: To help you with the migration, I\u0026rsquo;ve created [a script to migrate all existing artifacts from JCenter to Maven Central]({{ site.baseurl }}{% link blog/_posts/2021-03-24-migrate-artifacts-mavencentral.md %}).\nBut besides this customer argument, there could also be existing open source projects that are currently in low maintenance mode, but still incredibly valuable to the community as a learning resource. Would we want to break all those builds?\nFinally note that, even though May 1st is still a few months away, I highly recommend you to start migrating your library as soon as feasible. This won\u0026rsquo;t just decrease the burden for your customers, but I do also expect a surge in libraries being migrated to Maven central which could result in technical issues on their end. Hopefully not, of course, but better to make sure you have some extra time in your planning.\nWrap-up # Migrating your app away from JCenter can be done by replacing all jcenter() references with mavenCentral() and adding explicit inclusions for dependencies that haven\u0026rsquo;t migrated yet. For your published libraries, try to migrate as soon as possible, and don\u0026rsquo;t forget to also migrate all existing artifacts.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"4 February 2021","externalUrl":null,"permalink":"/blog/2021/02/04/migratingjcenter/","section":"Blogs","summary":"This week JFrog - out of nowhere - announced to completely remove their Maven repository. Since they\u0026rsquo;ll pull it offline already by May 2021 (!!!) it\u0026rsquo;s time to urgently migrate away.","title":"Migrating away from JCenter","type":"blog"},{"content":"","date":"4 February 2021","externalUrl":null,"permalink":"/tags/transitive-dependencies/","section":"Tags","summary":"","title":"Transitive Dependencies","type":"tags"},{"content":"","date":"5 January 2021","externalUrl":null,"permalink":"/tags/review/","section":"Tags","summary":"","title":"Review","type":"tags"},{"content":"Well\u0026hellip; I don\u0026rsquo;t really know where to start this time. 2020 was quite the rollercoaster, with many downs\u0026hellip; but fortunately also a few amazing ups. Let\u0026rsquo;s focus on the good stuff.\nMy first lucky break was that I started working remotely by choice! This privilege meant I was quite well equipped both practically and mentally for the challenges of remote work. And while not without its challenges, I haven\u0026rsquo;t been happier at my work.\nThe main work challenge was bridging the 9-hour timezone gap with my colleagues. And while I do work some evenings, I\u0026rsquo;ve never been more available for my kids. And I\u0026rsquo;ve grown really fond of:\nnever (!!!) having to set an alarm clock exercising in the middle of a working day grabbing coffee/breakfast with my wife anytime I want (can?) Another highlight was the amazing time I was able to spend with my kids during the first Lockdown. I would work from 2pm to 10pm so me and the kids could do fun stuff in the mornings (fixing up the house, gardening, playgrounds,\u0026hellip;). I recognize how extraordinary it was to have so much playtime with my kids and truly enjoyed it.\nHowever, working such long days also meant I pushed myself beyond my limits and I had to take it a lot slower for several weeks before I felt better. A huge shoutout to Plaid and my manager Judd for the immense understanding they\u0026rsquo;ve shown for my situation.\nFurther, I\u0026rsquo;ve also built and designed my own custom Lego set: Radio-Controlled Flip Over Stunt Car:\nPlease give me a vote!!! If I make it to 10k supporters, Lego might actually make it into an official set. 🤞\nFurther 2020 highlights include:\n🧱 Teaching my son and daughter how to build Lego 👨‍💻 Spoke at 4 online events and produced 1 video. 📝 Wrote 6 blog posts 📱 Grew my Twitter followers by ~20% to more than 7500 🦠 Contributed code to the official UK Covid app 🚗 Drove less than 1500 km with my car (down from 30k km) ☕️ Improved my coffee skills with (basic) latte art! 🚴‍♀️ Worked out (almost) biweekly on my indoor racing bike 🪒 Shaved my hair and grew a beard 📕 Read 4 books 📈 Started investing To keep the best for last: we\u0026rsquo;re expecting a baby girl in March! 🍼👼\nIn 2021, I\u0026rsquo;m going to try and exercise twice a week, read 5 books, enjoy every little moment with the baby and double down on being an awesome father for all my kids.\nI do want to pick up my community contributions again and maybe even venture into other areas beyond Android.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"5 January 2021","externalUrl":null,"permalink":"/blog/2021/01/05/yearinreview/","section":"Blogs","summary":"Well\u0026hellip; I don\u0026rsquo;t really know where to start this time. 2020 was quite the rollercoaster, with many downs\u0026hellip; but fortunately also a few amazing ups. Let\u0026rsquo;s focus on the good stuff.","title":"Year in review 2020","type":"blog"},{"content":"Short, powerful post on how to test the release version of libraries directly within a project without having to deploy them to Maven first.\nAs a bonus, there will also be an open-source example showcasing all of this in action.\nProblem description # In (Android) library development, the local development setup differs from how customers integrate the library.\nLocal development uses a module dependency:\ndependencies { implementation project(\u0026#39;:library\u0026#39;) } Customers integrate through Maven:\ndependencies { implementation `com.jeroenmols.lib:library:1.0.0` } Now because both integration mechanisms are fundamentally different, they can also lead to different results.\nWouldn\u0026rsquo;t it be great if you could test the Maven version of your library directly in your project?\nLet\u0026rsquo;s do that!\nThat avoids deploying the library to Maven, makes testing more realistic, and speeds up release testing considerably.\nCore idea # What we\u0026rsquo;ll try to accomplish is to mimic a local Maven repository within your Android project. That allows integrating the release build similar to an external Maven build:\ndependencies { // in-project build from current code releaseImplementation \u0026#39;com.jeroenmols.lib:library:local\u0026#39; // version from Maven releaseImplementation \u0026#39;com.jeroenmols.lib:library:1.0.0\u0026#39; } To accomplish this we\u0026rsquo;ll:\nadd a build flag to toggle between local and external build create a release artifact and pom.xml with a special version create a Maven like folder structure in app/libs add Maven metadata files and symlinks to the build outputs include the local Maven repository Implementation # In the app level build.gradle file, split the lib dependency between debug and release variant:\ndependencies { debugImplementation project(\u0026#39;:lib\u0026#39;) def releaseVersion = project.hasProperty(\u0026#34;external_version\u0026#34;) ? project.external_version : \u0026#34;local\u0026#34; releaseImplementation \u0026#34;com.jeroenmols.lib:library:$releaseVersion\u0026#34; ... } In the lib level build.gradle file, toggle the published version between local and external version:\npublishing { publications { aar(MavenPublication) { ... groupId = \u0026#39;com.jeroenmols.lib\u0026#39; artifactId = \u0026#39;library\u0026#39; version = project.hasProperty(\u0026#34;external_version\u0026#34;) ? project.external_version : \u0026#34;local\u0026#34; } } } Create a local Maven repository in the libs folder of the app module:\n$ mkdir -p app/libs/\u0026lt;group-id-slash-separated\u0026gt;/\u0026lt;artifact-id\u0026gt;/local # example: $ mkdir -p app/libs/com/jeroenmols/lib/library/local/ Go into the artifact-id folder and create a new file maven-metadata-local.xml:\n$ cd app/libs/\u0026lt;group-id-slash-separated\u0026gt;/\u0026lt;artifact-id\u0026gt; $ touch maven-metadata-local.xml # example: $ cd app/libs/com/jeroenmols/lib/library/ # $ touch maven-metadata-local.xml Copy the following content into the maven-metadata-local.xml and replace the placeholders with your groupId and artifactId:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;metadata\u0026gt; \u0026lt;groupId\u0026gt;GROUP ID HERE\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;ARTIFACT ID HERE\u0026lt;/artifactId\u0026gt; \u0026lt;versioning\u0026gt; \u0026lt;latest\u0026gt;local\u0026lt;/latest\u0026gt; \u0026lt;release\u0026gt;local\u0026lt;/release\u0026gt; \u0026lt;versions\u0026gt; \u0026lt;version\u0026gt;local\u0026lt;/version\u0026gt; \u0026lt;/versions\u0026gt; \u0026lt;/versioning\u0026gt; \u0026lt;/metadata\u0026gt; Create symbolic links to the aar and pom.xml files.\nNote that the file names and paths need to match exactly or this won\u0026rsquo;t work!\n// Make sure the output files exist, so we can symlink them $ ./gradlew generatePomFileForAarPublication assembleRelease $ cd app/libs/\u0026lt;group-id-slash-separated\u0026gt;/\u0026lt;artifact-id\u0026gt; $ ln -s \u0026lt;path-to-lib-build\u0026gt;/outputs/aar/\u0026lt;aar-file-name\u0026gt; \u0026lt;artifact-id\u0026gt;-local.aar $ ln -s \u0026lt;path-to-lib-build\u0026gt;/publications/aar/pom-default.xml \u0026lt;artifact-id\u0026gt;-local.pom # example: ln -s ../../../../../../../lib/build/outputs/aar/lib-release.aar library-local.aar # ln -s ../../../../../../../lib/build/publications/aar/pom-default.xml library-local.pom Add the local repository to the app level build.gradle file:\nrepositories { maven { url \u0026#34;$projectDir/libs\u0026#34; } } And make sure the library dependencies are built when running an app release build by adding to the app level build.gradle file:\nafterEvaluate { preReleaseBuild.dependsOn(\u0026#34;:lib:assembleRelease\u0026#34;) preReleaseBuild.dependsOn(\u0026#34;:lib:generatePomFileForAarPublication\u0026#34;) } That\u0026rsquo;s it!\nYou can now test your release variant locally by changing the build variant of the app project to release in Android studio and clicking run. Or you can test an external Maven version by invoking:\n./gradlew assembleRelease -Pexternal_version=1.0.0 Wrap-up # I hope this neat little trick is helpful to test your libraries. I\u0026rsquo;ve also open sourced a sample project that demonstrates this concept.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"2 December 2020","externalUrl":null,"permalink":"/blog/2020/12/02/inproject-maven/","section":"Blogs","summary":"Short, powerful post on how to test the release version of libraries directly within a project without having to deploy them to Maven first.\nAs a bonus, there will also be an open-source example showcasing all of this in action.","title":"Test library releases using an in project Maven repository","type":"blog"},{"content":"","date":"11 November 2020","externalUrl":null,"permalink":"/series/android-library-development/","section":"Series","summary":"","title":"Android Library Development","type":"series"},{"content":"Ever had a build failure while integrating an SDK? Wonder how you can avoid your SDK customers having dependency conflicts? How many transitive dependencies should your SDK have?\nThis post will cover how transitive dependencies of an Android library affect Apps integrating it.\nIntroduction # This post assumes familiarity with transitive dependencies and how Maven handles those. You can learn all about that and much more in the first part of this series.\nAssume there is an existing application CustomerApp that is about to start using our library:\nBefore integration, they have a single dependency on Another library that transitively depends on Transitive dependency 1.\nNow when they integrate the new library:\nThey don\u0026rsquo;t just start to depend on library, but they also depend on all its transitive dependencies Transitive dependency 1 and Transitive dependency 2.\nAll these transitive dependencies can easily cause integration issues in the host CustomerApp.\nThis blog post will look at the two most common issues:\nconflicting transitive dependency versions incompatible transitive dependencies It\u0026rsquo;s important to note that when transitive dependency issues occur, the last integrated SDK will be blamed for these issues!!!\nCustomerApp was compiling fine with Another library, only after adding library the issues occurred. So as an SDK developer, this is our problem to solve.\nConflicting dependency versions # Imagine if CustomerApp integrates the following two SDKs:\ndependencies { implementation \u0026#34;com.jeroenmols:library:1.0.0\u0026#34; implementation \u0026#34;com.example:anotherlibrary:2.0.0\u0026#34; } And that both library and anotherLibary depend on a different version of a common dependency like OkHttp.\nNow building CustomerApp would fail, because Gradle can\u0026rsquo;t know what OkHttp version to pick: v3 or v4?\nWhile more solutions possible, this post will cover the three most common ways this problem can be fixed:\nForce dependency resolution in CustomerApp Loosen dependency requirements in library Remove transitive dependency from library 1. Force dependency resolution in CustomerApp # The first way to address this problem is by adding code in the CustomerApp to force a particular dependency version.\nThis can either be done by excluding the OkHttp version from the library dependency.\nimplementation(\u0026#39;com.jeroenmols:library:1.0.0\u0026#39;) { exclude group: \u0026#39;com.squareup.okhttp3\u0026#39;, module: \u0026#39;okhttp\u0026#39; } Or by forcing the resolved OkHttp version for all dependencies to a particular version:\nconfigurations.all { resolutionStrategy { force \u0026#39;com.squareup.okhttp3:okhttp:4.9.0\u0026#39; } } The main advantage of this strategy is that no library update is required. So the developers of CustomerApp can apply this themselves when a conflict occurs.\nHowever, this is incredibly dangerous as CustomerApp is now forcing AnotherLibrary to work with OkHttp version 4.9.0, whereas AnotherLibrary was expecting OkHttp 3.x.x!\nAnd since the developers of AnotherLibrary never tested their SDK with the enforced version of OkHttp, this could cause runtime crashes (e.g. ClassNotFoundException), behavior differences,\u0026hellip;\nA second downside is that this puts the burden on the SDK customers (i.e. CustomerApp) to fix the problems arising from integrating your SDK.\n2. Loosen dependency requirements in library # A better solution is to loosen the dependency requirements of the library.\nInstead of explicitly requiring version OkHttp version 4.9.0, the SDK can also require a minimum version of 4.0.0 or higher in the pom.xml:\n... \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.squareup.okhttp3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;okhttp3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;[4.0.0,)\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; Notice how the OkHttp version is now specified as [4.0.0,) meaning any version of 4.0.0 or higher is supported.\nIn order to achieve this using Gradle, the publishing block of SDK build.gradle needs to contain the following:\npom.withXml { def dependencies = asNode().appendNode(\u0026#39;dependencies\u0026#39;) configurations.getByName(\u0026#34;releaseCompileClasspath\u0026#34;).getResolvedConfiguration().getFirstLevelModuleDependencies().each { ... def dependency = dependencies.appendNode(\u0026#39;dependency\u0026#39;) if (it.moduleGroup.contains(\u0026#39;okhttp3\u0026#39;)) { dependency.appendNode(\u0026#39;version\u0026#39;, \u0026#34;[4.0.0,)\u0026#34;) } else { dependency.appendNode(\u0026#39;version\u0026#39;, it.moduleVersion) } } } The main advantage of this strategy is that this doesn\u0026rsquo;t require any action from the CustomerApp.\nOn the other hand, this increases the testing burden for the developers of library to ensure compatibility with all supported versions of OkHttp.\nAlso, imagine OkHttp release a new major version 5.x.x with massive breaking API changes. What version of OkHttp would library then support and force their customers to adopt?\nNote that OkHttp actually solves this problem by including the version in their package name:\npackage com.square.okhttp3 \u0026gt; and Maven coordinates: \u0026gt; ```groovy \u0026gt; implementation \u0026#39;com.squareup.okhttp3:okhttp3:4.9.0\u0026#39; \u0026gt; ``` \u0026gt; So for `OkHttp` different major versions can coexist in `CustomerApp`, but this isn\u0026#39;t true for all other SDKs. ### 3. Remove transitive dependency from `library` While obvious, this actually is a highly effective way of reducing transitive dependency conflicts. Downside is that the library needs more code to solve the challenges the dependency would. This is also the only proposed solution that would be able to fully handle breaking API changes of a particular dependency that doesn\u0026#39;t support major versions to coexist. ## Incompatible transitive dependencies Similar to conflicting dependency versions, dependencies can be downright incompatible. Take for instance [protocol buffers](https://developers.google.com/protocol-buffers), which has two different artifacts: - `protobuf-java` - `protobuf-javalite` (optimized for Android) These artifacts are mostly similar but optimized for different use cases. So for a `CustomerApp` with two `libraries` dependencies that transitive rely on a different `protobuf` artifact: ![Customer app with incompatible transitive dependencies](dependency_incompatible.png) Compilation will fail! Because both `protobuf-java` and `protobuf-javalite` define the same/similar classes in the same namespace: $ ./gradlew clean assembleDebug\nTask :app:checkDebugDuplicateClasses FAILED\nFAILURE: Build failed with an exception.\nWhat went wrong: Execution failed for task \u0026lsquo;:myproject:checkReleaseDuplicateClasses\u0026rsquo;. 1 exception was raised by workers: java.lang.RuntimeException: Duplicate class com.google.protobuf.AbstractMessageLite found in modules protobuf-java-3.11.1.jar (com.google.protobuf:protobuf-java:3.11.1) and protobuf-javalite-3.11.0.jar (com.google.protobuf:protobuf-javalite:3.11.0) Duplicate class com.google.protobuf.AbstractMessageLite$Builder found in modules protobuf-java-3.11.1.jar (com.google.protobuf:protobuf-java:3.11.1) and protobuf-javalite-3.11.0.jar (com.google.protobuf:protobuf-javalite:3.11.0) Duplicate class com.google.protobuf.AbstractMessageLite$Builder$LimitedInputStream found in modules protobuf-java-3.11.1.jar (com.google.protobuf:protobuf-java:3.11.1) and protobuf-javalite-3.11.0.jar (com.google.protobuf:protobuf-javalite:3.11.0) \u0026hellip;\nAnd unfortunately for `protobuf`, this issue is very common: even Firebase performance monitoring `19.0.7` (April 2020 !!!) relied on an even different, incompatible, 4 year old `protobuf` artifact! ```groovy +--- com.google.firebase:firebase-perf:19.0.7 | +--- com.google.firebase:firebase-config:19.0.4 | | +--- com.google.firebase:firebase-abt:19.0.0 | | | \\--- com.google.protobuf:protobuf-lite:3.0.1 So what to do when a transitive dependency of the SDK relies on the wrong dependency?\nLet\u0026rsquo;s have a look at three possible solutions:\nSubstitute dependency in CustomerApp Remove dependency from transitive dependency of library Remove transitive dependency from library 1. Substitute dependency in CustomerApp # Similar to handling conflicting dependency versions, the CustomerApp can exclude the dependency:\nimplementation(\u0026#39;com.jeroenmols:library:1.0.0\u0026#39;) { exclude group: \u0026#39;com.google.protobuf\u0026#39;, module: \u0026#39;protobuf-java\u0026#39; } Or force the dependency to be substituted:\nallprojects { configurations.all { resolutionStrategy.dependencySubstitution { substitute module(\u0026#39;com.google.protobuf:protobuf-lite\u0026#39;) with module(\u0026#39;com.google.protobuf:protobuf-javalite\u0026#39;) } } } These solutions have similar advantages and disadvantages as solution 1 for conflicting versions.\n2. Remove dependency from transitive dependency # Let\u0026rsquo;s look at a more interesting approach.\nWe\u0026rsquo;ll take pbandk as an example, a very promising Kotlin code generator and runtime for Protocol buffers.\nImagine that library depends on pbandk, which unfortunately depends on the non-optimized version of protobuf, causing a build failure when integrated into the CustomerApp:\nNow to fix this, we need to ensure that protobuf-java doesn\u0026rsquo;t get transitively added to CustomerApp after adding a dependency on library.\nSo we\u0026rsquo;ll have to add a dependency exclusion to the library\u0026rsquo;s pom.xml:\n... \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;pro.streem.pbandk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pbandk-runtime-jvm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.0\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;com.google.protobuf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;protobuf-java\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; This can be done by modifying the publishing block of the library\u0026rsquo;s build.gradle:\npom.withXml { def dependencies = asNode().appendNode(\u0026#39;dependencies\u0026#39;) configurations.getByName(\u0026#34;releaseCompileClasspath\u0026#34;).getResolvedConfiguration().getFirstLevelModuleDependencies().each { ... def dependency = dependencies.appendNode(\u0026#39;dependency\u0026#39;) if (it.moduleName.contains(\u0026#34;pbandk\u0026#34;)) { dependency.appendNode(\u0026#39;version\u0026#39;, it.moduleVersion) def exclusions = dependency.appendNode(\u0026#39;exclusions\u0026#39;) def protobufExclusion = exclusions.appendNode(\u0026#39;exclusion\u0026#39;) protobufExclusion.appendNode(\u0026#39;groupId\u0026#39;, \u0026#34;com.google.protobuf\u0026#34;) protobufExclusion.appendNode(\u0026#39;artifactId\u0026#39;, \u0026#34;protobuf-java\u0026#34;) } else { dependency.appendNode(\u0026#39;version\u0026#39;, it.moduleVersion) } } } And don\u0026rsquo;t forget to also add protobuf-javalite as a direct transitive dependency to the library. This is needed to ensure the SDK also works in apps that don\u0026rsquo;t rely on protobuf-javalite yet.\nNote that the pbandk example is just as an illustration. The library is still under active development and there is an open issue to address this.\n3. Remove transitive dependency from library # Similar to solving dependency version conflicts, incompatibilities can also be solved by removing the transitive dependency altogether. Again with the disadvantage of having to write more code in the library.\nInvestigate dependency conflicts # Finally, whenever a dependency conflict occurs, there is one Gradle command that will be a lifesaver while debugging:\n./gradlew :library:dependencies Which will give you a detailed overview of how each transitive dependency ends up in your classpath:\n$ ./gradlew --console plain :app:dependencies --configuration releaseRuntimeClasspath \u0026gt; Task :app:dependencies ------------------------------------------------------------ Project :app ------------------------------------------------------------ releaseRuntimeClasspath - Runtime classpath of compilation \u0026#39;release\u0026#39; (target (androidJvm)). +--- org.jetbrains.kotlin:kotlin-stdlib:1.3.72 | +--- org.jetbrains.kotlin:kotlin-stdlib-common:1.3.72 | \\--- org.jetbrains:annotations:13.0 +--- androidx.core:core-ktx:1.3.2 | +--- org.jetbrains.kotlin:kotlin-stdlib:1.3.71 -\u0026gt; 1.3.72 (*) | +--- androidx.annotation:annotation:1.1.0 | \\--- androidx.core:core:1.3.2 | \\--- ... +--- androidx.appcompat:appcompat:1.2.0 | +--- androidx.annotation:annotation:1.1.0 | +--- androidx.core:core:1.3.0 -\u0026gt; 1.3.2 (*) | +--- androidx.cursoradapter:cursoradapter:1.0.0 | | \\--- ... | +--- androidx.fragment:fragment:1.1.0 | | \\--- ... | +--- androidx.appcompat:appcompat-resources:1.2.0 | | \\--- ... | | | +--- androidx.drawerlayout:drawerlayout:1.0.0 | | \\--- ... | \\--- androidx.collection:collection:1.0.0 -\u0026gt; 1.1.0 (*) +--- com.google.android.material:material:1.2.1 | +--- androidx.annotation:annotation:1.0.1 -\u0026gt; 1.1.0 | +--- androidx.appcompat:appcompat:1.1.0 -\u0026gt; 1.2.0 (*) | +--- androidx.cardview:cardview:1.0.0 | | \\--- ... | +--- androidx.coordinatorlayout:coordinatorlayout:1.1.0 | | \\--- ... | +--- androidx.core:core:1.2.0 -\u0026gt; 1.3.2 (*) | +--- androidx.annotation:annotation-experimental:1.0.0 | +--- androidx.fragment:fragment:1.0.0 -\u0026gt; 1.1.0 (*) | +--- androidx.lifecycle:lifecycle-runtime:2.0.0 -\u0026gt; 2.1.0 (*) | +--- androidx.recyclerview:recyclerview:1.0.0 -\u0026gt; 1.1.0 | | \\--- ... | +--- androidx.transition:transition:1.2.0 | | \\--- ... | +--- androidx.vectordrawable:vectordrawable:1.1.0 (*) | \\--- androidx.viewpager2:viewpager2:1.0.0 | \\--- ... \\--- androidx.constraintlayout:constraintlayout:1.1.3 \\--- androidx.constraintlayout:constraintlayout-solver:1.1.3 (*) - dependencies omitted (listed previously) Notice the sheer amount of dependencies that the standard Android project template already has!\nRecommendation # Transitive SDK dependencies can create very challenging issues. These tend to be hard to predict as they only pop up for certain combinations of dependencies in a CustomerApp.\nWorse even, their blame might be pushed onto the wrong SDK. And your SDK might be blamed for a conflict caused by an obsolete transitive Firebase dependency.\nThe only foolproof way to solve these issues is to not use any transitive dependencies for your library.\nAnd while that\u0026rsquo;s likely not very practical, here\u0026rsquo;s a few tips to avoid transitive dependency problems:\nminimize transitive dependencies often it\u0026rsquo;s easy to write your own (minimal) solution focus on commonly used dependencies (e.g. OkHttp) -\u0026gt; CustomerApp likely has this already investigate breaking changes are handled specify minimum versions instead of specific ones only rely on stable transitive dependencies (no RC, Beta or Alpha) use android optimized dependencies Finally, to combat device fragmentation, Android has a rich set of Jetpack libraries. These have become so ubiquitous, that it\u0026rsquo;s close to impossible not to rely on them when developing an Android app or SDK.\nTherefore, and thanks to their amazing track record of backward compatibility, it\u0026rsquo;s fine to rely on AndroidX dependencies. Most tips above remain valid (e.g. min version, no alpha\u0026rsquo;s,\u0026hellip;) and keep in mind that some AndroidX libraries may need Google play services in order to work.\nWrap-up # Transitive dependencies problems only occur when a CustomerApp has certain combinations of dependencies. This makes them hard to predict and quite disruptive for both the SDK as app developers.\nTry to reduce the library\u0026rsquo;s transitive dependencies to a minimum and focus on popular, Android optimized dependencies.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"11 November 2020","externalUrl":null,"permalink":"/blog/2020/11/11/library-dependencies/","section":"Blogs","summary":"Ever had a build failure while integrating an SDK? Wonder how you can avoid your SDK customers having dependency conflicts? How many transitive dependencies should your SDK have?","title":"Android library development - Dependencies","type":"blog"},{"content":"","date":"11 November 2020","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"With modularization being all the hype, should you also modularize an SDK? Are fat aar files really needed? And how do you prevent internal APIs from being exposed on your public interface?\nThis post will cover all things modularization for Android libraries.\nIntroduction # When building an SDK, one might be inclined to modularize the SDK as modularization has tons of benefits.\nHowever, there are two challenges with that:\nsubmodule dependencies don\u0026rsquo;t get included in the .aar file public interface of submodules gets exposed Submodule dependencies # Imagine the following project setup:\n├── app ├── library └── modules ├── database └── ui-components Here, the app module is an Android application that depends on the library module. And the library module depends on two other modules: database and ui-components.\nRemember that when a library module gets built, the .aar artifact will only include code and resources that are in the library module itself. It won\u0026rsquo;t include:\nany code or resources from database and ui-components links to its transitive dependencies (these go into the pom.xml) So when the app module directly includes the library as a Maven dependency, it would crash due to missing classes from database and ui-components on its classpath.\nThis is, unfortunately, a limitation of the current Android Gradle plugin, and there\u0026rsquo;s been a feature request open for more than 3 years now that\u0026rsquo;s still unaddressed\nThere are three ways to solve this though:\nrelease every submodule of your library directly to Maven create a fat .aar that includes the submodules create a single module SDK 1. Release submodules to Maven # Instead of publishing library to Maven, we could also publish database and ui-components. This way the library module can include them as a direct Maven dependency and add it as a transitive dependency to its pom.xml\ndependencies { implementation \u0026#34;com.jeroenmols:database:1.0.0\u0026#34; implementation \u0026#34;com.jeroenmols:ui-components:1.0.0\u0026#34; } However, this adds quite a bit of extra complexity. Because when a change is made to the database module, it now first has to be built, published and version updated in the library module before that module sees the changes.\nThis obviously has a significant impact on the day to day workflow for developers on the project! Moreover, it\u0026rsquo;s mostly practical when there are a limited amount of submodules that only change infrequently.\nThese challenges don\u0026rsquo;t mean this approach can\u0026rsquo;t be successful though. The Android Jetpack libraries are the living proof of that, but it\u0026rsquo;s also adopted by for instance the Square In-App payments SDK.\n2. Fat AAR # In the fat .aar solution, code and resources of the submodules are bundled into the main SDK module, hence creating a fat .aar. This can be done by using an external Gradle plugin such as fat-aar-android.\nTo create a fat .aar, apply a plugin to the build.gradle file of the library and change its dependencies from implementation to embed:\napply plugin: \u0026#39;com.kezong.fat-aar\u0026#39; ... dependencies { embed project(path: \u0026#39;:modules:database\u0026#39;, configuration:\u0026#39;default\u0026#39;) embed project(path: \u0026#39;:modules:ui-components\u0026#39;, configuration:\u0026#39;default\u0026#39;) } While the fat .aar solution works, it\u0026rsquo;s not without its challenges either.\nFor starters, the fat .aar plugin breaks on almost every minor Android Gradle plugin update! This is because it hooks itself into particular tasks of the Android Gradle plugin and these very often get renamed/moved. However, the project maintainer does a stellar job at fixing those within a few weeks after the breaking change.\nAlso, because of the way fat .aar references dependencies from submodules, it can significantly increase the binary size of your SDK. There is a way to solve that by using compileOnly for SDK submodule dependencies, but I\u0026rsquo;m not going to cover that in-depth here.\n3. Single module SDK # Quite obvious, but with a single module SDK this problem simply doesn\u0026rsquo;t exist.\nPublic interface pollution by submodules # Kotlin has four different visibility modifiers:\nprivate - visible inside this class only protected — same as private + visible in subclasses too internal — visible to all classes inside this module public — visible to all classes Notably absent here is a modifier that\u0026rsquo;s internal to the project, yet visible across different modules.\nSo when the database module wants to make its methods accessible to the library, it will need to mark those methods as public!\nHowever, that won\u0026rsquo;t just cause them to be accessible to the library, it will also make those methods accessible to any application using the library! Hence exposing SDK internals to the outside world.\nWhile this limitation is fundamental to Kotlin (and Java), there are a few ways to mitigate this:\nmove all internal APIs to an \u0026ldquo;internal package\u0026rdquo; obfuscate all non-public classes in the SDK using R8/proguard create a single module SDK 1. Internal package # The first solution is to move all classes that aren\u0026rsquo;t intended for public use to a package name that has internal in its name. This discourages (but not prevents!) others from using it.\npackage com.jeroenmols.internal.database For example OkHttp has an okhttp.internal package.\n2. Proguard/R8 # A more aggressive solution is to use Proguard/R8 to obfuscate each interface that isn\u0026rsquo;t supposed to be public.\na.a.a However, these class names no longer have a unique package prefix! Hence this could lead to class name collisions with other libraries that do the same.\nFortunately, there is an option to repackage classes under your own namespace to avoid collisions in proguard-rules.pro:\nrepackageclasses com.jeroenmols.internal This will make sure every obfuscated class will be flattened in the package specified.\ncom.jeroenmols.internal.a The main downside of this approach is that Proguard/R8 isn\u0026rsquo;t trivial to set up correctly, so expect some frustration and test well.\nNote: both these strategies aren\u0026rsquo;t mutually exclusive! I\u0026rsquo;ve successfully combined both to reduce an SDK API surface.\n3. Single module SDK # Finally, there is the third option of building a single module SDK and using the internal modifier to prevent classes/methods from being exposed publicly.\nRecommendation # While modularization is almost always a good idea for an App, the same can\u0026rsquo;t be said for SDKs. This is mainly because the tooling is lacking proper support for building Android libraries.\nTherefore I recommend making small and even mid-sized SDKs single module and organize code in packages instead.\nWhenever an SDK grows larger, it likely contains parts that could also be useful as a stand-alone library. Hence it might make sense to split the SDK and develop and deploy a few small spin-offs.\nMulti modules SDKs should be avoided as much as possible.\nWrap-up # Modularizing SDKs on Android unfortunately creates significant issues with packaging and restricting visibility of code. Therefore single module SDKs should be preferred.\nDon\u0026rsquo;t forget to follow me on Mastodon and don\u0026rsquo;t miss the last part about transitive dependencies!\nFeel free to leave a comment below!\n","date":"4 November 2020","externalUrl":null,"permalink":"/blog/2020/11/04/library-modularization/","section":"Blogs","summary":"With modularization being all the hype, should you also modularize an SDK? Are fat aar files really needed? And how do you prevent internal APIs from being exposed on your public interface?","title":"Android library development - Modularization","type":"blog"},{"content":"","date":"4 November 2020","externalUrl":null,"permalink":"/tags/modularization/","section":"Tags","summary":"","title":"Modularization","type":"tags"},{"content":"Having switched to Android SDK development over the past year, I\u0026rsquo;ve run into quite a few interesting and unexpected challenges. So how does library development differ from app development?\nThis mini-series will cover the differences between SDK and App development, and explore some interesting challenges around SDK modularization and transitive dependencies.\nIntroduction # Before kicking off the meat of this series, let\u0026rsquo;s have a quick look at how SDK development differs from app development. If you\u0026rsquo;re already familiar with these concepts, feel free to skip to the next article!\nNote that the term SDK or Android library will be used interchangeably.\nAnatomy of a library # A getting started Android SDK project typically contain of at least two modules:\napp module to test out the SDK library module that contains all SDK code and resources In this, the app module has a direct dependency on the library module:\ndependencies { implementation project(\u0026#39;:library\u0026#39;) } And the folder structure looks like this:\n. ├── app └── library The library module has the com.android.library plugin in its build.gradle file:\napply plugin: \u0026#39;com.android.library\u0026#39; Notice how everything so far is exactly the same as developing a submodule in a multi-module app!\nBuilding a library # Similar to building the application, the library can be built using a Gradle task:\n./gradlew :library:assembleRelease However, the output won\u0026rsquo;t be an .apk file (or .aab when using App Bundles). Instead it will be an Android Archive (or .aar) file, placed in the build folder of the library project:\nlibrary/build/outputs/aar/library-release.aar This .aar file is very similar to a Java Archive (.jar) file, but it can also contain Android XML resources.\nNote that .aar files aren\u0026rsquo;t signed, so in contrast to creating an .apk file, no signing config is required to create the release variant of the Android library.\nDeploying a library # However, customers shouldn\u0026rsquo;t directly copy-paste the SDK source code into their project. Instead, they should consume the library as a Maven dependency:\ndependencies { implementation \u0026#34;com.jeroenmols:library:1.0.0\u0026#34; } Resulting in the following project setup:\nTo make this possible, the library needs to be deployed to a public Maven repository such Maven Central or Bintray (jcenter). Which can be done by configuring the Gradle publishing plugin.\nThis blog post won\u0026rsquo;t cover how to publish your library, instead have a look at this great article by Andrew Kelly if you\u0026rsquo;re looking to learn.\nExternal dependencies # But as the library evolves, it might also start depending on Maven dependencies of its own! Imagine that the library would also depend on OkHttp:\nThis means that the customer application needs to depend on both library and OkHttp:\nWhy?\nBecause .aar files only contain code and resources of the library module that was used to build it! So the .aar file of the library won\u0026rsquo;t contain any OkHttp code, nor any indication that it requires OkHttp to run.\nConsequently, customer applications need to include both the library and OkHttp as a dependency.\ndependencies { implementation \u0026#34;com.jeroenmols:library:1.0.0\u0026#34; implementation \u0026#34;com.squareup.okhttp3:okhttp:4.9.0\u0026#34; } Notice that this did work when library is a submodule of a project! Then the build.gradle file of the library includes the OkHttp dependency and Gradle will include it into the .apk while building.\nTransitive dependencies # Wouldn\u0026rsquo;t it be nice if the OkHttp dependency could be automatically included in the customer application?\nThat way customers simply have to add:\ndependencies { implementation \u0026#34;com.jeroenmols:library:1.0.0\u0026#34; } And get the OkHttp dependency indirectly through the dependency on library. This is what we call a transitive dependency: OkHttp is a transitive dependency of the library and hence an indirect dependency of the customer application.\nBut how can Gradle know to include OkHttp in the customer app after adding the library as a dependency?\nThat\u0026rsquo;s taken care of by the pom.xml file that gets created when you deploy your app to a Maven repository (such a Maven Central).\nHere\u0026rsquo;s an example pom.xml for the library:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.jeroenmols\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;library\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;library\u0026lt;/name\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.squareup.okhttp3\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;okhttp3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.9.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; So when building an Android library, there are two key outputs:\n.aar file: a binary containing all library code and resources pom.xml file: containing all transitive dependencies In reality, there can be many more files (Javadoc, sources,\u0026hellip;). Have a look at the Files tab of the Maven entry for OkHttp.\nFor more information on how to generate a pom.xml, have a look at this post by Marco Gomiero.\nTesting # Finally, for Android libraries with external dependencies, there will be a difference between a local build of the SDK or a Maven build.\nIf the SDK source code is within a project, then transitive dependencies will automatically be included when the application is built.\nHowever, when the SDK is included through Maven, those transitive dependencies will only be included when the pom.xml file is properly constructed and deployed to Maven.\nTherefore it is always important to test the actual SDK artifact as a Maven dependency before shipping a new release!\nWrap-up # Android libraries are built into a special .aar format that includes all code and resources. For all its external dependencies, a pom.xml needs to be deployed alongside to the Maven repository.\nDon\u0026rsquo;t forget to follow me on Mastodon and enjoy reading the next post on SDK modularization!\nFeel free to leave a comment below!\n","date":"28 October 2020","externalUrl":null,"permalink":"/blog/2020/10/28/library-gettingstarted/","section":"Blogs","summary":"Having switched to Android SDK development over the past year, I\u0026rsquo;ve run into quite a few interesting and unexpected challenges. So how does library development differ from app development?","title":"Android library development - Getting started","type":"blog"},{"content":"","date":"19 February 2020","externalUrl":null,"permalink":"/tags/documentation/","section":"Tags","summary":"","title":"Documentation","type":"tags"},{"content":"","date":"19 February 2020","externalUrl":null,"permalink":"/tags/dokka/","section":"Tags","summary":"","title":"Dokka","type":"tags"},{"content":"","date":"19 February 2020","externalUrl":null,"permalink":"/tags/kdoc/","section":"Tags","summary":"","title":"Kdoc","type":"tags"},{"content":"A great way to make your library easier to use it to generate code documentation for its public interface. The default way to do this in Kotlin is to generate KDoc using the official Dokka plugin.\nThis post will cover some challenges in configuring Dokka and explain some neat tricks to improve your documentation.\nIntroduction # The equivalent of JavaDoc for Kotlin is called KDoc. While it is very similar to the former, it also supports inline Markup and allows to easily link to other elements using [ ] brackets.\n/** * A group of *members*. * * This class has no useful logic; * it\u0026#39;s just a documentation example. * * @param T the type of a member in this group. * @property name the name of this group. * @constructor Creates an empty group. */ class Group\u0026lt;T\u0026gt;(val name: String) { /** * Adds a [member] to this group. * @return the new size of the group. */ fun add(member: T): Int { ... } } The documentation generation tool is called Dokka. It comes with a Gradle plugin and can generate documentation in multiple formats such as JavaDoc, HTML and even Markdown optimized for Github pages! Neat!\nBasic Dokka configuration # Adding Dokka requires to define a dependency in your top-level build.gradle file:\nbuildscript { repositories { jcenter() } dependencies { classpath \u0026#34;org.jetbrains.dokka:dokka-gradle-plugin:0.10.1\u0026#34; } } repositories { jcenter() } And applying the plugin to the build.gradle of the module(s) for which you would like to generate documentation:\napply plugin: \u0026#39;org.jetbrains.dokka\u0026#39; dokka { outputFormat = \u0026#39;html\u0026#39; // use \u0026#39;javadoc\u0026#39; to get standard java docs outputDirectory = \u0026#34;$buildDir/javadoc\u0026#34; configuration { includeNonPublic = false skipEmptyPackages = true skipDeprecated = true reportUndocumented = true jdkVersion = 8 } } Congratulations, you can now start generating documentation for your code:\n./gradlew :library:dokka Challenges # However, when your library contains several modules, there are a few interesting challenges:\nRequired to use a fat AAR plugin to include all modules in the AAR artifact There is no visibility modifier to make classes only visible within the project The first challenge causes Dokka not to include the sources of all submodules. Consequently the resulting [KDoc] only contains documentation for your main library module.\nNote: this is because the fat AAR plugin includes the submodules as compileOnly dependencies when using the embed dependency. (See source code)\nThe second challenge bloats the documentation with a lot of classes that shouldn\u0026rsquo;t be part of the API:\nthe internal modifier is too restrictive as it doesn\u0026rsquo;t allow modules within the library to use each other\u0026rsquo;s classes. the public modifier is not restrictive enough and exposes classes to any other project using your library. Unfortunately, using public modifiers is currently the only way to have multiple module libraries until issue 62121508 gets fixed.\nMulti-module libraries # Luckily there is a way to directly tell Dokka what sources it should include in the documentation via the sourceRoots attribute.\ndokka { configuration { ... sourceRoots = ... // ENTER SOURCE ROOTS HERE } } Though this doesn\u0026rsquo;t take a String pointing to the sources, instead it requires a wrapper object a SourceRoot, which has an attribute path. 🤔\nThe easiest way to create a SourceRoot is to create a GradleSourceRootImpl and set it\u0026rsquo;s path:\nimport org.jetbrains.dokka.gradle.GradleSourceRootImpl def sourceRoot = new GradleSourceRootImpl() sourceRoot.path = it And with a bit of business logic on top, we can easily extract all sources from our directories:\n// Converts the source path Strings into SourceRoot private List\u0026lt;GradleSourceRootImpl\u0026gt; getSourceRootsToDocument() { return getSourceRootsToDocumentAsStrings().collect { def impl = new GradleSourceRootImpl() impl.path = it impl } } private List\u0026lt;String\u0026gt; getSourceRootsToDocumentAsStrings() { def sources = new ArrayList\u0026lt;\u0026gt;() sources += \u0026#34;$rootDir/app/src/main/java\u0026#34; sources += getSourceDirs(\u0026#34;$rootDir/features\u0026#34;) sources += getSourceDirs(\u0026#34;$rootDir/libraries\u0026#34;) // add other locations of sources here sources } private List\u0026lt;String\u0026gt; getSourceDirs(String directoryPath) { file(directoryPath).listFiles() .findAll { it.isDirectory() \u0026amp;\u0026amp; it.name != \u0026#34;build\u0026#34; } // Non build subfolders .collect { \u0026#34;${it.path}/src/main/java\u0026#34; } // path of main sources .findAll { new File(it).exists() } // only include if path exists } Note that these methods only look in the main source folders and that getSourceDirs only looks at direct subfolders.\nSadly, this doesn\u0026rsquo;t work and causes compilation issues when running Dokka. (╯°□°）╯︵ ┻━┻\nThis can be solved by creating a new Android library module, without any source code and apply the Dokka plugin with reference to all sources there:\nimport org.jetbrains.dokka.gradle.GradleSourceRootImpl apply plugin: \u0026#39;com.android.library\u0026#39; apply plugin: \u0026#39;org.jetbrains.dokka\u0026#39; android { buildToolsVersion BuildConfig.buildTools compileSdkVersion BuildConfig.compileSdk defaultConfig { minSdkVersion BuildConfig.minSdk targetSdkVersion BuildConfig.targetSdk } } dokka { configuration { ... sourceRoots = getSourceRootsToDocument() } } In summary, with a bit of logic, we can make sure source files of new modules are automatically included in the documentation.\nExcluding public classes # Since Kotlin doesn\u0026rsquo;t have a project internal visibility modifier, we need a way to exclude public classes from our documentation that shouldn\u0026rsquo;t be exposed.\nOne way of doing that is moving all classes that are internal to your SDK to a package name ending with internal.\npackage com.jeroenmols.internal package com.jeroenmols.api.models.internal This also gives a clear indication to users of your SDK that these classes aren\u0026rsquo;t supposed to be used.\nNote that you could use proguard on your final AAR to hide non-public classes using obfuscation.\nNow that all classes that should be internal are grouped, they can also be excluded from the documentation:\ndokka { configuration { ... perPackageOption { prefix = \u0026#34;com.jeroenmols.internal\u0026#34; suppress = true } } } And more generically, all packages in each source root that end with internal can be filtered:\nimport groovy.io.FileType private List\u0026lt;String\u0026gt; getInternalPackages() { def sourceRoots = getSourceRootsToDocumentAsStrings() def internalPackages = new ArrayList\u0026lt;String\u0026gt;() for (String root in sourceRoots) { def subPackages = getAllSubDirectories(new File(root)) .findAll { it.path.contains(\u0026#34;internal\u0026#34;) } .collect { it.path.split(\u0026#34;src/main/java/\u0026#34;)[1].replaceAll(\u0026#34;/\u0026#34;, \u0026#34;.\u0026#34;) } internalPackages.addAll(subPackages) } return internalPackages } private List\u0026lt;File\u0026gt; getAllSubDirectories(File directory) { def list = new ArrayList\u0026lt;String\u0026gt;() directory.eachFileRecurse (FileType.DIRECTORIES) { file -\u0026gt; list \u0026lt;\u0026lt; file } return list } And hooking this all together will make sure all internal classes are excluded:\ndokka { configuration { ... for (String p in getInternalPackages()) { perPackageOption { prefix = p suppress = true } } } } Bringing it all together # Here\u0026rsquo;s the full example of a Dokka configuration that includes all source from each submodule and excludes internal classes:\nimport org.jetbrains.dokka.gradle.GradleSourceRootImpl apply plugin: \u0026#39;org.jetbrains.dokka\u0026#39; dokka { outputFormat = \u0026#39;html\u0026#39; // use \u0026#39;javadoc\u0026#39; to get standard java docs outputDirectory = \u0026#34;$buildDir/javadoc\u0026#34; configuration { includeNonPublic = false skipEmptyPackages = true skipDeprecated = true reportUndocumented = true jdkVersion = 8 sourceRoots = getSourceRootsToDocument() for (String p in getInternalPackages()) { perPackageOption { prefix = p suppress = true } } } } private List\u0026lt;String\u0026gt; getInternalPackages() { def sourceRoots = getSourceRootsToDocumentAsStrings() def internalPackages = new ArrayList\u0026lt;String\u0026gt;() for (String root in sourceRoots) { def subPackages = getAllSubDirectories(new File(root)) .findAll { it.path.contains(\u0026#34;internal\u0026#34;) } .collect { it.path.split(\u0026#34;src/main/java/\u0026#34;)[1].replaceAll(\u0026#34;/\u0026#34;, \u0026#34;.\u0026#34;) } internalPackages.addAll(subPackages) } return internalPackages } private List\u0026lt;File\u0026gt; getAllSubDirectories(File directory) { def list = new ArrayList\u0026lt;String\u0026gt;() directory.eachFileRecurse (FileType.DIRECTORIES) { file -\u0026gt; list \u0026lt;\u0026lt; file } return list } // Converts the source path Strings into SourceRoot private List\u0026lt;GradleSourceRootImpl\u0026gt; getSourceRootsToDocument() { return getSourceRootsToDocumentAsStrings().collect { def impl = new GradleSourceRootImpl() impl.path = it impl } } private List\u0026lt;String\u0026gt; getSourceRootsToDocumentAsStrings() { def sources = new ArrayList\u0026lt;\u0026gt;() sources += \u0026#34;$rootDir/app/src/main/java\u0026#34; sources += getSourceDirs(\u0026#34;$rootDir/features\u0026#34;) sources += getSourceDirs(\u0026#34;$rootDir/libraries\u0026#34;) // add other locations of sources here sources } private List\u0026lt;String\u0026gt; getSourceDirs(String directoryPath) { file(directoryPath).listFiles() .findAll { it.isDirectory() \u0026amp;\u0026amp; it.name != \u0026#34;build\u0026#34; } // Non build subfolders .collect { \u0026#34;${it.path}/src/main/java\u0026#34; } // path of main sources .findAll { new File(it).exists() } // only include if path exists } Wrap-up # This post covered how to configure Dokka to generate KDoc documentation. It explained how Dokka can be used for multi-module libraries and how public classes of submodules can be excluded.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"19 February 2020","externalUrl":null,"permalink":"/blog/2020/02/19/dokka-code-documentation/","section":"Blogs","summary":"A great way to make your library easier to use it to generate code documentation for its public interface. The default way to do this in Kotlin is to generate KDoc using the official Dokka plugin.","title":"Kdoc for Android libraries using Dokka","type":"blog"},{"content":"Getting up without being rushed, cycling my kids to school, cooking healthy salads for lunch, kids running into my arms when they get home\u0026hellip; I\u0026rsquo;m quite happy with my new daily routine!\nWithout a doubt, 2019 was the highlight of my career!\nAt Philips Hue, we quadrupled (!!! 🚀) our team output and increased our app rating to 4.4 stars (up from 2.8 stars). After a year of searching, I transitioned to remote work to spend more time with my kids. However, not everything went according to plan: my new employer ran out of money and I found myself unemployed for the very first time in my life.\nThis caused quite a bit of anxiety and stress for my wife and I, especially given our mortgage and two kids\u0026hellip;\nAnd then something amazing happened:\nLooking for a new job! 🚀\nDue to a financial setback, my new employer cancelled my contract right before joining. Hence looking for a remote opportunity as #AndroidDev or Android lead, either employee or #freelancer.\nMy DM\u0026#39;s are open, thanks for RT! 🙌https://t.co/HdVjotJalX pic.twitter.com/JSNX4rjNzf\n\u0026mdash; Jeroen Mols (@molsjeroen) September 5, 2019 I reached out for help on twitter and the response was so overwhelming\u0026hellip; it really moved us.\nSo thanks to everyone for sharing the message, providing leads and support! 🙇‍\nWhile all those job interviews were quite demanding, I ended up finding a stellar freelance gig at TransferWise and a very exciting new position at Plaid. I\u0026rsquo;m stoked to share more about those on my blog later this year.\nFurther 2019 highlights include:\nTeaching my daughter how to cycle and my son to tell his mother \u0026ldquo;I love you\u0026rdquo; Spoke at 5 big conferences and 2 meetups. Wrote 14 blog posts, including two quite ambitious in-depth series Gave my first talk on inclusion at the GDE summit Open-sourced two sample apps on Github Wrote an honest, self critical retrospective on my experiences leading the team at Philips Hue Doubled my Twitter followers to more than 6300 Got featured a whopping 11 times in Android weekly Started working remotely Took many steps to reduce my impact on the environment: cycle more, remote work, carry reusable cup, avoid single-use items,\u0026hellip; In 2020, I\u0026rsquo;m going to focus on living a healthier lifestyle: exercise more, eat healthier and get better sleep. Further, I want to continue enjoying the little things in life and do silly stuff with my kids.\nI don\u0026rsquo;t plan on increasing my community contributions, in fact, I might even do slightly less. However, I would also like to explore alternative ways to give back such as one-on-one mentoring or speaking at a remote conference.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"9 January 2020","externalUrl":null,"permalink":"/blog/2020/01/09/yearinreview/","section":"Blogs","summary":"Getting up without being rushed, cycling my kids to school, cooking healthy salads for lunch, kids running into my arms when they get home\u0026hellip; I\u0026rsquo;m quite happy with my new daily routine!","title":"Year in review 2019","type":"blog"},{"content":"","date":"12 September 2019","externalUrl":null,"permalink":"/tags/feature-flags/","section":"Tags","summary":"","title":"Feature Flags","type":"tags"},{"content":"","date":"12 September 2019","externalUrl":null,"permalink":"/series/feature-flags/","section":"Series","summary":"","title":"Feature Flags","type":"series"},{"content":"Now that we know how feature flags can help us release faster, it\u0026rsquo;s time to dive into the actual implementation details. How can we easily define feature flags? How to configure them both locally as remotely? And use them in our testing?\nThis post will present a simple, powerful architecture to manage feature flags and comes with a full example on Github.\nCreating new feature flags # As discussed in part 1, the easier it is to add feature flags, the more likely developers will use the system. At its core a Feature is something very simple:\ninterface Feature { val key: String val title: String val explanation: String val defaultValue: Boolean } It needs to have a unique key to reference it on your remote feature flagging tool. A title and description to help understand what it is all about. And optionally a default value, which is handy if you\u0026rsquo;re using both FeatureFlags and TestSettings.\nThis interface can now be implemented by both a FeatureFlag and TestSetting enum:\nenum class FeatureFlag( override val key: String, override val title: String, override val explanation: String, override val defaultValue: Boolean = true ) : Feature { DARK_MODE(\u0026#34;feature.darkmode\u0026#34;, \u0026#34;Dark theme\u0026#34;, \u0026#34;Enabled dark mode\u0026#34;) } enum class TestSetting( override val key: String, override val title: String, override val explanation: String, override val defaultValue: Boolean = false ) : Feature { USE_DEVELOP_PORTAL(\u0026#34;testsetting.usedevelopportal\u0026#34;, \u0026#34;Development portal\u0026#34;, \u0026#34;Use developer REST endpoint\u0026#34;), DEBUG_LOGGING(\u0026#34;testsetting.debuglogging\u0026#34;, \u0026#34;Enable logging\u0026#34;, \u0026#34;Print all app logging to console\u0026#34;, defaultValue = true) } Note how a FeatureFlag is on by default so that it is immediately visible in developer builds, whereas TestSettings are off by default as they usually put the app in a specific condition to help with testing.\nBoth FeatureFlag and TestSetting are enums so that the Kotlin compiler can force you to handle each case explicitly in a when statement. At the same time, they are not sealed classes, because we need to be able to enumerate all items, later on, to automatically generate a UI from it. (There is no way to ask a sealed class to list all it\u0026rsquo;s subclasses)\nMission accomplished: adding a new FeatureFlag / TestSetting is as easy as adding a one-liner!\nAWESOME(\u0026#34;feature.awesome\u0026#34;, \u0026#34;Awesome\u0026#34;, \u0026#34;Does something awesome\u0026#34;) Consuming feature flags # Next, our app needs to be able to read out what value (true/false) a Feature is currently set to. This can be done by requesting one of the FeatureFlagProviders for the current value:\ninterface FeatureFlagProvider { val priority: Int fun isFeatureEnabled(feature: Feature): Boolean fun hasFeature(feature: Feature): Boolean } This interface will have several implementations with different priorities attached to it so that they can override each other. (more on that later)\nNote how implementations don\u0026rsquo;t need to provide a value for every Feature thanks to the hasFeature() method! This has two benefits:\nyou can prevent accidentally relying on build-in defaults of the feature flag tool you are using by requiring an explicit opt-in for that tool (e.g. Firebase remote config returns false when it doesn\u0026rsquo;t have a value) you can have a chain of providers (e.g. we can have a feature flag that is only locally available, not remotely). The RuntimeBehavior links all FeatureFlagProviders together and exposes the API that should be used from within the application:\nobject RuntimeBehavior { @VisibleForTesting internal val providers = CopyOnWriteArrayList\u0026lt;FeatureFlagProvider\u0026gt;() @JvmStatic fun isFeatureEnabled(feature: Feature): Boolean { return providers.filter { it.hasFeature(feature) } .sortedBy(FeatureFlagProvider::priority) .firstOrNull() ?.isFeatureEnabled(feature) ?: feature.defaultValue } @JvmStatic fun addProvider(provider: FeatureFlagProvider) = providers.add(provider) } Note how it takes all FeatureFlagProviders, removes those that don\u0026rsquo;t provide a value for the Feature and then takes the value of the highest priority provider. If no one provides a value, the default value is returned.\nThanks to all of this we can now call from anywhere in the app:\nif (RuntimeBehavior.isFeatureEnabled(FeatureFlag.DARK_MODE)) { // set dark theme } else { // set light them } Consuming FeatureFlag/TestSetting is as easy as asking the RuntimeBehavior\nif (isFeatureEnabled(AWESOME)) { // code here } Providing feature flag values # Let\u0026rsquo;s have a look at the several different FeatureFlagProviders, why we need them and how they work.\nRuntimeFeatureFlagProvider # This provider only exists in the debug version of the app and allows to dynamically turn features on or off.\nIt does this by keeping a SharedPreferences internally where it automatically stores a value for each Feature using its key.\nclass RuntimeFeatureFlagProvider : FeatureFlagProvider { private val preferences: SharedPreferences override val priority = MEDIUM_PRIORITY constructor(applicationContext: Context) { preferences = applicationContext.getSharedPreferences(\u0026#34;runtime.featureflags\u0026#34;, Context.MODE_PRIVATE) } override fun isFeatureEnabled(feature: Feature): Boolean = preferences.getBoolean(feature.key, feature.defaultValue) override fun hasFeature(feature: Feature): Boolean = true fun setFeatureEnabled(feature: Feature, enabled: Boolean) = preferences.edit().putBoolean(feature.key, enabled).apply() } Notice how this provider has a public API setFeatureEnabled to change the current value of a Feature and how every Feature is always configurable at runtime. (i.e. hasFeature() returns true for every feature)\nThe RuntimeFeatureFlagProvider allows to locally turn any FeatureFlag/TestSetting on or off.\nStoreFeatureFlagProvider # This provider only exists in the release version of the app and defines the baseline of what Features are on or off. TestSettings aren\u0026rsquo;t exposed in the release version of an app and are always off.\nclass StoreFeatureFlagProvider : FeatureFlagProvider { override val priority = MIN_PRIORITY @Suppress(\u0026#34;ComplexMethod\u0026#34;) override fun isFeatureEnabled(feature: Feature): Boolean { if (feature is FeatureFlag) { // No \u0026#34;else\u0026#34; branch here -\u0026gt; choosing the default // option for release must be an explicit choice return when (feature) { DARK_MODE -\u0026gt; false } } else { // TestSettings should never be shipped to users return when (feature as TestSetting) { else -\u0026gt; false } } } override fun hasFeature(feature: Feature): Boolean = true } Notice how you must provide an explicit value for every feature toggle! This is because you never want to accidentally ship an unfinished feature to users. Non gradual rollout of a feature requires an explicit change to the StoreFeatureFlagProvider.\nFinally, this makes it very easy to check what features are on or off in any given app release. And since all of this is just Kotlin code, it\u0026rsquo;s easy to write a script to generate a release report with what feature toggles exist and their value for that app version.\nThe StoreFeatureFlagProvider defines for every Feature whether it is on or off in the release build\nFirebaseFeatureFlagProvider # One of the most interesting things about FeatureFlags is that you can gradually roll them out using a remote feature flagging tool. We\u0026rsquo;ll look at Firebase Remote Config as an example, but this architecture supports any tool.\nclass FirebaseFeatureFlagProvider(private val isDevModeEnabled: Boolean) : FeatureFlagProvider { private val remoteConfig: FirebaseRemoteConfig = FirebaseRemoteConfig.getInstance() init { val configSettings = FirebaseRemoteConfigSettings.Builder().setDeveloperModeEnabled(isDevModeEnabled).build() remoteConfig.setConfigSettings(configSettings) } override val priority: Int = MAX_PRIORITY override fun isFeatureEnabled(feature: Feature): Boolean = remoteConfig.getBoolean(feature.key) override fun hasFeature(feature: Feature): Boolean { return when (feature) { FeatureFlag.DARK_MODE -\u0026gt; true else -\u0026gt; false } } } The most important thing to note here is that the FirebaseFeatureFlagProvider has the maximum priority, which means it takes precedence over any other FeatureFlagProvider.\nHowever, it doesn\u0026rsquo;t provide a value for all feature flags! That is because a FeatureFlag should only be remotely toggled once development for the feature is done. We don\u0026rsquo;t want anyone accidentally expose an unfinished/broken feature to users from the feature flag tool console.\nTypically the lifecycle of a FeatureFlag is:\nDevelopment started on new feature -\u0026gt; FeatureFlag added While development ongoing -\u0026gt; FeatureFlag locally available Development done Either toggle FeatureFlag in StoreFeatureFlagProvider and roll it out to all users at once. (typically if you have a marketing campaign attached to the feature) Or add the FeatureFlag to the FirebaseFeatureFlagProvider and gradually roll it out Rollout done -\u0026gt; remove FeatureFlag and clean up unused code The \u0026lt;tool name\u0026gt; - FeatureFlagProvider allows to gradually roll out finished features to users\nHow the different providers work together # Whenever the RuntimeBehavior is initialized, it will initialize all providers:\nobject RuntimeBehavior { ... @JvmStatic fun initialize(context: Context, isDebugBuild: Boolean) { if (isDebugBuild) { val runtimeFeatureFlagProvider = RuntimeFeatureFlagProvider(context) addProvider(RuntimeFeatureFlagProvider(context)) if (runtimeFeatureFlagProvider.isFeatureEnabled(TestSetting.DEBUG_FIREBASE)) { addProvider(FirebaseFeatureFlagProvider(true)) } } else { addProvider(StoreFeatureFlagProvider()) addProvider(FirebaseFeatureFlagProvider(false)) } } } For debug builds, usually only the RuntimeFeatureFlagProvider is enabled so feature flags can be toggled from the test settings screen (more on that next).\nBut you can even enable the FirebaseFeatureFlagProvider in the debug build. This allows to also easily test the remote feature flag tool.\nIn release, however, the FeatureFlag value is taken from Firebase when the FeatureFlag was made remotely available (using hasFeature() in FirebaseFeatureFlagProvider). If not, the value from StoreFeatureFlagProvider is used.\nShowing the flags in a UI # Within the developer version of our app, we want to be able to both see the status of all Features and TestSettings and also toggle each one on or off. Basically, we want to automatically generate a UI like this:\nTo show all of the Features, we can simply define a custom RecyclerView that displays an Array of Features.\nprivate class FeatureFlagAdapter\u0026lt;T : Feature\u0026gt;( val items: Array\u0026lt;T\u0026gt;, val provider: FeatureFlagProvider, val checkedListener: Function2\u0026lt;Feature, Boolean, Unit\u0026gt; ) : RecyclerView.Adapter\u0026lt;FeatureFlagViewHolder\u0026lt;T\u0026gt;\u0026gt;() { override fun getItemCount(): Int = items.size override fun onBindViewHolder(holder: FeatureFlagViewHolder\u0026lt;T\u0026gt;, position: Int) = holder.bind(items[position]) override fun onCreateViewHolder(parent: ViewGroup, viewType: Int): FeatureFlagViewHolder\u0026lt;T\u0026gt; { val itemView = LayoutInflater.from(parent.context).inflate(R.layout.item_featureflag, parent, false) return FeatureFlagViewHolder(itemView, provider, checkedListener) } } Now it becomes clear why FeatureFlags and TestSettings had to be enums, because this allows to pass the FeatureFlagAdapter either FeatureFlag.values() or TestSetting.values() and automatically generate the UI for all defined FeatureFlags or TestSettings.\nAdditionally we hand it the RuntimeFeatureFlagProvider to look up the current values of each Feature. Finally it needs a listener to respond when an item gets enabled/disabled.\nThe FeatureFlagViewHolder simply binds the properties of the Feature to the view, requests the current value from the FeatureFlagProvider and connects a listener to the switch:\nprivate class FeatureFlagViewHolder\u0026lt;T : Feature\u0026gt;( view: View, val provider: FeatureFlagProvider, val checkedListener: Function2\u0026lt;Feature, Boolean, Unit\u0026gt; ) : RecyclerView.ViewHolder(view) { fun bind(feature: T) { title.text = feature.title description.text = feature.explanation switch.isChecked = provider.isFeatureEnabled(feature) switch.setOnCheckedChangeListener { switch, isChecked -\u0026gt; if (switch.isPressed) checkedListener.invoke(feature, isChecked) } } } The listener passed into the FeatureFlagAdapter simply changes the value of the Feature on the RuntimeFeatureFlagProvider and shows a SnackBar to restart the app to ensure the new value is properly applied:\nval checkedListener = { feature: Feature, enabled: Boolean -\u0026gt; runtimeFeatureFlagProvider.setFeatureEnabled(feature, enabled) requestRestart() } private fun requestRestart() { val msg = \u0026#34;In order for changes to reflect please restart the app via settings\u0026#34; Snackbar.make(view!!, msg, Snackbar.LENGTH_INDEFINITE) .setActionTextColor(Color.RED) .setAction(\u0026#34;Force Stop\u0026#34;) { exitProcess(-1) } .show() } Now we just wrap all of this into a TestSettingsActivity with a separate launch icon and make sure this activity isn\u0026rsquo;t available in release builds. The simplest way to do this is by moving all UI classes to the debug source folder.\nNow we have a very powerful, easy to use UI framework to dynamically configure the behavior of our app! By just adding a single line FeatureFlag or TestSetting it instantly shows up in our UI.\nDebug builds have a UI to toggle all FeatureFlags and TestSettings on or off that gets fully automatically generated.\nRemote feature flags # Whilst talking about the FirebaseFeatureFlagProvider before, there is one important aspect that we didn\u0026rsquo;t cover: how to refresh the local FeatureFlag cache with new remote values. Some feature flag tools do that for you automatically, but for others (like Firebase Remote Config), you need to trigger that process manually.\nA way to make that fit into our architecture is to define an additional interface RemoteFeatureFlagProvider that every FeatureFlagProvider for a remote tool should implement.\ninterface RemoteFeatureFlagProvider { fun refreshFeatureFlags() } Now we just need to expand the FirebaseFeatureFlagProvider with this interface and implement refreshFeatureFlags:\nclass FirebaseFeatureFlagProvider(private val isDevModeEnabled: Boolean) : FeatureFlagProvider, RemoteFeatureFlagProvider { ... override fun refreshFeatureFlags() { remoteConfig.fetch(getCacheExpirationSeconds(isDevModeEnabled)).addOnCompleteListener { task -\u0026gt; if (task.isSuccessful) { // After config data is successfully fetched, it must be activated before newly fetched values are returned. remoteConfig.activateFetched() } } } private fun getCacheExpirationSeconds(isDevModeEnabled: Boolean): Long = if (isDevModeEnabled) ONE_SECOND else ONE_HOUR } Then we expose a new function on the RuntimeBehavior to refresh all remote feature flag providers at the same time whenever you want in your app lifecycle.\nobject RuntimeBehavior { fun refreshFeatureFlags() { providers.filter { it is RemoteFeatureFlagProvider }.forEach { (it as RemoteFeatureFlagProvider).refreshFeatureFlags() } } } Since Firebase Remote Config internally throttles refresh requests, it\u0026rsquo;s safe to call the refreshFeatureFlags method on every app resume.\nThe RemoteFeatureFlagProvider offers the generic ability to refresh values for all remote feature flagging tools.\nTesting feature flags # During automated unit or espresso tests, you sometimes need to enable/disable particular features. Even that is simple with this architecture, just make a TestFeatureFlagProvider:\nobject TestFeatureFlagProvider : FeatureFlagProvider { private val features = HashMap\u0026lt;Feature, Boolean\u0026gt;() override val priority = TEST_PRIORITY override fun isFeatureEnabled(feature: Feature): Boolean = features[feature]!! override fun hasFeature(feature: Feature): Boolean = features.containsKey(feature) fun setFeatureEnabled(feature: Feature, enabled: Boolean) = features.put(feature, enabled) fun clearFeatures() = features.clear() } With its TEST_PRIORITY it takes precedence over all other FeatureFlagProviders and exposes an API to dynamically enable/disable features and to clear its state after each test.\n@Test fun withFeatureFlags() { TestFeatureFlagProvider.enableFeature(DARK_MODE) // do test here } @After fun tearDown() { TestFeatureFlagProvider.clearFeatures() } And this extra provider gets added during the debug initialization in the RuntimeBehavior:\nobject RuntimeBehavior { @VisibleForTesting internal val providers = CopyOnWriteArrayList\u0026lt;FeatureFlagProvider\u0026gt;() fun initialize(context: Context, isDebugBuild: Boolean) { if (isDebugBuild) { val runtimeFeatureFlagProvider = RuntimeFeatureFlagProvider(context) addProvider(runtimeFeatureFlagProvider) addProvider(TestFeatureFlagProvider) if (runtimeFeatureFlagProvider.isFeatureEnabled(TestSetting.DEBUG_FIREBASE)) { addProvider(FirebaseFeatureFlagProvider(true)) } } else { addProvider(StoreFeatureFlagProvider()) addProvider(FirebaseFeatureFlagProvider(false)) } } } The TestFeatureFlagProvider allows to turn FeatureFlags or TestSettings on during unit/instrumentation tests.\nPutting it all together # When we look at all of the classes involved we get the following overview:\nWhile that might seem a bit overwhelming, it consists of a lot of very small classes that are very easy to understand:\nRuntimeBehavior: to easily consume feature flags FeatureFlagProvider: to provide values during debug, release or testing Feature: one-line definition of FeatureFlags or TestSettings And based on these classes, a local UI is automagically generated to toggle the Features on/off in debug builds!\nI\u0026rsquo;ve created a full Github sample project where you can see all code in action here\nBonus # When combining this Feature Flag architecture with my previous modularization architecture, all UI classes can be moved to their own feature module test-settings that is only included into the app module for debug builds:\ndependencies { debugImplementation project(\u0026#39;:features:test-settings\u0026#39;) } This does require all feature flag business logic to move to a library module feature-flags, but the end result is a very clean!\nWrap-up # With just a few simple classes we\u0026rsquo;ve been able to build a powerful feature flagging architecture. In that it\u0026rsquo;s very easy to add new features, there is support for both local and remote feature flags, feature flags are testable and a local UI for enabling/disabling feature flags is automatically generated.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"12 September 2019","externalUrl":null,"permalink":"/blog/2019/09/12/featureflagsarchitecture/","section":"Blogs","summary":"Now that we know how feature flags can help us release faster, it\u0026rsquo;s time to dive into the actual implementation details. How can we easily define feature flags?","title":"Feature flags - A successful architecture","type":"blog"},{"content":"","date":"12 September 2019","externalUrl":null,"permalink":"/tags/firebase/","section":"Tags","summary":"","title":"Firebase","type":"tags"},{"content":"Empowered with what feature flags are and why they are useful, let\u0026rsquo;s see how we can actually integrate them into an app. And how can we roll them out to our users?\nThis mini-series will explain the benefits of using feature flags and propose a handy architecture that enables local feature flag configuration, remote configuration, and easy testability.\nIntegrating feature flags # Roughly there are two ways you could use a feature flag: for new features and existing features.\nNew features # Let\u0026rsquo;s start with the easiest way: use feature flags for new features. A new feature typically includes some UI that\u0026rsquo;s either in a new screen (e.g. a complete new tab) or a new part of a screen (e.g. new social provider in login). In these cases the feature flag is usually a single if statement that shows/hides that part of the UI.\nFor instance, at Philips Hue, we built a new feature to configure the start-up behavior of your lights and the feature toggle just showed/hid the menu item that gave access to the feature.\nif (isFeatureEnabled(POWER_ON_BEHAVIOR)) { menuitem.visibility = View.VISIBLE } else { menuitem.visibility = View.GONE } The same principle can also be used for showing an extra tab or an extra UI element that gives access to the new feature. Some features might even require several if statements in several locations, but try to avoid that if you can as that complicates things.\nExisting features # While refactoring existing code, on the other hand, the situation is slightly more complex. In the ideal case, there is an old code path that you simply replace with a new one:\nfun withLegacy() { if (isFeatureEnabled(LOGIC_REFACTOR)) { var code = NewLogic() code.with(UnitTests()) } else { var code = LegacyLogic() code.with(OutUnitTests()) } } Notice how you need to duplicate existing code before refactoring start! If not, you can no longer toggle the feature off and all the feature flag benefits disappear\u0026hellip;\nIdeally you should do every refactoring behind a feature flag, but the simply isn\u0026rsquo;t practical. Sometimes the overhead of keeping the original code path intact is simply too big for a minor refactoring. Or some code can even be so interconnected that it\u0026rsquo;s impossible to cleanly surround one code path with a feature flag.\nThe best way to handle these cases is to think impact based: if you\u0026rsquo;re refactoring a crucial part of your business logic then you should take more actions to ensure nothing accidentally breaks. This can either be splitting the refactoring into several small steps (and shipping them), using a feature flag or both.\nTo give you an example, at Philips Hue we replaced our Geofence implementation with a new one a while ago. Here the IntentService handling the geofence starts with an if statement that runs either the old or new code. Note that there are also extra analytics in place to monitor and compare the behavior.\nclass GeofenceIntentService : IntentService() { override fun onHandleIntent(intent: Intent?) { if (isFeatureEnabled(GEOFENCE_REWRITE)) { GeofenceRewrite.onHandleIntent(intent) } else { LegacyGeofence.onHandleIntent(intent) } } } Rollout # What would you choose: a big bang feature release to all users or gradually rolling out a feature? Well, thanks to the first post we know the second option is a lot less risky.\nIn reality, however, your marketing department might want to create some buzz around the newly launched feature. In that case, you must do a big bang roll out to all users or some users reading the announcement wouldn\u0026rsquo;t have access to the feature yet!\nTo combine the best of both worlds, you can strive to roll out as many features as possible in a gradual fashion. That typically applies to:\nsmall new features (e.g. more stock images) refactoring of critical business logic (e.g. geofence IntentService rewrite) rewrites of existing features (no visible change to the users) A key aspect in doing this successfully is adding extra analytics events, defining clear KPIs and putting a dashboard in place to monitor everything.\nIn the above dashboard, the performance of both old and rewritten features is measured. The Y-axis indicates how many users successfully completed the feature and the X-axis shows how long it took them to complete it. Here the rewritten feature clearly outperform the old feature and we should fully remove the old one in the next release.\nWhen you can\u0026rsquo;t roll out a feature gradually, you can still derisk its launch using remote feature flags. Just make sure to wrap up feature development early so you have time to use a remote feature flag to test it in your beta community. This allows learning how the code behaves in the wild, while still allowing you to promote that exact build to production (with feature flag turned off).\nOnce confident that the feature works well in beta, you can hardcode the feature flag to be on in the next app release. Better to still leave both code paths in your code base at this stage though, that still provides an easy way to hotfix, you never know. Once the code is behaving properly in production, you can remove the old code path.\nFinally, note that it\u0026rsquo;s crucial to roll out features as quickly as possible. This is because feature flags can create a lot of confusion around what feature flags are \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo; in production and after a while you can even get dependencies between different feature flags! Like always releasing fast is key to reducing the complexity, followed by a swift clean up of rolled out feature flags.\nWrap-up # Feature flags can help in releasing new features and improvements on existing functionality. Always try to roll out features gradually, if that\u0026rsquo;s not possible, rely on your beta community to test the feature prior to release,\nMake sure you follow me on Mastodon or continue to part 3 to learn more about an architecture to integrate feature flags into your app.\n","date":"20 August 2019","externalUrl":null,"permalink":"/blog/2019/08/20/featureflagshowtouse/","section":"Blogs","summary":"Empowered with what feature flags are and why they are useful, let\u0026rsquo;s see how we can actually integrate them into an app. And how can we roll them out to our users?","title":"Feature Flags - How to use","type":"blog"},{"content":"","date":"20 August 2019","externalUrl":null,"permalink":"/tags/software-engineering/","section":"Tags","summary":"","title":"Software Engineering","type":"tags"},{"content":"","date":"20 August 2019","externalUrl":null,"permalink":"/tags/tools/","section":"Tags","summary":"","title":"Tools","type":"tags"},{"content":"A key ingredient to speed up modern software development is feature flags. But what is a feature flag precisely? Why should you care about them? How do you integrate them into your codebase? And how can we make them easy to use?\nThis mini-series will explain the benefits of using feature flags and propose a handy architecture that enables local feature flag configuration, remote configuration, and easy testability.\nWhat is a feature flag # In essence, a feature flag is simply a Boolean that determines whether something is \u0026ldquo;on\u0026rdquo; or \u0026ldquo;of\u0026rdquo;:\nif (isFeatureOn) { // give access to something } else { // prevent access to something } This \u0026ldquo;something\u0026rdquo; can be many things:\na new user-facing feature in your app (e.g. enable dark theme) a non-user-facing feature (e.g. new analytics provider) a replacement for existing feature (e.g. rewrite of some screen) a refactoring of business logic (e.g. conversion of SQL to Room) \u0026hellip; Basically, a feature flag decides whether a particular code path will be executed or not. As such it can make both very small (e.g. new button color) as very large things (e.g. new multi-screen feature) available to users. The mechanics are always the same.\nThere are two types of feature flags: static and dynamic.\nA static feature flag gets hardcoded into the app at build time and hence you decide during compilation what will be \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo;. Because of its inflexibility at runtime, it\u0026rsquo;s benefits are mostly limited to the development process itself.\nA dynamic feature flag, on the other hand, can still be changed at runtime. This happens either via a secret settings screen in the debug variant or via a remote tool (e.g. Firebase Remote Config) when the app is in production. This enables some very interesting use cases such as gradual feature rollout and A/B testing.\nFinally, note that feature flags don\u0026rsquo;t affect the code that is bundled into your app binary! All they do is change the code path that is executed. This is in contrast to tools like ProGuard that can actually strip out parts of your code.\nWhy use feature flags # The key benefit of using feature flags is that they decouple development from app releases. This means two things:\nfeatures can be merged before they are fully implemented fully implemented features can remain hidden until you are ready to release them. First and foremost, feature flags help developers because incomplete features can be merged! This allows to split a feature into many small increments and merge those branches one by one.\nThese smaller branches aren\u0026rsquo;t just easier to review (fewer files), but they are also easier to merge. This is because their difference with master is small causing a lot less merge conflicts. When merging is painless, it will happen more often and hence development will speed up.\nSecondly, feature flags also help with releasing. In the old days, an app release could get blocked when finding a last-minute issue on a new feature. Thanks to feature flags, this can no longer happen! If a feature isn\u0026rsquo;t fully ready, it can just be temporarily disabled.\nEven more, when a feature is ready to ship, you no longer have to do a big bang roll out to all users. Instead, you can gradually roll out and make a data-driven decision on to roll out further or maybe even roll back! That dramatically de-risks rolling out new features. At Philips Hue, we recently rewrote one of our most important screens and rolled it out over 10 days to make sure users weren\u0026rsquo;t negatively impacted.\nAlso, there are commercial benefits: time-critical new features can be built ahead of time and only made available when you are ready to announce them. This was especially useful at Philips Hue where we need to time app launches together with new product introductions (e.g. a new lamp or accessory).\nFinally, improvements to new features can be built side by side the old feature and using A/B tests you can then decide which feature should remain. This allows optimizing user engagement in your app.\nBenefits of feature flags:\nspeed up development by integrating incomplete features allow releasing when a new feature is not yet ready enable to derisk releases using gradual feature rollout enable roll back when production issue found in feature time the release of new features to the market enable A/B testing Requirements of good feature flags # Now that we know that feature flags can be quite useful, let\u0026rsquo;s take a minute and think about what we need to make feature flags work.\nFirst and foremost: it must be incredibly easy to add a new feature flag. The easier that is, the more you will do it and the more you\u0026rsquo;ll benefit from them. In the next posts, we\u0026rsquo;ll see how we can define feature flags using one single line of code!\nNext, we need to be able to toggle feature flags both locally and remotely. For developer (debug) builds, you want predictable, easy access to feature flags. Hence there should be some screen in the app where you can see the current state of all feature flags and toggle them. Ideally, this UI should even be auto-generated.\nOn the other hand, for production (release) builds, you want to be able to remotely toggle the feature flags. Hence they should also be remotely available, which is typically provided by a framework like Firebase Remote Config.\nIn terms of feature flag values, we are going to restrict ourselves to just boolean flags. Having binary values keeps things simple, both from a development perspective as conceptually: something is either on or off. Using many feature flags can already be quite confusing with just binary values, let alone if strings or integers are allowed. This simplification also allows to elegantly generate the UI for our feature flags later on.\nWe do need more than just feature flags though! Apps typically also have a dynamic configuration that you only use in the debug build type: logging, leak canary, espresso idling resources, development backend, bypass onboarding, simulate a crash\u0026hellip; All of these are \u0026ldquo;test settings\u0026rdquo; that facilitate testing or debugging your app. Wouldn\u0026rsquo;t it be nice if you could also turn these on or off using a built-in UI?\nTests settings don\u0026rsquo;t just ease development and testing, but they also reduce the need to build flavors. Instead of having a separate flavor for leak canary or logging or espresso idling resources or \u0026hellip; these now become a configuration that you can turn on or off on demand!\nThis allows having predictable debug builds that never behave differently due to a remote feature flag change (that would also cause test flakiness). And at the same time enables to turn the remote feature flagging on to actual test whether remote feature flags still work.\nContrary to feature flags, test settings are long-lived and are never shipped directly to users.\nFinally, we should be able to easily toggle feature flags on/off in automated tests and we don\u0026rsquo;t want to lock ourselves into a particular framework. So it should be easy to swap to a different remote feature flag tool later on.\nWrapping it all up, feature flags should be:\nvery easy to add locally and remotely available binary in value cater for both features and test settings configurable for automated tests agnostic of the used remote feature flag tool Wrap-up # Feature flags are an incredibly powerful tool to speed up development: they allow to merge incomplete features and derisk app release by allowing gradual rollouts. They should be incredibly easy to add, usable in automated tests and you should be able to toggle them remotely for production use and locally for development and testing.\nMake sure you follow me on Mastodon and read on in part 2 that covers how you can use and release feature flags.\n","date":"13 August 2019","externalUrl":null,"permalink":"/blog/2019/08/13/featureflags/","section":"Blogs","summary":"A key ingredient to speed up modern software development is feature flags. But what is a feature flag precisely? Why should you care about them? How do you integrate them into your codebase?","title":"Feature Flags - Why you should care","type":"blog"},{"content":"Three years ago, we decided ramp up internal app development at Philips Hue. After interviewing candidates (78!) for six months, I became the lead Android developer of the freshly hired Android team.\nIn this non-tech post (for a change), I\u0026rsquo;d like to openly share my experiences being a team lead. It\u0026rsquo;s been a bumpy ride, but I came out with quite some new perspectives that make me a stronger lead and a better person.\nPart 1: Team and project # To put my experiences into perspective, I think it\u0026rsquo;s important to first cover the team set up, my role and some of the project history.\nFeel free to skip this part and jump to the learnings instead 👇!\nTeam setup and my role # Our team was a component team, responsible for building the Philips Hue Android app. Consisting of both quality assurance (QA) and developers, the team size was significant.\nNow to be clear, I wasn\u0026rsquo;t the team manager and hence didn\u0026rsquo;t do many typical managers related activities:\nI didn\u0026rsquo;t ensure people follow corporate processes (e.g. time writing) I didn\u0026rsquo;t make practical arrangements for people (e.g. order hardware) I didn\u0026rsquo;t approve leave/conferences/\u0026hellip; I didn\u0026rsquo;t do evaluation and career planning meetings \u0026hellip; This was a very deliberate choice to be a part of the team instead of boss-of, I strongly wanted to stay on the technical career path.\nI write code, not manage people.\nInstead, my role was to write code (!), drive the Android app structurally forward (tech debt/architecture) and coach team members to help them grow.\nA rough start # From day one, the project was met with many different challenges.\nFirst of all, the existing source code stemmed from our start up days and had a very weak architecture with a very high coupling between classes. Hence, refactoring often created side effects in other parts of the code.\nHow on Earth do we make this app better if every change we make has unintended side effects?\nTo make matters worse, this happened at a time where the tech stack on Android was changing rapidly: Kotlin, architecture components, modularization, RXJava\u0026hellip; So which one of these should we adopt? How do we build up the knowledge in the team? And with which one do we start?\nHow on Earth do we make this app better if we don\u0026rsquo;t know where to start?\nSecondly, our build infrastructure was slow and unstable. These slow and flaky builds made it very painful to integrate new changes. On top of that, we had the habit of creating extremely huge pull requests (for various reasons) which were nearly impossible to review.\nHow on Earth do we make this app better if integrating pull requests is tedious?\nThirdly, the Philips Hue business was incredibly ambitious and wanted features to be delivered fast. This resulted in many projects being executed in parallel (including a full app UI makeover by a different team!). But as a team, we were still struggling to agree on a future vision/architecture for the app.\nHow on Earth do we make this app better if we can\u0026rsquo;t agree on a clear architecture vision?\nAnd to make matters worse, we didn\u0026rsquo;t have a grip on the app quality! Hence a lot of slow manual testing was required that would find a lot of regression bugs. These bugs would often be found late, making it very difficult to fix them without breaking something else.\nHow on Earth do we make this app better if we struggle to release?\nFinally, we had chosen to refactor our app instead of rewriting it. But because of the sheer amount of technical depth we had this refactoring was only providing limited results. For sure our codebase was (slowly) improving, but to put it bluntly, the results weren\u0026rsquo;t motivating the team.\nHow on Earth do we make this app better if people lose their motivation?\nPart 2: Lessons learned # While we managed to solve all of these challenges (and more), I don\u0026rsquo;t want to cover the solutions to these in this post. Rather I\u0026rsquo;d like to talk about what I learned as a lead along the way as these learnings will be more universally applicable.\n1. Acknowledge the bad # All of these challenges were frustrating people\u0026hellip; and with reason. However, as a team, this pushed us into a negative, complaining mode which wasn\u0026rsquo;t very motivating either. Arguably, complaining was even making it worse\u0026hellip; even causing a downwards spiral.\nOn the other hand though, we were making things better and being able to successfully push back on many business decisions that would have made our lives even more challenging.\nAs the negative was clearly overshadowing the positive, I always tried to spin it positively and emphasize our successes (as small as they may have been). And the harder people complained, the more I tried to spin it\u0026hellip;\nBut despite my good intentions however, in my spinning I came across as dismissive of other people\u0026rsquo;s complaints. It\u0026rsquo;s not because we had a few minor successes that all our other challenges weren\u0026rsquo;t real anymore. Even worse, I made people feel as if they didn\u0026rsquo;t have the right to complain.\nLearning 1: When something is bad or someone complains, acknowledge it and empathize. People have the right to complain. Stuff sometimes simply sucks. Once the dust settles down, try to open a constructive conversation on how to make things better. One of my favorite questions here is: \u0026ldquo;What will we do differently tomorrow to make this better?\u0026rdquo;\n2. Focus on your happiness # Another thing I used to do is try and shield the team from all distractions that were happening around them. So I would attend the reporting meetings, write all documentation myself, pick up the dull tasks nobody else wanted to do,\u0026hellip; All just so the team could do what they love doing most: writing awesome code!\nHowever, by always putting myself last I wasn\u0026rsquo;t getting a lot of job satisfaction anymore. Being overloaded with \u0026ldquo;dull work\u0026rdquo; wasn\u0026rsquo;t just demotivating, but by not involving others you also miss the opportunity to get their buy-in. For instance, if you document something, others will be more inclined to keep the documentation up to date if they co-authored it in the first place.\nAnd it turns out that having low energy levels myself, also influences how I\u0026rsquo;m able to impact the rest of the team. So I decided to drop quite a few of my tasks or delegate them to others so that I could also focus on writing more code. This brought me closer to the team, made me feel happier and increased my energy level to empower people to drive things forward.\nLearning 2: You can\u0026rsquo;t do your job well if you\u0026rsquo;re low on energy, make sure to also do challenging/exciting tasks. Examples of tasks I delegated are architecture documentation, architecture plans, attending feature team meetings, redirect external questions to other team members, giving access to tools, high-level estimations\u0026hellip;\nExamples of tasks I stopped doing: one on ones. That was a tough decision, but at some point, I realized that trying to help individual members in the team wasn\u0026rsquo;t helping the team as a whole. Instead, I created a culture where any one from the team could interrupt me and ask questions at any time.\nI do want to stress that helping team members was always my highest priority and I would instantly drop anything to help them out. However, doing structural one on ones was the responsibility of their manager.\n3. Be transparent # As part of my role I had quite some non developer related work, whether it was reporting to upper management, early-stage planning of new features, aligning between teams, high-level estimates\u0026hellip;\nUsually, I didn\u0026rsquo;t want to bother the team with this information. E.g. My thinking was that people could feel extra pressured once they knew management was asking for regular status updates.\nThere are actually two big drawbacks doing so:\nIf you don\u0026rsquo;t tell people what\u0026rsquo;s up, they will start assuming themselves. My stand up reports often made it look like I wasn\u0026rsquo;t doing anything. So instead I decided to just be completely open and transparent about everything. Even top-level decisions like: \u0026ldquo;we need to let go of some of our (contractor) team members\u0026rdquo; or \u0026ldquo;management isn\u0026rsquo;t happy with the current speed of development\u0026rdquo;, I would communicate as quickly and openly as possible and offer people to ask any questions about it.\nTo give you an idea of how far I took this: I even disclosed to my team that I felt I struggled in my role and decided to find some help. So, one day, during stand up I shared that I started following coaching to do my job better and that I would be spending a considerable amount of time doing so.\nOpening up like that made me feel very vulnerable (and my direct approach definitely surprised some team members). But the team really appreciated the openness and respected me for taking my job seriously.\nLearning 3: Be open and transparent, especially about bad news or difficult matters. Openness is a key cornerstone of building trust between people. 4. Lead by example # During our standup, I would say I was going to do X, but because I had so many interruptions and meetings, I often never got around to actually doing it. This was especially inconvenient during times where we struggled to get things done and make our codebase better.\nActually, this even made it seem like special rules applied to me! How can I expect us as a team to deliver on our committed work if I don\u0026rsquo;t deliver on my commitments myself?\nLearning 4: Exhibit the good behaviors yourself that you expect from others. While this is (in retrospect) my most obvious learning, in practice it hit me quite hard when I got this feedback\u0026hellip; But I learned and even though it was hard to turn around, I now deliver on what I say I will. Which, in my case, involves saying no or postponing/delegating other work.\n5. Team building # Something I strongly believe in is that a happy team is (almost) all you need to be successful as a team. When people are having fun and get fulfillment from their work, they take pride and ownership in what they do and will do things right.\nOne very important aspect of that is to ensure that people also hang out in a non-work context. This doesn\u0026rsquo;t just build trust between them, but it also increases the fun!\nAnd this can be done in very simple ways! I would trigger the team at least once per week to all walk over to the coffee bar on our campus together. Or we also organized cultural lunches (as we have a lot of different nationalities in the team), where a team member would book lunch in a restaurant the country of origin.\nGetting closer together as a team increased the trust between people and the fun we were having. To me this is probably the biggest reason why we ended up being successful. We managed to fully integrate testers and developers, everyone took their share of dull work and we made everyone jointly accountable for app quality.\nLearning 5: Focus on the fun, plan regular activities that bring people closer together. It doesn\u0026rsquo;t need to be big: small ad hoc events during work time work really well. Interestingly, \u0026ldquo;building a team\u0026rdquo; wasn\u0026rsquo;t part of my original role. Over time though, I realized that this is also a key part of being a lead. However, I made sure not to organize most events myself, I just made sure someone was.\n6. Leverage the power of the team # There\u0026rsquo;s so much more that you can get done as a team than you can accomplish by yourself. So don\u0026rsquo;t be afraid to ask team members for help, advice and even delegate things.\nSure, the delegated work doesn\u0026rsquo;t get done exactly as you would have done it, but that\u0026rsquo;s exactly the strength! At the very least it\u0026rsquo;s an opportunity to coach and help a team member. Whereas at the other end of the spectrum the result is way better than what you would have done in the first place. E.g. I was blown away by the business case one of our testers made to scale up our Firebase test lab tests to more devices.\nWhat might seem dull to you (as you\u0026rsquo;ve done it so many times), could actually be an opportunity for another team member, a way for them to step up and take on more responsibility.\nI’ve learned that my team is really the most valuable asset I have as a lead, as such they are also the primary indicator to tell me how things are going.\nBut how can I know that I\u0026rsquo;m being a good lead? Is there maybe something I could do better? Or even… what does the team expect their lead to do in the first place? Well… just ask them.\nI asked my team a while ago what they expected me to do (see below) and interestingly enough, nobody expected me to solve our technical problems. Instead, they wanted me to facilitate decision making and ensure we have a clear architecture goal to work towards.\nSo I took their advice and changed my priorities.\nLearning 6: Leverage the power of the team, they can help you get more things done and have valuable insights about the project and your role. 7. Have faith # To be fair, my tenure as a lead developer definitely wasn\u0026rsquo;t a walk in the park. The legacy code and inconvenient timings of internal projects proved to be a real challenge and strongly affected our team mindset. And once a team gets in a negative vibe, it is very hard to turn that around.\nPersonally, I struggled with this for quite some time and tried hundreds of ideas to make things better. One of such was biweekly workshops to learn something new. This came from the insight that different team members felt they weren\u0026rsquo;t learning enough. That ended up boosting team spirit and accelerating our Architecture components, RXJava, and Kotlin adoption.\nBut in the end, I, no matter how hard I tried, I wasn\u0026rsquo;t able to turn things around fast enough\u0026hellip; And frankly, we lost quite some amazing developers along the way. Seeing people leave as a lead is\u0026hellip; well\u0026hellip; very painful.\nI\u0026rsquo;m very happy to have reached out for help and to have found a great coach. For six months, we did monthly sessions which I prepared and took homework from. And that opened my mind to a lot of different perspectives and exposed me to even more of my own flaws.\nThanks to the coaching, my always positive attitude and a lot of perseverance, we managed to book our first successes:\nMove over to biweekly releases Start using Architecture components \u0026amp; Kotlin Get a stable set of Espresso tests And funny thing, because of these successes, people actually slowly but surely started to believe! Almost like a self-fulfilling prophecy we were able to stack up success after success:\nBuild, test and upload releases in under 12 min Rewrote the key screens of our app Dramatically sped up app startup Decreased app size by 65% over 30 modules and 35% Kotlin close to 200 stable integration tests \u0026hellip; Learning 7: getting to a cohesive, highly performant and fun team can be quite challenging. But have faith, stay positive, persist and reach out for help. Together as a team, you can do this!\nLearning 7: Getting to a cohesive, highly performant and fun team can be quite challenging. But have faith, stay positive, persist and reach out for help. Together as a team, you can do this! *. Other learnings # To keep the length of this post under control, I\u0026rsquo;m just going to briefly mention my runner-up learnings:\nRefactoring isn\u0026rsquo;t a very motivating activity ➡️ We tackled this by splitting our app in modules (\u0026ldquo;vertical slices\u0026rdquo;). This allows to aggressively rewrite parts of our app or isolate legacy code in dedicated modules. Avoid rehashing the same discussions over and over ➡️ We tackled this by very concisely documenting decisions and their rationale. Next time we would start rehashing the same discussion, I would intervene and say: \u0026ldquo;last time we decided this for that reason, do we have any new insights to reopen this discussion?\u0026rdquo; All team members are equal ➡️ Doesn\u0026rsquo;t matter whether they are contractors or on the payroll, anyone gets the same opportunity to make their mark on the project and gets proper feedback and support from me. ➡️ Also as a team lead I don\u0026rsquo;t have any more to say than any other developer, nor do they have any more to say than one of our QA engineers. We are all jointly accountable for app quality and releasing on time. Either we all fail or success together. Celebrate success ➡️ It\u0026rsquo;s so easy to get dragged along in the day to day operations that you fail to appreciate what you accomplish as a team. Therefore I keep a dedicated confluence page where I keep track of every success (e.g. high app version rating, sped up app startup,\u0026hellip;). I regularly share this with the team (on Slack) and even the rest of the organization. Leverage existing solutions ➡️ While tackling our technical challenges, we cooked up some custom solutions to already solved problems (e.g. a custom MVP implementation optimized for A/B testing). But this introduced a lot of complexity and increased the learning curve. Eventually, we just settled with vanilla Android architecture components, a simple solution that worked well out of the box. It\u0026rsquo;s totally fine not to do things ➡️ Quite regularly, we would say we were going to do a particular thing (e.g. more pair programming), but we never ended up doing it. That\u0026rsquo;s totally fine. A key reason why some things don\u0026rsquo;t happen is often that people don\u0026rsquo;t fundamentally believe in them, but instead think we should do them to please others. Well, you shouldn\u0026rsquo;t. Just try to be open and explicit about what you actually will and won\u0026rsquo;t do. What\u0026rsquo;s next # With everything we\u0026rsquo;ve learned building our mobile engineering culture at Philips Hue, we\u0026rsquo;ve got some very exciting stuff in the pipeline. Make sure to follow the Philips Hue engineering medium to catch it!\nWrap-up # Two years in being a team lead, I\u0026rsquo;m incredibly proud of what we accomplished as a team: we can release ridiculously fast, dramatically improved our codebase, streamlined our processes and increased our output by a factor of 4x. This isn\u0026rsquo;t just visible in the joy/pride the team takes in working on our app, but user sentiment is also going up fast.\nWe\u0026rsquo;re on track to hit our original team goal that we set 2 years ago of being a 4 ⭐️ rated app (4.4!) in August! The ride to get there was rough though and despite my good intentions, I made many mistakes. However, by keeping on investing in the team and myself we were able to get our app on track!\nOne of my long open career goals was to work in a high performant team on a world-class product. And I\u0026rsquo;m happy to say that I can now finally check that box!!! Though, I didn\u0026rsquo;t expect to be leading that team.\nHopefully, you liked this honest retrospective, feel free to leave a comment below or follow me on Mastodon.\n","date":"6 August 2019","externalUrl":null,"permalink":"/blog/2019/08/06/lessonsleaddeveloper/","section":"Blogs","summary":"Three years ago, we decided ramp up internal app development at Philips Hue. After interviewing candidates (78!) for six months, I became the lead Android developer of the freshly hired Android team.","title":"Lessons learned being a lead developer","type":"blog"},{"content":"","date":"6 August 2019","externalUrl":null,"permalink":"/tags/lessonslearned/","section":"Tags","summary":"","title":"Lessonslearned","type":"tags"},{"content":"","date":"6 August 2019","externalUrl":null,"permalink":"/tags/team-lead/","section":"Tags","summary":"","title":"Team Lead","type":"tags"},{"content":"","date":"17 July 2019","externalUrl":null,"permalink":"/tags/androidq/","section":"Tags","summary":"","title":"Androidq","type":"tags"},{"content":"","date":"17 July 2019","externalUrl":null,"permalink":"/tags/gestures/","section":"Tags","summary":"","title":"Gestures","type":"tags"},{"content":"","date":"17 July 2019","externalUrl":null,"permalink":"/tags/navigation/","section":"Tags","summary":"","title":"Navigation","type":"tags"},{"content":"From Android Q onwards devices can now operate in a fully gestural system navigation mode. In that mode, there is no longer an on-screen back button, instead users can swipe from both edges to navigate back.\nIn this blog post, we\u0026rsquo;ll look at a case study on how we added support for these back gestures in the Philips Hue app.\nUnique Challenge # At Philips Hue we\u0026rsquo;ve heavily optimized the information density so users can control the maximum amount of rooms/zones (cards) within one screen:\nThere are three main optimizations we made to allow the maximum amount of cards to fit:\nThe brightness slider is aligned with the bottom of the card Card height is smaller when a room/zone is off Brightness slider only responds to swiping the thumb, not clicking on a position in the slider. This is done to avoid confusion when clicking on the card to enter a room/zone. Let\u0026rsquo;s investigate how these created some unique challenges to prepare our app for Android Q gesture navigation.\nEdge to edge Brightness sliders # To start, as the cards go nearly edge to edge, moving the bottom aligned brightness slider isn\u0026rsquo;t possible when the thumb is near the min or max. Instead, the back gesture is triggered:\nFortunately, Android Q offers a way to tell the Android system that it shouldn\u0026rsquo;t intercept gestures in a particular area of the screen using setSystemGestureExclusionRects:\nbrightnessSlider.doOnLayout { val exclusions = listOf( Rect(0, 0, exclusionWidth, it.height), // min area Rect(it.width - exclusionWidth, 0, it.width, it.height) // max area ) ViewCompat.setSystemGestureExclusionRects(brightnessSlider, exclusions) } In the example above, we exclude both the minimum and maximum area of the brightness slider from navigation gestures.\nImportant to know is that you should define the systemGestureExclusionRects in coordinates relative to the View/ViewGroup you are applying the exclusion Rects on!\nIn the example above we apply them on the brightness slider so we use coordinates relative to the slider (notice the use of width and height). But we can also apply the exclusion to the parent (notice the use of left and right):\nparent.doOnLayout { val exclusions = with(brightnessSlider) { listOf( Rect(left, top, exclusionWidth, bottom), // min area Rect(right - exclusionWidth, top, right, bottom) // max area ) } ViewCompat.setSystemGestureExclusionRects(parent, exclusions) } At any rate, we can only apply the exclusion Rects once the view is laid out, hence we wrap the setSystemGestureExclusionRects with the awesome doOnLayout method from Android KTX.\nTo get the width of the exclusion area exclusionWidth, we should add an OnApplyWindowInsetsListener and ask the returned insets for the getSystemGestureInsets. There is one problem though: this listener is only called when the edge to edge system UI flags (View.SYSTEM_UI_FLAG_LAYOUT_FULLSCREEN) are set!\nSo as an alternative we can take the WindowInsets from the root view, which can easily be done in the following way:\nseekbar.doOnAttach { val insets = WindowInsetsCompat.wrap(view.rootWindowInsets) val minExclusionWidth = insets.systemGestureInsets.left val maxExclusionWidth = insets.systemGestureInsets.right applySystemGestureExclusionRects(minExclusionWidth, maxExclusionWidth) } Note that doOnAttach and WindowInsetsCompat.wrap() have yet to be released in an upcoming support library\nFinally, note that you need to use at least androidx.core version 1.2.0 or higher in order for the ViewCompat setSystemGestureExclusionRects API) to be available. If you\u0026rsquo;re not ready to jump on 1.2.0 yet, you can always surround it with an API level check (make sure to use compile SDK Q).\nif (Build.VERSION.SDK_INT \u0026gt;= Q) { val exclusions = with(brightnessSlider) { listOf( Rect(0, 0, exclusionWidth, height), Rect(width - exclusionWidth, 0, width, height) ) } brightnessSlider.setSystemGestureExclusionRects(exclusions) } Exclusion limitations # Android Q will only excluding a maximum of 200dp from each edge from back navigation (effective from Q beta 6 onwards). Otherwise, apps could exclude both full edges and completely break the back navigation.\nUnfortunately, this creates a problem for us as our screen can show up to 8 cards at any given point in time. Hence we would require almost double the allowed maximum assuming our brightness slider has a 48dp height!!!\nRequesting too much area exclusion area will cause the topmost cards not to have any exclusion as Android grants the exclusions from bottom to top:\nSo how do we solve this?\nFirst of all, the thumb of the brightness slider can only be at one edge at any given point in time, so the very first thing we can do is only exclude a brightness slider edge when the thumb is there:\nbrightnessSlider.doOnLayout { if (isThumbNearMin()) { ViewCompat.setSystemGestureExclusionRects(it, getMinExclustionRect()) } else if (isThumbNearMax()) { ViewCompat.setSystemGestureExclusionRects(it, getMaxExclusionRect()) } else { ViewCompat.setSystemGestureExclusionRects(it, emptyList()) } } This doesn\u0026rsquo;t just improve the user experience (by supporting back gestures on most cards), but it also significantly reduces the likelihood that we request more than the max exclusion area. Only when more than 5 cards are at full brightness or minimum brightness we would still exceed!\nSecondly, when cards are off (and the brightness slider is at 0 alpha), we also shouldn\u0026rsquo;t ask for any exclusions of such a slider:\nif (!switch.checked) { ViewCompat.setSystemGestureExclusionRects(brightnessSlider, emptyList()) } The end result is pretty neat:\nWhen thumb is near max/min: you can swipe back from the opposite edge When thumb is not near max/min: you can swipe back from both edges Crosstalk with brightness sliders # Unfortunately, all isn\u0026rsquo;t good just yet, because in very rare cases back navigation would still accidentally cause onTouchEvent of our custom brightness slider to also be called:\nImagine a user opening our app, lowering the brightness of a room and then navigating back just to see the brightness jumping back to 100% right before the app exits\u0026hellip; infuriating!\nTo fix this we decided to detect whether a swipe gesture is being performed near the min/max of the brightness slider while the thumb isn\u0026rsquo;t there. In that case, the system should handle the back gesture and we should ignore the touch:\nprivate fun isTouchInterferingWithBackNavigation(touchX: Float): Boolean { if (Build.VERSION.SDK_INT \u0026lt; Q) return false val positionOnSlider = (getProgressForXPosition(touchX) - min).toFloat() / (max - min) val slideGestureNearMinNotOnThumb = positionOnSlider \u0026lt; 0.1f \u0026amp;\u0026amp; !isThumbNearMin val slideGestureNearMaxNotOnThumb = positionOnSlider \u0026gt; 0.9f \u0026amp;\u0026amp; !isThumbNearMax return slideGestureNearMinNotOnThumb || slideGestureNearMaxNotOnThumb } Ignoring the touch is as easy as just returning false in the onTouchEvent method:\nwhen (ev.getAction() and MotionEvent.ACTION_MASK) { MotionEvent.ACTION_DOWN -\u0026gt; { if (isTouchInterferingWithBackNavigation(x)) { return false } ... } Note that this does impact the UX of our brightness slider as touch only works near the edges when the thumb is there. But this is a trade-off we made to avoid the thumb from accidentally jumping to the wrong position while navigating back.\nFinally, we have the exact behavior we were looking for!\nWrap-up # Android Q gesture navigation will impact how users interact with our apps. For most apps, this should work out of the box, but in rare cases, the system gesture exclusion API can help whitelist parts of your app where touch is required to work near the edges.\nFollow me on Mastodon to get notified when I post more interesting content! Feel free to leave a comment below.\n","date":"17 July 2019","externalUrl":null,"permalink":"/blog/2019/07/17/androidqgestures/","section":"Blogs","summary":"From Android Q onwards devices can now operate in a fully gestural system navigation mode. In that mode, there is no longer an on-screen back button, instead users can swipe from both edges to navigate back.","title":"Supporting Android Q gestural navigation","type":"blog"},{"content":"","date":"17 July 2019","externalUrl":null,"permalink":"/tags/ui/","section":"Tags","summary":"","title":"Ui","type":"tags"},{"content":"","date":"3 July 2019","externalUrl":null,"permalink":"/tags/adaptive-icon/","section":"Tags","summary":"","title":"Adaptive Icon","type":"tags"},{"content":"Your icon is one of the most important assets in your app. With a bit of luck, users might even put it on their main launcher screen!\nAs various Android launchers, versions or devices might resize/reshape your icon to make them look consistent, you\u0026rsquo;ll need to be robust against this kind of changes. Learn how we did that at Philips Hue.\nBackground # For various years, different device manufacturers have been reshaping icons to make them fit their custom skin of Android. Unfortunately, there wasn\u0026rsquo;t a clear contract in place to do that reshaping, leading to some pretty bad results:\nShadows overlayed on top of the Philips wordmark, part of the Hue text cut off and a teardrop shape that looked really weird are just a few of the problems.\nFortunately, in Android O, adaptive icons came to the rescue to solve this problem.\nIcon design # Inspired by this blog post from Nick Butcher, we wanted to create a depth effect in our icon. Wouldn\u0026rsquo;t it be cool if our icon could change color just like our lights?\nHence we decided to use a gradient as the background layer:\nNotice how the gradient gets lighter towards the top and darker towards the bottom. It also contains a darker shade of red on the left side and a darker shade of blue on the right.\nThe foreground of the icon, however, consists out of a static blue \u0026ldquo;Philips\u0026rdquo; word mark and a plain white background with \u0026ldquo;Hue\u0026rdquo; cut out from that:\nNow when the icon will be dragged or pressed, the foreground will move independently of the background causing the \u0026ldquo;Hue\u0026rdquo; cutout to hover over different parts of the gradient. This creates a very nice effect where the Hue logo slightly changes colors!\nImplementation # In Android Studio, right-click your project and select \u0026ldquo;New \u0026gt; Image asset\u0026rdquo;.\nFor the best scaling quality and minimal icon size, we use a vector asset as the foreground layer. This wasn\u0026rsquo;t possible for the gradient though due to the complexity of that asset, so for that we use a webp background.\nNotice how both \u0026ldquo;Hue\u0026rdquo; and \u0026ldquo;Philips\u0026rdquo; fit nicely within the safe zone indicated by the circle area. This is the zone that is guaranteed to be always displayed and never cut off.\nMake sure to also generate a round icon for Android N and plain image assets for older Android versions. Click next and review the assets being generated, and finish to complete the icon creation.\nYou\u0026rsquo;ll see that in mipmap-anydpi-v26 two resources get generated ic_launcher.xml and ic_launcher_round.xml. Both these files simply indicate what resource to use for the icon foreground and background:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;adaptive-icon xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34;\u0026gt; \u0026lt;background android:drawable=\u0026#34;@mipmap/ic_launcher_background\u0026#34;/\u0026gt; \u0026lt;foreground android:drawable=\u0026#34;@drawable/ic_launcher_foreground\u0026#34;/\u0026gt; \u0026lt;/adaptive-icon\u0026gt; In the Android manifest you simply reference both resources in order to use them:\n\u0026lt;application ... android:icon=\u0026#34;@mipmap/ic_launcher\u0026#34; android:roundIcon=\u0026#34;@mipmap/ic_launcher_round\u0026#34;\u0026gt; Note: ic_launcher_round.xml got introduced with the launch of the Google Pixel (Android N) and has since been replaced with the more powerful adaptive icon. However you can still provide a rounded icon to avoid that Android N devices show your square item in a round bounding box: End result # Bringing it all together, we now have an icon that not only adapts to any device launcher, but also has a nice subtle color effect on the Hue letters while moving.\nNotice for instance how the letter \u0026ldquo;e\u0026rdquo; changes from green to blue while moving right.\nWrap-up # The launcher icon is one of the most important assets of your app and therefore it is key to make it look perfect on any device. Adaptive icons make that possible and also allow you to add a nice little extra touch to your app.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free to leave a comment below!\n","date":"3 July 2019","externalUrl":null,"permalink":"/blog/2019/07/03/adaptiveicon/","section":"Blogs","summary":"Your icon is one of the most important assets in your app. With a bit of luck, users might even put it on their main launcher screen!","title":"Philips Hue adaptive icon","type":"blog"},{"content":"","date":"12 June 2019","externalUrl":null,"permalink":"/series/modularization/","section":"Series","summary":"","title":"Modularization","type":"series"},{"content":"Wrapping up this series on modularization I\u0026rsquo;d like to share some of the things we\u0026rsquo;ve learned at Philips Hue while going through this process the past year.\nPart five of this series will share quite a few useful tips and tricks for modularizing apps.\nConfiguring modules # In order to drive modularization it\u0026rsquo;s very important to make creating a new module as simple as possible:\nadding a new module must be easy (so it will happen often) maintaining module configurations must be easy Both of these can be accomplished via a nice little trick in the project level build.gradle file (thanks to Olivier Patry for the simplification):\nsubprojects { afterEvaluate { project -\u0026gt; if (project.hasProperty(\u0026#39;android\u0026#39;)) { android { buildToolsVersion Config.buildTools compileSdkVersion Config.compileSdk defaultConfig { minSdkVersion Config.minSdk targetSdkVersion Config.targetSdk testInstrumentationRunner \u0026#34;androidx.test.runner.AndroidJUnitRunner\u0026#34; } compileOptions { sourceCompatibility Config.javaVersion targetCompatibility Config.javaVersion } } } } } The block above will dynamically look for all android or android-library modules and configure the android block with all default values. That way each module will use the same minSdk, buildTools, testRunner, javaVersion,\u0026hellip;\nThis won\u0026rsquo;t just avoid issues like dangerous permissions sneaking into your app, but will also make it very easy to bump the target/minimum SDK and will simplify configuring submodules to just listing the dependencies.\nFor instance the Login feature build.gradle is:\napply plugin: \u0026#39;com.android.library\u0026#39; apply plugin: \u0026#39;kotlin-android-extensions\u0026#39; apply plugin: \u0026#39;kotlin-android\u0026#39; dependencies { implementation project(\u0026#39;:libraries:ui-components\u0026#39;) implementation project(\u0026#39;:libraries:actions\u0026#39;) implementation Deps.androidx_material implementation Deps.androidx_constraintlayout implementation Deps.androidx_navigation_fragment implementation Deps.androidx_navigation_ui testImplementation Deps.testlib_junit androidTestImplementation Deps.testandroidx_runner androidTestImplementation Deps.testandroidx_rules androidTestImplementation Deps.testandroidx_espressocore } No more android{} block required! Also, note that there is no need to specify a release or debug build type block.\nModule graph # While modularizing it\u0026rsquo;s great to keep an eye on the dependencies between different modules. For this, Jake Wharton made a little script that creates a visual overview of your modules.\nTo use it, I recommend downloading the script and adding it to your repository. But you could also simply add the following to your app build.gradle file:\napply from: \u0026#39;https://raw.githubusercontent.com/JakeWharton/SdkSearch/master/gradle/projectDependencyGraph.gradle\u0026#39; Then you can simply run ./gradlew projectDependencyGraph to get a graphical overview.\n\u0026gt; Task :app:projectDependencyGraph Project module dependency graph created at ~/ModularizationExample/build/reports/dependency-graph/project.dot.png Android modules are shown in green, Java modules in pink and Kotlin multiplatform modules in orange.\nOrganize settings.gradle # When adding a new module via Android Studio, by default a new entry is added to the settings.gradle file. This is necessary to inform Gradle that this module will also participate in the build.\nBy default each new module is added to the same line:\ninclude \u0026#39;:app\u0026#39;, \u0026#39;:features:login\u0026#39;, \u0026#39;:features:dashboard\u0026#39;, \u0026#39;:features:sharing\u0026#39;, \u0026#39;:libraries:ui-components\u0026#39;, \u0026#39;:libraries:actions\u0026#39; However, you can also configure each module on it\u0026rsquo;s own line:\ninclude \u0026#39;:app\u0026#39; include \u0026#39;:features:login\u0026#39; include \u0026#39;:features:dashboard\u0026#39; include \u0026#39;:features:sharing\u0026#39; include \u0026#39;:libraries:ui-components\u0026#39; include \u0026#39;:libraries:actions\u0026#39; This keeps the settings.gradle file cleaner and easier to read. But it also avoids clutter in your Git history, because adding a new module will now add a new line instead of modifying an already existing (very long) file at some random place.\nNote: I\u0026rsquo;ve created a feature request for this and this will now be the default behavior from Android Studio 3.6 onwards!\nModule internals # Project organization # When you scale up the number of modules, your root git folder might become quite messy. One convenient way to organize it is to create three different top-level folders: app, features and libraries. This will naturally organize all the modules that you have:\n. ├── app ├── features │ ├── dashboard │ ├── login │ └── sharing └── libraries ├── actions └── ui-components In order to directly generate a module in one of the subfolders, go to File \u0026gt; New \u0026gt; New Module in Android studio and prefix the module name with features: to directly create the module in the features folder.\nAlternatively, you can also create the new module, and drag it to the correct subfolder. In that case, just make sure to also update the module reference in settings.gradle after you do that.\ninclude \u0026#39;:app\u0026#39; include \u0026#39;:features:newfeature\u0026#39; Finally, every module should have a README.md file at its root level explaining in a concise one-liner what that module is supposed to do. That makes navigating the code online (e.g. Github) a breeze.\nPackage names # While the main app package name is rather long (com.jeroenmols.modularization.example), the modules follow a very simple pattern:\nfeatures: [project-name].features.[feature-name]\ne.g. modularization.features.login libraries: [project-name].libraries.[library-name]\ne.g. modularization.libraries.actions This doesn\u0026rsquo;t just avoid getting very long package names, but it will also logically group your imports in your code:\nall your modules are grouped due to the same project name feature imports appear first, followed by library imports Layout previews # When looking at the layout preview of any layout resource in a submodule, it is shown by default in the wrong theme:\nThis makes sense, as our submodules don\u0026rsquo;t know anything about the application theme set in the main app module manifest.\nWhile you can manually change the theme from the drop-down menu, you can also tell the module what theme it will eventually inherit from the app module. Do this by adding the theme attribute to the application element of the submodule manifest:\n\u0026lt;manifest xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; package=\u0026#34;modularization.features.dashboard\u0026#34;\u0026gt; \u0026lt;application android:theme=\u0026#34;@style/AppTheme\u0026#34;\u0026gt; \u0026lt;activity android:name=\u0026#34;.DashboardActivity\u0026#34; /\u0026gt; \u0026lt;/application\u0026gt; \u0026lt;/manifest\u0026gt; That way the layout previews will be shown in the correct theme by default!\nRestrict visibility # In order to ensure different modules are properly decoupled, I highly recommend marking each class with an internal modifier unless it is part of the public API.\nThis has the added advantage that Android Studio autocomplete will suggest fewer options (only the relevant ones), making it easier to find the classes you need while coding.\nDependency management # When scaling up your project to a lot of modules, making sure that every module uses the same version of each dependency can be quite a challenge. Hence I advice to centrally manage the version of each dependency so it can be updated for all modules with just one change.\nThere are many different ways in order to accomplish that, so I encourage you to check out Sam Edward\u0026rsquo;s great article on dependency management. Adopting this into the ModularizationExample leads to a very simple dependencies file listing all dependencies:\nimport org.gradle.api.JavaVersion object Config { val minSdk = 23 val compileSdk = 28 val targetSdk = 28 val javaVersion = JavaVersion.VERSION_1_8 val buildTools = \u0026#34;28.0.3\u0026#34; } object Versions { // \u0026lt;editor-fold desc=\u0026#34;google\u0026#34;\u0026gt; val androidx_core = \u0026#34;1.0.1\u0026#34; val androidx_recyclerview = \u0026#34;1.0.0\u0026#34; val androidx_navigation = \u0026#34;2.0.0\u0026#34; val androidx_constraintLayout = \u0026#34;1.1.3\u0026#34; val material = \u0026#34;1.1.0-alpha04\u0026#34; // \u0026lt;/editor-fold\u0026gt; ... } object Deps { val androidx_core = \u0026#34;androidx.core:core-ktx:${Versions.androidx_core}\u0026#34; val androidx_constraintlayout = \u0026#34;androidx.constraintlayout:constraintlayout:${Versions.androidx_constraintLayout}\u0026#34; val androidx_material = \u0026#34;com.google.android.material:material:${Versions.material}\u0026#34; val androidx_navigation_fragment = \u0026#34;androidx.navigation:navigation-fragment-ktx:${Versions.androidx_navigation}\u0026#34; val androidx_navigation_ui = \u0026#34;androidx.navigation:navigation-ui-ktx:${Versions.androidx_navigation}\u0026#34; val androidx_recyclerview = \u0026#34;androidx.recyclerview:recyclerview:${Versions.androidx_recyclerview}\u0026#34; ... } Also, when projects grow bigger, the number of dependencies will also grow causing it hard to keep all of them up to date. Fortunately, Ben Manes has created a Gradle Versions Plugin that makes it very easy to keep your dependencies up to date.\nSimply add the plugin and run:\n./gradlew dependencyUpdates To get a clear output of all up to date and out of date dependencies:\n------------------------------------------------------------ : Project Dependency Updates (report to plain text file) ------------------------------------------------------------ The following dependencies are using the latest milestone version: - com.github.ben-manes:gradle-versions-plugin:0.21.0 The following dependencies have later milestone versions: - androidx.constraintlayout:constraintlayout [1.1.3 -\u0026gt; 2.0.0-beta1] http://tools.android.com - androidx.core:core-ktx [1.0.1 -\u0026gt; 1.2.0-alpha01] http://developer.android.com/tools/extras/support-library.html - androidx.navigation:navigation-fragment-ktx [2.0.0 -\u0026gt; 2.1.0-alpha04] https://developer.android.com/topic/libraries/architecture/index.html - androidx.navigation:navigation-ui-ktx [2.0.0 -\u0026gt; 2.1.0-alpha04] https://developer.android.com/topic/libraries/architecture/index.html - org.jetbrains.kotlin:kotlin-android-extensions [1.3.20 -\u0026gt; 1.3.31] https://kotlinlang.org/ - org.jetbrains.kotlin:kotlin-android-extensions-runtime [1.3.20 -\u0026gt; 1.3.31] https://kotlinlang.org/ - org.jetbrains.kotlin:kotlin-gradle-plugin [1.3.20 -\u0026gt; 1.3.31] https://kotlinlang.org/ ... Speed up builds # Remember that speeding up builds was an important reason to modularize apps. One of the most intriguing ways Gradle accomplishes this is by being smart about whether a code change will also require other modules to be recompiled.\nWhile you can find the full explanation here, it suffices to say here that you should always strive to implementation dependencies instead of api.\ndependencies { // Don\u0026#39;t do this api project(\u0026#39;:libraries:ui-components\u0026#39;) // Do this instead implementation project(\u0026#39;:libraries:ui-components\u0026#39;) } Wrap-up # Modularization yields tons of benefits, yet can be quite challenging.\nAfter reading this series, you\u0026rsquo;ve learned why modularization is important, what the architecture of a modularized app could be, how to start modularizing your app and finally quite some useful tips and tricks to help you along the way.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"12 June 2019","externalUrl":null,"permalink":"/blog/2019/06/12/modularizationtips/","section":"Blogs","summary":"Wrapping up this series on modularization I\u0026rsquo;d like to share some of the things we\u0026rsquo;ve learned at Philips Hue while going through this process the past year.","title":"Modularization - Lessons learned","type":"blog"},{"content":"","date":"24 April 2019","externalUrl":null,"permalink":"/tags/how-to/","section":"Tags","summary":"","title":"How To","type":"tags"},{"content":"Now that we have a clear idea of how a modularized app could look like how can this be applied to an existing app?\nPart four will dive deeper into how existing apps can be sliced and how you can gradually migrate to a fully modularized architecture.\nModularization strategy # Roughly speaking there are two strategies you can take:\nconvert the old app to a library and pull code up keep the old app and push code down Pull code up # In this approach, the old app gets converted to an Android library module and a new app module is created on top of that. This allows to gradually pull up code (features and libraries) from the old app module into a new module.\nWhen all code is pulled up, the old app module is removed and what\u0026rsquo;s left is the architecture we were striving for.\nConceptually this is very simple and it has one huge advantage: (almost) no dependency problems!\nAll old code is in the old app module and new modules are only created on top of that. Hence, those modules will always have access to all legacy files they depend on, even if those files weren\u0026rsquo;t migrated to a proper module yet.\nE.g. a new feature can easily access the analytics framework, even if there isn\u0026rsquo;t an analytics module yet. This is because all old analytics code is already in the old app module that the feature depends on.\nThere are also some disadvantages, unfortunately:\nrenaming/moving the old app module is a huge upfront change and could cause a lot of merge conflicts =\u0026gt; can be avoided by not moving/renaming the app module need to convert all references to view IDs from R.id.*** to R2.id.*** when using Butterknife. This is because the Android build system dynamically changes IDs of resources in libraries to avoid ID conflicts while merging libraries together in the app features need to be modularized first and only after libraries can be extracted. E.g. hard to extract all analytics up to an analytics library when some features that are still in old app module still need to access that. At Philips Hue, we heavily used Butterknife so this approach turned out to be impractical for us. Mainly due to the large number of upfront changes to prepare the old app module.\nPush code down # Alternatively, the old app module can also just remain in place and modules are extracted from that downwards one by one.\nAt first, this is quite a bit more challenging because all the common plumbing (UI components, analytics, storage,\u0026hellip; ) is still in the upper app module and isn\u0026rsquo;t accessible by lower modules. e.g. It\u0026rsquo;s hard to pull out a feature that relies on analytics if the analytics code is still in the app module.\nOn the plus side, this method aggressively forces you to modularize: you will easily run into actual dependency problems that must be solved before you can continue. E.g. add a new or extract a feature module will force you to extract common logic first (e.g. network layer)\nHence common plumbing must be modularized on the short term and cannot be parked in a single huge core module for a long time. But once these key plumbing modules are extracted, the rest of the modularization will become a lot easier.\nAnd because moving code down is harder than moving it up, only the essential code parts will be moved down at first. Resulting in smaller steps, enabling a better grip on the entire modularisation process.\nFinally, this way of modularisation allows to clean up the code base bottom up: move part code down -\u0026gt; convert to Kotlin -\u0026gt; make idiomatic -\u0026gt; rinse and repeat. It\u0026rsquo;s a lot easier to set architecture goals (e.g. % Kotlin, % test coverage,\u0026hellip;) for smaller parts of your code base than for huge monolithic modules.\nNote: Introducing new technologies (e.g. coroutines, rxjava) is usually also easier bottom up. This is because modules making use of these can directly access \u0026ldquo;cleaned up interfaces\u0026rdquo; instead of wrapping old ones to fit the new paradigms. So you start benefitting from the end-to-end benefits of the new technologies sooner in your app.\nAt Philips Hue, we decided to go for this approach, mainly because it forced us to think better about our library modules upfront and it also avoided a huge refactoring due to Butterknife.\nConsiderations # Regardless of what strategy you decide two follow, here are a few things you should take into consideration:\nTry to make a big initial push # Only once you reach a critical mass of modules, you will start reaping the benefits. (build times, easier to understand code,\u0026hellip;) Therefore try to define a few key modules and put them in place as soon as possible.\nAt Philips Hue these were:\nUI components (incl themes and styles) SDK wrapper (Hue system domain model) Translations Analytics Api clean up # Modularizing an existing app will be quite the challenge and you will uncover dependencies between classes that shouldn\u0026rsquo;t be have been there. Cutting these might be non-trivial and could result in splitting classes, introducing adapters,\u0026hellip;\nHence clean up work cannot be avoided while modularizing. But try to keep that cleanup work focussed as much as possible to the API of the modules. Once they are clean/fixed you\u0026rsquo;ll be able to refactor/replace their internals easily later on.\nAlso, try to aggressively restrict the visibility of the non-public interface to private or internal. This decouples modules and again facilitates doing an internal module clean up later without affecting the rest of the code base.\nSometimes, however, a simple interface clean up can blow up and result in tons of code changes somewhere. At this point, it could become impractical to completely clean up the entire interface when all you need is just to extract a simple module.\nThat\u0026rsquo;s fine, just mark the old API as deprecated and provide a new API next to that one. Don\u0026rsquo;t be afraid to postpone other problems when you are trying to solve the modularization one.\nGeneral code improvements # While doing all this work, nearly all parts of the code will be touched at some point. This generates a unique opportunity to finally do some of the improvements that were on your backlog for quite some time like:\nconversion to Kotlin add (more) unit tests \u0026hellip; Wrap-up # Generally speaking, there are two strategies to modularize an existing app: pull code up or push code down. Make sure to make a big initial push towards modularization to reap the benefits as soon as possible, clean up the module APIs and see if you can take some code improvements along.\nMake sure to follow me on Mastodon and read on to learn some tips and lessons learned while modularizing in part 5.\n","date":"24 April 2019","externalUrl":null,"permalink":"/blog/2019/04/24/modularizationhow/","section":"Blogs","summary":"Now that we have a clear idea of how a modularized app could look like how can this be applied to an existing app?\nPart four will dive deeper into how existing apps can be sliced and how you can gradually migrate to a fully modularized architecture.","title":"Modularization - How to approach","type":"blog"},{"content":"With a clear view on how multi-module apps should be architected, let\u0026rsquo;s dive into a real-life practical example.\nWe\u0026rsquo;ll discover how the architecture results in a clear application structure, how navigation is handled, how to use staged rollouts, how to test everything and even look at a production app that is using this architecture.\nSource code # All source code for this blog post is available on Github.\nThis is not a fully functional app, but rather a highly focussed example that only concentrates on demonstrating the modularization architecture.\nApplication structure # One of the key benefits of the three-layer app-features-libraries architecture is supposed to be clear navigation throughout the app and source code. So let\u0026rsquo;s investigate if that promise holds true.\nLooking at the root folder of the project, the following structure becomes clear:\n. ├── app ├── features │ ├── dashboard │ ├── login │ └── sharing └── libraries ├── actions └── ui-components Simple, right?\nThere is one app that consists out of three features: dashboard, login, and sharing. It is backed by a few libraries: actions and ui-components. All feature and library modules are grouped within the features and libraries folder respectively.\nBut what do the features themselves do?\nWe\u0026rsquo;ll let\u0026rsquo;s have a look at their respective navigation graphs! First up is the dashboard:\nClearly, this app seems to be about photos!\nBut the navigation graph looks a bit odd (no destinations), this is because this isn\u0026rsquo;t an actual functioning graph! The navigation components don\u0026rsquo;t support visualizing a graph for an activity with bottom tabs (yet?).\nSo let\u0026rsquo;s have a look at the DashboardActivity more closely:\nHere we go, the main dashboard consists out of three tabs: photos, albums and social.\nNow let\u0026rsquo;s have a look at the Login feature:\nIn one visual overview you can see that the login screen consists out of three screens that link together as a flow. The navigation graph even displays the nave of every screen on top so you can easily navigate to it!\nSimilarly, zooming into the Sharing module immediately explains what this feature is all about:\nAgain, a picture says more than a 1000 lines of code!\nDue to the way feature modules are defined, this architecture splits your app hierarchically, similar to how a user navigates through your app. This in combination with a visual represenation of each feature (navigation graph) helps to understand the app structure, the navigation between screens and find back the name of screens.\nNavigation # As navigation seems to be one of the key problems people are facing in multi-modules apps (see my previous article), let\u0026rsquo;s explore the two different modes of navigation:\nwithin a feature between features 1. Within a feature # All navigation within a feature is handled by the navigation components. To do this, just add a NavHostFragment to the Activity layout and load it with a navigation graph.\nLet\u0026rsquo;s have a look at the LoginActivity layout:\n\u0026lt;fragment xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:id=\u0026#34;@+id/nav_host_fragment\u0026#34; android:name=\u0026#34;androidx.navigation.fragment.NavHostFragment\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; app:defaultNavHost=\u0026#34;true\u0026#34; app:navGraph=\u0026#34;@navigation/login_graph\u0026#34;/\u0026gt; Note how the fragment attribute instantiates a NavHostFragment that gets loaded with the navigation graph from login_graph.xml.\nThis navigation graph doesn\u0026rsquo;t only describe the three screens that are in the login feature, but it also defines actions for navigation between screens.\n\u0026lt;navigation xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:id=\u0026#34;@+id/login_graph\u0026#34; app:startDestination=\u0026#34;@id/welcomeFragment\u0026#34;\u0026gt; \u0026lt;fragment android:id=\u0026#34;@+id/welcomeFragment\u0026#34; android:name=\u0026#34;modularization.login.WelcomeFragment\u0026#34;\u0026gt; \u0026lt;action android:id=\u0026#34;@+id/action_welcomeFragment_to_loginFragment\u0026#34; app:destination=\u0026#34;@id/loginFragment\u0026#34; /\u0026gt; \u0026lt;/fragment\u0026gt; \u0026lt;fragment android:id=\u0026#34;@+id/loginFragment\u0026#34; android:name=\u0026#34;modularization.login.LoginFragment\u0026#34;\u0026gt; \u0026lt;action android:id=\u0026#34;@+id/action_loginFragment_to_avatarFragment\u0026#34; app:destination=\u0026#34;@id/avatarFragment\u0026#34; /\u0026gt; \u0026lt;/fragment\u0026gt; \u0026lt;fragment android:id=\u0026#34;@+id/avatarFragment\u0026#34; android:name=\u0026#34;modularization.login.AvatarFragment\u0026#34; /\u0026gt; \u0026lt;/navigation\u0026gt; In this graph, the WelcomeFragment is the entrypoint of the feature and navigation to the next screens can simply be done by invoking a navigation action. E.g. navigating to the LoginFragment is done by:\nfindNavController() .navigate(R.id.action_welcomeFragment_to_loginFragment) AvatarFragment, on the other end, is the last screen from where navigation is triggered to a different feature.\n2. Between features # Recall that features are full screen (entry point is an Activity) and different features aren\u0026rsquo;t allowed to rely on each other.\nThis means that the login feature cannot start the dashboard feature using an explicit Intent (e.g. by defining the exact class of the Activity to start):\nstartActivity(Intent(activity, DashboardActivity::class.java)) But has to use an implicit Intent instead, where you basically ask for some Activity that can handle the action.opendashboard:\nstartActivity(Intent(\u0026#34;action.dashboard.open\u0026#34;)) Which will start the DashBoardActivity as it defines it will respond to that action in the manifest.xml of the dashboard feature:\n\u0026lt;manifest xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; package=\u0026#34;modularization.dashboard\u0026#34;\u0026gt; \u0026lt;application android:theme=\u0026#34;@style/AppTheme\u0026#34; \u0026gt; \u0026lt;activity android:name=\u0026#34;.DashboardActivity\u0026#34;\u0026gt; \u0026lt;intent-filter\u0026gt; \u0026lt;action android:name=\u0026#34;action.dashboard.open\u0026#34;/\u0026gt; \u0026lt;category android:name=\u0026#34;android.intent.category.DEFAULT\u0026#34; /\u0026gt; \u0026lt;/intent-filter\u0026gt; \u0026lt;/activity\u0026gt; \u0026lt;/application\u0026gt; \u0026lt;/manifest\u0026gt; Note that in theory, multiple activities can offer to handle this action causing a chooser dialog to be displayed. (e.g. multiple apps could offer to take a picture when asking for the implicit action MediaStore.ACTION_IMAGE_CAPTURE)\nHowever, implicit intents alone don\u0026rsquo;t fully solve how to navigate between features:\nduplication of action String \u0026ldquo;action.opendashboard\u0026rdquo; in the feature manifest and every feature that wants to create an intent with that action in-depth knowledge required of how to create Intent with extras when passing data into a feature (e.g. name of extras) another app can define the same action causing a chooser dialog to pop up (also possible between multiple build flavors) The first two can be solved by introducing an actions module that is responsible for generating properly formatted intents to start feature Activities:\nobject Actions { fun openLoginIntent() = Intent(\u0026#34;action.login.open\u0026#34;) fun openDashboardIntent() = Intent(\u0026#34;action.dashboard.open\u0026#34;) fun openSharingIntent() = Intent(\u0026#34;action.sharing.open\u0026#34;) } Starting the next feature can then simply be done by:\nactivity.startActivity(Actions.openDashboardIntent()) Not only is this a very descriptive way of linking to the next feature, but this principle can also be used to make passing data into the new feature type safe:\nobject Actions { fun openDashboardIntent(userId: String) = Intent(context, \u0026#34;action.dashboard.open\u0026#34;) .putExtra(EXTRA_USER, UserArgs(userId)) } Now the login feature no longer needs to know how the data is passed into the dashboard, it simply has to call:\nactivity.startActivity(Actions.openDashboardIntent(\u0026#34;userId\u0026#34;)) Neat, right?\nFinally, relying on implicit Intents can cause chooser dialogs to pop up. While a collision with a 3rd party app is unlikely, it can easily happen for different build flavors.\nThis can easily be avoided by restricting the intents to the current package:\nobject Actions { fun openLoginIntent(context: Context) = internalIntent(context, \u0026#34;action.login.open\u0026#34;) private fun internalIntent(context: Context, action: String) = Intent(action).setPackage(context.packageName) } Feature rewrites/refactors # As you probably already know, I don\u0026rsquo;t believe in-app rewrites. However, refactoring by itself can also be frustrating and take a long time to provide results. So how do you get your app in better shape?\nWouldn\u0026rsquo;t it be nice if you could aggressively refactor or even rewrite parts of your app without having to worry about a risky release?\nWell, this architecture actually allows you to easily do exactly that! E.g. you can rewrite a completely new login module and ship both the old and new one in your app. Using the actions module you can now very easily choose what feature to start:\nobject Actions { fun openLoginIntent() = if (FeatureFlag.loginRewrite) { Intent(\u0026#34;action.login2.open\u0026#34;) } else { Intent(\u0026#34;action.login.open\u0026#34;) } } With the right analytics in place and a remote feature toggle framework such as Firebase remote config, you can now gradually roll out the rewrite.\nThis allows you to build up confidence in the new code, mitigate risks of breaking a crucial user flow (e.g. Login) and hence refactor/rewrite parts of your app way more aggressively.\nTesting # The strategy to test this architecture consists of three key parts:\nunit tests: super fast, test classes in isolation feature tests: espresso tests for features in isolation app tests: test key user flows across different features First of all, unit tests should be added for all business logic: both for logic internal to the feature modules as for all business logic of libraries. The app module likely doesn\u0026rsquo;t require any unit tests as there is no business logic in that module.\nNext, all features can be tested using Espresso in isolation from the rest of the app! No need to step from the start screen throughout the entire app towards the screen you want to test first. Just start the feature activity directly via an ActivityTestRule.\nLook at how simple life can be:\nclass LoginFlowTest { @Rule @JvmField var mActivityTestRule = ActivityTestRule(LoginActivity::class.java) @Test fun loginFlowTest() { onView(withId(R.id.button_login_start)).perform(click()) onView(withId(R.id.button_login_signin)).perform(click()) onView(withId(R.id.button_login_toapp)).check(matches(isDisplayed())) } } Such feature tests are fast, way more reliable (can\u0026rsquo;t fail due to bugs in other features) and don\u0026rsquo;t require much setup.\nWith all business logic unit tested and features tested in isolation, the missing link is to test \u0026ldquo;real world app usage\u0026rdquo; in terms of long, typical user flows.\nThese scenarios are tested in the app module. Take for instance the following test where a user logs in, navigates to the sharing screen and does something meaningful there:\nclass AppFlowTest { @Rule @JvmField var mActivityTestRule = ActivityTestRule(MainActivity::class.java) @Test fun test_criticalUserFlow_throughoutEntireApp() { onView(withId(modularization.login.R.id.button_login_start)).perform(click()) onView(withId(modularization.login.R.id.button_login_signin)).perform(click()) onView(withId(modularization.login.R.id.button_login_toapp)).perform(click()) onView(withId(R.id.action_albums)).perform(click()) onView(withId(R.id.action_sharing)).perform(click()) onView(withId(R.id.button_social_facebook)).perform(click()) onView(withId(R.id.recyclerView_sharing_contacts)).check(ViewAssertions.matches(ViewMatchers.isDisplayed())) } } The app module tests will be the most difficult ones to write and stabilize, but due to the split in feature modules, the largest chunk of tests can run in isolation per feature. So this provides a really nice balance between reducing repetitive manual testing, while keeping development/maintenance cost under control.\nProduction example # While this architecture sounds good in theory and the example looks nice on paper, it still isn\u0026rsquo;t a full fidelity app. Are you sure this will actually work in production?\nWell, I\u0026rsquo;m glad you ask! Because this is exactly the way that the Philips Hue app is modularized:\nAll features are independent, self-contained and they don\u0026rsquo;t rely on each other. There is only one single app module.\nNote that due to the large legacy code base of Philips Hue, it hasn\u0026rsquo;t fully migrated to this architecture yet: currently, there are 8 feature modules and 14 libraries. Rewriting features with a feature toggle and gradually rolling them out happens on a regular basis.\nIt\u0026rsquo;s also interesting to look into some decisions taken on the library level:\nUI components: components reused across features + themes and styles Analytics: most of the \u0026ldquo;horizontal service layers\u0026rdquo; are already extracted from the app as a library Translations: ideally each feature should contain its own translations, but for Philips Hue, this would require to dynamically split the monolithic translation files from our translation agency for each feature. Simply not the biggest fish to fry at the moment. Wrap-up # The three-layer app-features-libraries architecture addresses quite some fundamental app/modularization issues: project structure, navigation, staged rollouts and testability.\nAll source code is available on Github.\nMake sure to follow me on Mastodon and let\u0026rsquo;s investigate how you can start modularizing an existing app in part 4.\n","date":"2 April 2019","externalUrl":null,"permalink":"/blog/2019/04/02/modularizationexample/","section":"Blogs","summary":"With a clear view on how multi-module apps should be architected, let\u0026rsquo;s dive into a real-life practical example.\nWe\u0026rsquo;ll discover how the architecture results in a clear application structure, how navigation is handled, how to use staged rollouts, how to test everything and even look at a production app that is using this architecture.","title":"Modularization - Real-life example","type":"blog"},{"content":"","date":"2 April 2019","externalUrl":null,"permalink":"/tags/sample/","section":"Tags","summary":"","title":"Sample","type":"tags"},{"content":"Now that we\u0026rsquo;ve established that modularization is a really good thing to strive for, how should a modularized app look like? How are the different modules connected? And how does this look for a real app?\nThis second part will explore a simple, yet very effective approach to modularizing apps. It will cover in depth the different kinds of modules and present the benefits of this approach.\nDisclaimer # This is by no means the only way to modularize an app, but it does offer some key benefits that we will touch upon later.\nApp structure # Let\u0026rsquo;s start by looking at the app you are working on:\nDoes it consists out of a main screen with several tabs/clickable elements? What happens when users click those elements? Chances are high that will open a new full-screen part of the app, often consisting out of several sub-screens to perform a particular action.\nHave a look at gmail for instance:\nSimplified, it consists of a main screen (inbox) with an app drawer, a compose button and email items in the inbox. Clicking one of these elements leads you to a new full screen \u0026ldquo;feature\u0026rdquo;:\nclicking an email -\u0026gt; read email feature (one screen) clicking compose -\u0026gt; write email feature (several screens) clicking settings (in drawer) -\u0026gt; settings (several screens) Highly simplified, apps are just a tree of (fullscreen) screens, where multiple screens often form a user flow together.\nLet\u0026rsquo;s call all these \u0026ldquo;user flows\u0026rdquo; features.\nNow let\u0026rsquo;s think about how the Android OS is designed to work: multiple apps can interact with each other via intents. This is actually pretty cool, as any app can request an action to be performed (e.g. take a picture) without having to know who will process that request and how it will be processed.\nThe Android system simply links multiple apps together via a system of implicit intents.\nWhat if we were to take advantage of both these observations and split our app into several completely independent feature modules? Where each feature is decoupled using a simple \u0026ldquo;startActivityForResult\u0026rdquo; contract?\nModularized Architecture # While splitting your app into several features, all of those features will likely depend on some common business logic or UI components. Hence we need to introduce a third level of \u0026ldquo;library modules\u0026rdquo;.\nBringing that all together yields:\nThis architecture basically splits an app into three levels of modules:\nApp: links together features modules (usually only one) Features: self-contained, full-screen UI level features that include Espresso tests. Each feature consists of at least one activity and optionally a navigation graph. Feature modules never directly depend on each other. Libraries: functionality shared across multiple features. Different libraries can depend on each other Let\u0026rsquo;s investigate these three levels in depth.\nFeature modules # Probably the most important modules are feature modules. These have the following characteristics:\nan android-library module single activity with (optional) navigation graph (multiple activities are allowed) respond to implicit intents and pass back a result never depend on other features or app depend on several library modules Feature modules correspond with full screen, coherent user facing functionality in the app: e.g. user login, app settings, picture cropping,\u0026hellip;\nNavigation # Note that navigation in apps is identified as a big challenge in a public poll by @emmaguy\nThe first key benefit is that feature modules make navigation within an app significantly easier. This is because they split the navigation problem into smaller parts:\nnavigation within a feature -\u0026gt; handled by the feature itself navigation between features -\u0026gt; handled by the app module Hence there is no need for very large and complex navigation controllers! Features simply split an app in logical, coherent flows.\nEven more, the navigation component gives every feature a clear visual representation of its UI flow. That allows to quickly figure out what a feature does. E.g. What does the game feature do?\nFinally no more guessing how a particular screen was named, just jump to the right feature, look for the screen and you\u0026rsquo;ll find the fragment/views without having to guess/remember their name.\nScaling # Second, making features independent like this completely decouples their implementations. Hence eliminating merge conflicts across different feature teams by design!\nExperimenting with new technologies also becomes a lot easier: you can easily benefit from new tech end to end within a single feature. Evaluate if it\u0026rsquo;s beneficial for your team and in case of a bad choice, all effects are contained within a single modules!\nAnd should you ever decide to launch a second app (or SDK), you can simply package existing features together with new ones in a new app module.\nTesting # Because all features can be started directly using an intent, there is no need for Espresso to step through other parts of the app to arrive at the feature to test.\nThis not only makes tests simpler and faster, but fewer steps also make them more reliable and tests can no longer break due to bugs in other features!\nLibrary modules # Libraries provide shared plumbing that is reused across several or all features. Their characteristics are:\nandroid library, pure Java or pure Kotlin module never depend on features or app can (but don\u0026rsquo;t have to) depend on other libraries Consequently, libraries can be very diverse: e.g. UI components, data storage, network communication, std lib,\u0026hellip;\nWhere features are a \u0026ldquo;vertical slice\u0026rdquo; of the app, libraries are a \u0026ldquo;horizontal slice\u0026rdquo;, providing functionality to several other modules.\nApp module # In order to ship an app to users, something has to link all features together: the app module.\nIn doing so the app module orchestrates the navigation from between features. It uses feature toggles to determine what should be enabled and what not.\nThese feature toggles are incredibly powerful because by shipping multiple versions of the same feature in one app (e.g. the old and rewritten version), the app module allows to gradually roll out the rewritten feature to users.\nif (isRewriteFeatureEnabled) { startActivityForResult(Intent(\u0026#34;rewritten_feature\u0026#34;)) } else { startActivityForResult(Intent(\u0026#34;feature\u0026#34;)) } Finally, launching several apps and sharing features between them is as easy as creating a new app module.\nWrap-up # Recapping, this simple, three-layered architecture of app, features and libraries has the the following benefits:\nsimplifies navigation by splitting the in-feature and across feature navigation makes it easy to find back screens and understand features (especially when using the navigation graph) enables scaling teams: fewer merge conflicts between feature teams as features are decoupled makes test automation easier: features can be started directly, no need to step through the app to the feature first simplifies experimenting with new technologies: quickly achieve end-to-end benefits within feature + low cost of bad technology choice (isolated from rest of the app) allows staged rollout of rewritten features using feature toggles Make sure to follow me on Mastodon and let\u0026rsquo;s study a detailed example of this architecture in part 3.\n","date":"18 March 2019","externalUrl":null,"permalink":"/blog/2019/03/18/modularizationarchitecture/","section":"Blogs","summary":"Now that we\u0026rsquo;ve established that modularization is a really good thing to strive for, how should a modularized app look like? How are the different modules connected?","title":"Modularization - A successful architecture","type":"blog"},{"content":"Modularizing your app seems to be all the hype these days. But why should you actually care? What are the benefits for you and your team? How should a modularized app look like? And how do you start splitting your app?\nPart one of this blog post series will deep dive into the problems modularization solves and the unique opportunities it offers.\nWhy # There is no short answer to this question, modularisation really has a lot going for it:\nSpeeds up builds Enable on demand delivery Simplify development Reuse modules across apps Experiment with new technologies Scale development teams Enables refactoring Simplifies test automation Let\u0026rsquo;s investigate these benefits more in depth.\n1. Speeds up builds # Highly simplified, Gradle does two things to speed up builds:\nCache work it did before so it doesn\u0026rsquo;t have to do it again Try to do as much work as possible in parallel Both of these strategies aren\u0026rsquo;t effective for single module apps as every code change, makes it impossible to reuse the already generated (cached) compiled code artifact and hence all code has to be recompiled again sequentially.\nWith multiple modules, however, Gradle can build several modules in parallel and avoid building modules that have no code changed it already has a cached artifact for. This speeds up your incremental builds and even your clean builds if you use the Gradle build cache.\nNote: modules sometimes need to be recompiled even if they don\u0026rsquo;t have direct code changes, but because a dependency changed. More info here.\n2. Enable on demand delivery # While you could argue that app size isn\u0026rsquo;t a major concern in most western countries, the same cannot be said for all parts of the world. But no matter where your users are, saving bandwidth and on device storage is a nice thing to do.\nRecent years however, Android has added support for some interesting new deployment options:\nInstant apps allow users to run apps without installing them. On demand delivery allows to ship a smaller app with fewer features and download new features on the fly when the user starts accessing those Modularizing your app is the very first step in being able to add support for these. Even if you aren\u0026rsquo;t considering these use cases today, it\u0026rsquo;s a big win if your architecture is already prepared to add them later on.\n3. Simplify development # As covered in my [previous post]({{ site.baseurl }}{% link blog/_posts/2019-02-20-tacklelegacy.md %}), modularization helps to get rid of or to avoid spaghetti code. In a modularized world you could still have spaghetti (within modules), but at least it would be multiple smaller, easily digestible portions.\nA clear contract between the modules won\u0026rsquo;t just decouple everything, avoiding that one change causes side effects somewhere else. But it also forces you to group code in smaller coherent parts. That makes the code easier to read, understand and consequently, maintenance will also become a lot easier.\nIt\u0026rsquo;s always easier to build several small things than trying to build one huge thing.\n4. Reuse modules across apps # Even if your business has no plans to launch several apps in the near future, preparing for that still makes sense:\nshould your business be successful, you have a head start launching a second app/product! maybe someday you want to involve 3rd party developers on your platform and make an SDK or perhaps you want to expose full app flows to 3rd party developers. (e.g. Firebase remote login)\nAt Philips Hue, for instance, our bridge discovery flow could potentially bootstrap any 3rd party Hue app) and why wouldn\u0026rsquo;t you step up your game and contribute a few of those shine modules back to the open source community? Striving to make modules reusable across apps is a great thing to strive for, even if you never end up actually doing it.\n5. Experiment with new technologies # The Android landscape is evolving at a rapid pace: just two years ago we didn\u0026rsquo;t have Kotlin, Jetpack, Architecture components, Navigation components, \u0026hellip; and that\u0026rsquo;s just the official Google stuff!\nHow on earth can you keep up with that in your app, while avoiding hype driven development? Because making the wrong technology or architecture choice could haunt you for several months or even years!\nAgain modularisation comes in to save the day. What if you just contain the new tech/architecture to a single module? That makes integrating the technology (e.g. RXJava) a lot easier and you can experience the full benefits of the technology by converting an entire module end to end. Hence you can rapidly experiment and if the choice turns out not to work for you, it won\u0026rsquo;t be that much work to revert it.\nEnabling experimentation with new technologies isn\u0026rsquo;t the only benefit. Modules also help to avoid technology lock-in! What if you go all in react native and Facebook pulls official support? Containing technology choices to modules gives you room to see how a technology matures before going all in.\n6. Scale development teams # The more people that work on a code base, the more files will be modified concurrently causing a hell of merge conflicts. And let\u0026rsquo;s face it, every conflict you solve is like flipping a coin hoping it falls on the right side, so regression is a real issue here.\nAgain modularisation softens the blow because if you split your app in a smart way, you can delegate the ownership of particular feature modules to particular teams/people. Completely avoiding concurrent modifications, or at least limiting those problems to a smaller set of modules.\nBut this isn\u0026rsquo;t the only kind of scaling that modularisation enables: you can even outsource development of particular feature modules to an external company as your app won\u0026rsquo;t be affected by the (lower) quality of the code inside of those modules.\n7. Enables refactoring # Monolithic apps are usually very hard to change or improve (see above). This is mainly because cleaning up code in one place can easily have unforeseen side effects somewhere else.\nBut there is a second reason why monoliths are hard to refactor: there is no easy way to gradually roll out your improvements!\nIdeally, you want to refactor or rebuilt all functionality behind a feature toggle, so you can first verify that everything works (at least on par) before rolling it out to everyone. Risk reduction like this is key, especially if your app directly impacts the revenue stream of your business.\nGradually rolling out improvements will still be challenging, even in a fully modularized app. But with the right split (see below) you can at least solve this problem for some use cases.\n8. Simplifies test automation # Besides unit tests and UI tests, it is also important to automate the key user flows to ensure they keep on working. On Android, we typically use Espresso for this kind of integration tests.\nNow imagine we want to test the payment flow in a taxi application. Do you really want every test to:\nlog in a user first first enter a destination on the map pick the preferred taxi pay for the ride (👈 interesting part) No! Because this would not only make the test very slow (# steps), but it also makes them all fail when a bug appears in the login flow.\nOn the other hand, modularization (if done well) can enable the payment flow to be tested without having to step through other parts of the app. This speeds up tests, simplifies test setup and increases their reliability.\nWrap-up # Modularization is incredibly powerful to speed up your builds, simplify development and fundamentally scale your team. On top of that, it enables interesting use cases such as instant apps and makes it easier to experiment with new technologies.\nMake sure to follow me on Mastodon and learn how to architect a multi module app by reading part 2.\n","date":"6 March 2019","externalUrl":null,"permalink":"/blog/2019/03/06/modularizationwhy/","section":"Blogs","summary":"Modularizing your app seems to be all the hype these days. But why should you actually care? What are the benefits for you and your team?","title":"Modularization - Why you should care","type":"blog"},{"content":"Are you living the dream? Is your code so clean it makes your eyes just tear a little? Can\u0026rsquo;t think of anything you would still like to refactor? Never have any bugs? Using all the latest technologies?\nUnfortunately, most of us aren\u0026rsquo;t in this state. We have bugs that haunt us, crashes at inconvenient times and sometimes 💩 simply hits the fan\u0026hellip; So how on earth do you get out of this mess?\nWell, I\u0026rsquo;m glad you ask! Here are five tips to get started.\n1. Don\u0026rsquo;t rewrite # If only we could rewrite all of the code, we would be out of this mess in no time;\nRemember that every project was a green field once, right? So why is it that all of us seem to end up in a similar state? Do you really think the previous developers didn\u0026rsquo;t have the best intentions?\nIn reality rewrites hardly ever work out. Mainly because the complexity (corner cases) and required effort (amount of features) to rewrite everything gets underestimated. Hence rewriting will be incredibly time-consuming.\nAt the same time, rewrites don\u0026rsquo;t focus on maximizing user value: you\u0026rsquo;ll lose tons of time rewriting stuff that wasn\u0026rsquo;t problematic to begin with and users won\u0026rsquo;t get any new features until the rewrite is done.\nAnd technology isn\u0026rsquo;t standing still either: two years ago we didn\u0026rsquo;t have Kotlin, Jetpack, Architecture components, Navigation components,\u0026hellip; And that\u0026rsquo;s just the official Google stuff!\nWith deadlines slipping, users complaining (no new features) and competition catching up\u0026hellip; will you really be able to resist not taking any shortcuts? Can you really guarantee you\u0026rsquo;ll be better off?\nI\u0026rsquo;m not saying rewrites never work out, but they are certainly one of the riskiest approaches to getting rid of your legacy. If you\u0026rsquo;re rewriting your app, you are basically developing a new product that just happens to have the same feature set as the old app. (with all risks involved in new product development)\nRead more about challenges while rewriting by Chad Fowler, Joel Spolsky, Jeroen Moons or Jo Van Eyck.\n2. Release, release, release # If it hurts, do it more often; Jez Humble\nOne thing that all legacy code has in common is that it\u0026rsquo;s poorly tested. Hence it can be very hard to control the impact of code changes.\nEver been in the situation where a simple code clean up, suddenly broke a seemingly unrelated feature elsewhere in the app?\nOr maybe you wanted to release a new update to the field, but your test team just kept on finding issues? Causing release candidate to be created after release candidate?\nSuch a lack of control over regression, unfortunately, isn\u0026rsquo;t uncommon. And while your natural instinct might be to just test each release longer manually, that just creates different problems:\nslower time to market due to longer test cycles decreased release frequency due to more test overhead harder to fix bugs, because they are found later more overhead with Git branches (where does this fix go?) working on several releases in parallel frustrated testers \u0026hellip; The problem here is that you\u0026rsquo;re actually fundamentally accepting you don\u0026rsquo;t trust your app anymore. You start to rely on release testing to find bugs, implicitly taking away the responsibility from developers to not break things.\nCounterintuitively, however, you should release more often instead of less.\nHaving smaller releases increases awareness of what changes were made in each release. Hence bugs can be easily tracked back to code changes and testing can be better focussed on the parts changed.\nAlso having fewer lines of code changed in every release will simply cause fewer bugs to be introduced. And the more often you do something, the better you\u0026rsquo;ll become at doing it.\nFinally, developers will get feedback faster as their code ends up in production sooner. That makes them more accountable, causing quality to go up.\nAt Philips Hue, we now release every two weeks and it has gotten so normal that we barely think about it.\n3. Divide and conquer # It\u0026rsquo;s easier to build several smaller things than to build one big thing;\nWhile most developers tend to like spaghetti, they aren\u0026rsquo;t quite as fond of spaghetti code. This is because, in a spaghetti codebase, everything is connected to everything else.\nThis has several challenges:\nchanging things is hard: one small clean up leads to changes in another file, requiring changes somewhere else, cascading into a world of pain. making changes in one place has unintended side effects difficult to introduce new technologies (e.g. RXJava) hard to scale up team: developers will often change the same files causing a lot of merge conflicts What you are really missing, in this case, is having clearly defined contracts between different parts of your code. Instead, the implementation of several parts is tightly coupled together.\nSo why don\u0026rsquo;t you split your big monolith in several, fully decoupled feature modules? This doesn\u0026rsquo;t just speed up builds, allow you to do instant apps, but it also allows to aggressively improve your app.\nOnce you split a feature off, the rest of the app becomes completely agnostic of the internal implementation of such a feature, which means you can:\neither refactor the feature fully rewrite the feature or leave the feature as-is (not a problem to solve now) This allows you to quickly and aggressively get your app into good shape, focussing on those parts that need attention most. In that way, even rewriting parts of your app suddenly becomes possible as you can derisk their roll-out with a feature toggle!\n4. Master your tools # The right tools for the right Job;\nIf you read any book on refactoring, you’ll quickly learn that one of the main prerequisites of it is to have proper tests in place. But as mentioned above, legacy code usually either has no tests or is poorly tested.\nNow I don’t really want to dive into any particular refactoring strategies here, but a great way to reduce regression while refactoring is to automate as much of the process as possible.\nBy this time I hope nobody renames classes by hand anymore? (e.g. rename class, rename constructors, rename file,\u0026hellip;) But did you also know Android studio can also move code, extract methods, inline interfaces,\u0026hellip;?\nReally really powerful stuff there. And it doesn’t just reduce regression, it also removes a lot of dull repetitive work from your plate allowing you to focus on the interesting challenges.\nI can help you get started with posts on code navigation and refactoring in Android Studio.\n5. Have faith # We choose to go to the Moon, not because it is easy, but because it is hard; JFK\nIncrementally refactoring your app and rewriting parts of it isn\u0026rsquo;t going to be easy. It definitely won\u0026rsquo;t be a walk in the park.\nEspecially refactoring can easily leave you unfulfilled: If you clean up the code in different places, it can easily feel insignificant, like your work barely made a dent in the bigger picture.\nPlease know that you are not alone. The age of small apps is behind us for quite some time now. And software often looks deceptively simple, yet can be extremely hard.\nBear with us, you\u0026rsquo;ll manage. Even if you fail a few times along the way, at least you are trying (and learning!). There is light at the end of the tunnel, things will go better if you persist, one step at a time.\nFinally, know that you are learning an invaluable skill: maintaining software whilst improving and building further upon it. Trust me, these refactoring skills will prove to be invaluable for the rest of your career.\nWrap-up # There is no silver bullet to magically improve your code base, especially not rewriting. But by learning your tools, slicing your app in several modules and releasing often you will succeed if you have faith.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\nFurther reads # If I\u0026rsquo;ve piqued your interest and you would like to learn more, I can highly recommend the following books:\nWorking effectively with legacy code by Michael Feathers: Excellent book on how to refactor legacy code with amazing chapter names like \u0026ldquo;I Don’t Have Much Time and I Have to Change It\u0026rdquo; and \u0026ldquo;I Need to Make a Change, but I Don’t Know What Tests to Write\u0026rdquo; Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation by Jez Humble and David Farley: Great book if you\u0026rsquo;d like to learn more about continuous delivery and what the benefits could be for your team/organization. Test Driven Development: By Example by Kent Beck: While tackling legacy code, writing automated tests is of the utmost importance. This book provides a really nice introduction to test-driven development from its inventor Kent Beck. ","date":"20 February 2019","externalUrl":null,"permalink":"/blog/2019/02/20/tacklelegacy/","section":"Blogs","summary":"Are you living the dream? Is your code so clean it makes your eyes just tear a little? Can\u0026rsquo;t think of anything you would still like to refactor?","title":"Five tips to get your code base in shape","type":"blog"},{"content":"","date":"20 February 2019","externalUrl":null,"permalink":"/tags/refactoring/","section":"Tags","summary":"","title":"Refactoring","type":"tags"},{"content":"","date":"17 January 2019","externalUrl":null,"permalink":"/tags/livedata/","section":"Tags","summary":"","title":"Livedata","type":"tags"},{"content":"","date":"17 January 2019","externalUrl":null,"permalink":"/tags/testing/","section":"Tags","summary":"","title":"Testing","type":"tags"},{"content":"Architecture components are one of the most exciting things that happened to Android in the past years. But how do you effectively go about and testing this?\nProblem statement # One of the interesting problems LiveData solves is to ensure the observer is always called on the main thread. This happens in the following ways:\nsetValue(): crashes if not called from main thread postValue(): swaps to main thread and is safe to be called from any background thread Now what happens if you call any of these methods in a junit test?\nWhen calling livedata.setValue() or livedata.value = you get:\njava.lang.RuntimeException: Method getMainLooper in android.os.Looper not mocked. Or alternatively when unitTests.returnDefaultValues = true is on:\njava.lang.NullPointerException at androidx.arch.core.executor.DefaultTaskExecutor.isMainThread(DefaultTaskExecutor.java:74) This makes sense, because JVM unit tests don\u0026rsquo;t know anything about the Android main thread! Hence all unit test are executed on a random (background) thread.\nNote that this is true in general. The main Thread is just a concept provided by most UI frameworks to avoid race conditions while updating the UI. E.g. on Android the main thread is provided by the Android Framework, for Java applications the main thread is provided by Swing (for instance).\nWhen calling livedata.postValue(), you get similar results.\nHowever here the problem is even more fundamental as this can never work. Even if the main thread would exist in the test, then the actual value update would happen asynchronously from the test, causing the asserts to happen before the value is actually updated.\nJUnit 4 # Solving this means doing two things:\ndon\u0026rsquo;t update live data on the main thread update live data immediately (don\u0026rsquo;t post value) Fortunately the architecture components team has provided a JUnit rule to do exactly that:\nclass ExampleUnitTest { @get:Rule val rule = InstantTaskExecutorRule() @Test fun `my test`() { val mutableLiveData = MutableLiveData\u0026lt;String\u0026gt;() mutableLiveData.postValue(\u0026#34;test\u0026#34;) assertEquals(\u0026#34;test\u0026#34;, mutableLiveData.value) } } All you have to do is add a InstantTaskExecutorRule() to the class containing ViewModel and add the following Gradle dependency:\ndependencies { testImplementation \u0026#39;android.arch.core:core-testing:1.1.1\u0026#39; } JUnit 5 # This doesn\u0026rsquo;t work for JUnit 5 however as the concept of Rule and TestRunner are merged into one single concept of Extensions.\nHence we can create a similar extension like the InstantTaskExecutorRule:\nimport androidx.arch.core.executor.ArchTaskExecutor import androidx.arch.core.executor.TaskExecutor import org.junit.jupiter.api.extension.AfterEachCallback import org.junit.jupiter.api.extension.BeforeEachCallback import org.junit.jupiter.api.extension.ExtensionContext class InstantExecutorExtension : BeforeEachCallback, AfterEachCallback { override fun beforeEach(context: ExtensionContext?) { ArchTaskExecutor.getInstance() .setDelegate(object : TaskExecutor() { override fun executeOnDiskIO(runnable: Runnable) = runnable.run() override fun postToMainThread(runnable: Runnable) = runnable.run() override fun isMainThread(): Boolean = true }) } override fun afterEach(context: ExtensionContext?) { ArchTaskExecutor.getInstance().setDelegate(null) } } This basically does two things:\nset a delegate before each test that updates live data values immediately on the calling thread remove the delegate after each tests to avoid influencing other tests. Using this, the JUnit 4 test can easily be converted to JUnit 5:\n@ExtendWith(InstantExecutorExtension::class) class PhotosViewModelTest { @Test fun `my test`() { val mutableLiveData = MutableLiveData\u0026lt;String\u0026gt;() mutableLiveData.postValue(\u0026#34;test\u0026#34;) assertEquals(\u0026#34;test\u0026#34;, mutableLiveData.value) } Voila! That\u0026rsquo;s it.\nWrap-up # In order to test LiveData, it\u0026rsquo;s values need to be directly updated on the calling thread. This can be done using a rule in JUnit 4 or an extension in JUnit 5.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"17 January 2019","externalUrl":null,"permalink":"/blog/2019/01/17/livedatajunit5/","section":"Blogs","summary":"Architecture components are one of the most exciting things that happened to Android in the past years. But how do you effectively go about and testing this?","title":"Testing LiveData in JUnit 4 and JUnit 5","type":"blog"},{"content":"Sitting in our own couch, in our own house, kids safely asleep upstairs,\u0026hellip; The road here was brutal, but the result is extraordinary.\nThe past year was (hopefully) the busiest year of my entire life. In the midst of raising two amazing kids, a challenging full-time job and being an active GDE, we built our dream house!\nLooking back I honestly don\u0026rsquo;t know how we managed to pull all of this off\u0026hellip; Choosing everything for the house, selecting and planning all contractors and even doing some (a lot more than anticipated) work myself\u0026hellip; Anyways, I won\u0026rsquo;t bother you with the details, but if not for my wife and kids I would have broken down completely. The goal justifies the means.\nAlso at work, it was a non-trivial and very demanding year. I used to pride myself for being great at keeping a work-life balance, but\u0026hellip; being a responsible for a team of people can really be quite intense.\nOur team had quite some challenges thrown at us, and we really made the best of it: sometimes massively successful, but we also struggled\u0026hellip; All in all, we did get a tight grip on our regression, laid the groundwork to improve our architecture and migrated to continuous deployment. (talk coming 2019 ;) )\nIn 2018, I/we mostly invested in our family\u0026rsquo;s future and:\nBuilt and moved into our dream house Helped our daughter go to school and taught our son how to walk Spoke at 4 big conferences and 1 meetup. Wrote 9 blog posts, not making my goal of 1 per month Almost double my Twitter followers to more than 3620 Got 6 times featured in Android weekly and several times in Kotlin weekly Exclusively used Kotlin for every blog post and slide deck Helped Pluralsight built a Kotlin: App Fundamentals assessment Looking forward to next year, I\u0026rsquo;m planning on living more! I\u0026rsquo;ve bought quite a few Lego\u0026rsquo;s I\u0026rsquo;d like to build, want to bring my kids to school by bike, spend more quality time with my wife and just professionally waste time on occasion. :)\nI\u0026rsquo;m going to try and increase my community efforts back to 2017 level and maybe experiment with some new formats, such as my last blog post.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"1 January 2019","externalUrl":null,"permalink":"/blog/2019/01/01/yearinreview/","section":"Blogs","summary":"Sitting in our own couch, in our own house, kids safely asleep upstairs,\u0026hellip; The road here was brutal, but the result is extraordinary.\nThe past year was (hopefully) the busiest year of my entire life.","title":"Year in review 2018","type":"blog"},{"content":"Learning from analyzing code is one of the greatest ways to improve your skills. Can you spot the mistakes in the tests below?\nThis post brings a fun little quiz for both testing gurus as novices, with a deep dive into the how and why of awesome tests.\nCase 1: sugary # // Instrumented test, run on Android device. @RunWith(AndroidJUnit4::class) class CalculatorTest : TestCase() { fun test_sumShouldAddNumbers() { val sum = Calculator().sum(1, 2) assertThat(sum).isEqualTo(3) } } Take a good look at the test above and think what you would do differently.\n\u0026hellip;\nDon\u0026rsquo;t worry, I\u0026rsquo;ll wait.\n\u0026hellip;\nReady?\nWell there are actually quite some things wrong with this test, but the main problem is the syntax:\nCalculatorTest inherits from TestCase test_sumShouldAddNumbers() is prefixed with test This is actually the old JUnit3 syntax, whereas Android currently supports JUnit4 (and even JUnit5).\nIn these newer frameworks, the inheritance and prefixing are not required. All you have to do is annotate each test method with @Test.\n// Instrumented test, run on Android device. @RunWith(AndroidJUnit4::class) class CalculatorTest { @Test fun sumShouldAddNumbers() { val sum = Calculator().sum(1, 2) assertThat(sum).isEqualTo(3) } } Interestingly enough the JUnit4 conversion enables two additional optimizations:\nsince test prefix is not required for test methods, we can use the backtick notation in Kotlin to make more descriptive test names (e.g. `sum of 1 and 2 should equal 3`) since we are only using JUnit4 now, there is no need to declare @RunWith(AndroidJUnit4::class) as this is only required to run both JUnit3 and 4 tests in the same file This dramatically clarifies our test:\nclass CalculatorTest { @Test fun `sum of 1 and 2 should equal 3`() { val sum = Calculator().sum(1, 2) assertThat(sum).isEqualTo(3) } } Note that the test above also doesn\u0026rsquo;t need to be run on an Android device as it doesn\u0026rsquo;t use the Instrumentation framework.\nThe @RunWith() annotation was only added to be able to explain what AndroidJunit4 does.\nTL;DR All you need is @Test annotations on test methods\nCase 2: exceptional # @Test fun `divide by zero should throw an exception`() { try { Calculator().divide(1, 0) fail(\u0026#34;No exception thrown\u0026#34;) } catch (e: RuntimeException) { } } Alright, now that you\u0026rsquo;re warmed up, have a good look at the next test.\n\u0026hellip;\nGoing for a quick coffee brb\u0026hellip;\n\u0026hellip;\nTrying to catch the exception yourself and making the test fail subsequently is quite verbose, no?\nThere is actually a better way of doing this, by using the expected annotation.\n@Test (expected = RuntimeException::class) fun `divide by zero should throw an exception`() { Calculator().divide(1, 0) } This doesn\u0026rsquo;t just amount to less code to write (and maintain) but you\u0026rsquo;ll also get a proper error message out of the box.\njava.lang.AssertionError: Expected exception: java.lang.RuntimeException TL;DR Use @Test (expected = \u0026hellip;) for expected exceptions\nCase 3: assertive # @Test fun `should ask WebService to login`() { val result = User(mockWebService).login() verify(mockWebService).login() verify(mockWebService, never()).logout() } An example with mocks this time! Can you spot the improvement?\n\u0026hellip;\nI\u0026rsquo;m not mocking you, I promise! ;)\n\u0026hellip;\nImagine for a second that the test above fails\u0026hellip; What could be the cause of that?\nThere are actually a few different possibilities:\neither login() was not called or logout() was called or both of the above Because the test can fail for multiple reasons, you can never conclude from the failure output what the problem is. Instead you have to dive deeper into each failing test, which can be quite time consuming and frustrating.\nWouldn\u0026rsquo;t it be nice if every tests would just fail for one single reason?\n@Test fun `login should ask WebService to login`() { val result = User(mockWebService).login() verify(mockWebService).login() } @Test fun `login shouldn\u0026#39;t ask WebService to logout`() { val result = User(mockWebService).login() verify(mockWebService, never()).logout() } If one of those fail, the test message will immediate tell you what\u0026rsquo;s going wrong!\nThis actually isn\u0026rsquo;t the only reason why you should only use one single assert/verify per test:\nJUnit4 stops test execution after the first failure: so if the first assert fails, the following ones aren\u0026rsquo;t executed! Consequently you don\u0026rsquo;t know how many problems there are on test failure.\nToo many assertions can make code nearly impossible to refactor: To fully test a login functionality, you probably need over 10 tests (username null, wrong password,\u0026hellip;), right? Imagine that every single test also explicitly checks that logout isn\u0026rsquo;t called on login\u0026hellip; What happens now if your requirement changes and you need to support immediate logout after login? (e.g. For Android Wear) Then you would have to refactor all those tests!!!\nTL;DR Use only one assert/verify per test\nCase 4: divided # @Test fun `should do multiple calculations`() { val calculator = Calculator() val sum = calculator.sum(1, 2) val division = calculator.divide(sum, 3) assertThat(division).isEqualTo(1f) } \u0026hellip;\nYou know the drill\u0026hellip;\n\u0026hellip;\nLet\u0026rsquo;s step through the test: first it calculates the sum of 1 and 2, followed by a division of the result by 3.\nWhy are we testing that sequence? Mathematical operations (add/divide) aren\u0026rsquo;t supposed to have side effects (and influence each other), right?\nEven more, the interface of Calculator makes that clear: both sum() and divide() take all parameters they need as an input to produce an output.\nSo if sum() and divide() are already tested, there really isn\u0026rsquo;t an added benefit of testing the sequence, right?\nInstead, there are quite some disadvantages:\nthe combined test is harder to understand (more steps) the combined test can fail due to multiple reasons (causing more failure analysis effort). it\u0026rsquo;s unclear what combinations of steps should be tested and which ones not (where do you stop?) not really a unit test Hence this test should be split it two:\n@Test fun `sum of 1 and 2 should be 3`() { val sum = Calculator().sum(1, 2) assertThat(sum).isEqualTo(3) } @Test fun `division of 3 and 3 should be 1f`() { val division = Calculator().divide(3, 3) assertThat(division).isEqualTo(1f) } TL;DR Only unit test one method per test\nCase 5: readable # class WebServiceTest { lateinit var webService: WebService @Before fun setUp() { webService = WebServiceTestHelper.createWebService() } @Test fun `login should fail when wrong password`() { val result = webService.login() checkLoginFailed(result) } } Let\u0026rsquo;s make things slightly more interesting\u0026hellip;\n\u0026hellip;\nAny ideas?\n\u0026hellip;\nIn order to understand what\u0026rsquo;s bad about this test, you need to imagine a lot more tests in the same file.\nIf you where to encounter the test above somewhere in a file with a lot more tests, it would take you quite some time to figure out what\u0026rsquo;s going on:\nNeed to look at setUp() method to understand where the WebService under test is coming from Need to open WebServiceTestHelperto understand the WebService initialization Need to open checkLoginFailed() method to see how a failed login is identified That\u0026rsquo;s a lot of work!\nThe problem here is that the reader constantly has to exit the test method to figure out what\u0026rsquo;s going on.\nRemoving the setUp method, inlining the WebServiceTestHelper and the checkLoginFailed() method yields the following.\nclass WebServiceTest { @Test fun `loginHasFailed`() { var webService = WebService() webService.setUserCredentials(\u0026#34;email@google.com\u0026#34;, “wrong_pwd”) val result = webService.login() assertThat(result.isSuccess).isFalse() } } Notice how easy it has now become to understand what\u0026rsquo;s going on in the test!\nBut wouldn\u0026rsquo;t that lead to quite some code duplication you say? Well, I\u0026rsquo;m glad you ask. YES! But even though testing code is also production code, the same rules don\u0026rsquo;t completely apply.\nIt is fine for test code to have duplication, magic numbers/strings, long method names,\u0026hellip; Readability and ease of fixing failures are what matter most.\nTL;DR Always keep the reader within the test function\nCase 6: trustworthy # @Test fun `should properly format time`() { val expectedTime = FORMAT.format(Date()) val formattedTime = TimeFormatter().currentFormattedTime assertEquals(expectedTime, formattedTime) } companion object { private val FORMAT = SimpleDateFormat(\u0026#34;HH:mm:ss:SSS\u0026#34;) } And the final contender of the day is\u0026hellip;\n\u0026hellip;\nAny ideas?\n\u0026hellip;\nSimply put, this test is flaky. It will only fail very rarely, but still it will.\nReason for this is that the expectedTime isn\u0026rsquo;t the time used by the TimeFormatter and hence there will be a slight difference (~ ns) between both. When rounding works against us, this could actually end up in a real formatted ms difference.\nAnd flakiness in tests, well\u0026hellip; no matter how infrequent, we should have a zero tolerance policy towards them. This is because flakiness can completely destroy the confidence of the team in the test suite.\nFortunately this can easily be fixed by passing the current time into the TimeFormatter.\n@Test fun `should properly format time`() { val now = Date() val expectedTime = FORMAT.format(now) val formattedTime = TimeFormatter(now).currentFormattedTime assertEquals(expectedTime, formattedTime) } companion object { private val FORMAT = SimpleDateFormat(\u0026#34;HH:mm:ss:SSS\u0026#34;) } TL;DR Tests should never randomly fail\nWrap-up # Putting it all together, great tests follow the following principles:\nAll you need is @Test annotations on test methods Use @Test (expected = \u0026hellip;) for expected exceptions Only one assert/verify per test Only unit test one method per test Always keep the reader within the test function Tests should never randomly fail Check out my slides/video to learn more about awesome unit tests.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"6 December 2018","externalUrl":null,"permalink":"/blog/2018/12/06/fixthetest/","section":"Blogs","summary":"Learning from analyzing code is one of the greatest ways to improve your skills. Can you spot the mistakes in the tests below?\nThis post brings a fun little quiz for both testing gurus as novices, with a deep dive into the how and why of awesome tests.","title":"Can you fix the test?","type":"blog"},{"content":"","date":"6 December 2018","externalUrl":null,"permalink":"/tags/cleancode/","section":"Tags","summary":"","title":"Cleancode","type":"tags"},{"content":"Java interop is one of the best features of the Kotlin language, yet sometimes this also can cause unforeseen issues\u0026hellip;\nPuzzle # Disclaimer, the example below is a consequence of legacy code and only serves to demonstrate a Kotlin puzzler.\nHave a look at the simple test class below. It subclasses the subject under test (BaseFragment) to inject a mocked Repository that is used by the getDataOperation() method in the test.\nclass BaseFragmentTest { @get:Rule public val mockitoRule = MockitoJUnit.rule() @Mock lateinit var repository: Repository @Test fun `data should be as expected`() { val actual = TestFragment().getDataOperation() assertEquals(actual, \u0026#34;expected\u0026#34;) } inner class TestFragment : BaseFragment() { override fun getRepository(): Repository { return repository } } } What do you think will happen we run the test?\n\u0026hellip;\nWell\u0026hellip;\n\u0026hellip;\njava.lang.StackOverflowError at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) at com.jeroenmols.BaseFragmentTest$TestFragment.getRepository(BaseFragmentTest.kt:26) Wait, what???\nThis trace indicates that the line return repository (line 26) is called recursively\u0026hellip; How is that even possible? That line just return a value, right?\nWell\u0026hellip;\nExplanation # This is actually a very interesting case of Java/Kotlin interop. Because a Kotlin property is compiled down to the following Java elements:\na getter method with get prefix a setter method with set prefix a private field backing the property Hence the return repository statement actually ends up executing return getRepository() and hence recursively calling itself!\nNow the really interesting detail here is that this only happens when BaseFragment is a Java class! When converting the class to Kotlin this doesn\u0026rsquo;t happen.\nSo let\u0026rsquo;s have a look at the decompiled bytecode:\n// Decompiled when BaseFragment in Java public final class TestFragment extends BaseFragment { @NotNull public Repository getRepository() { return this.getRepository(); } } // Decompiled when BaseFragment in Kotlin public final class TestFragment extends BaseFragment { @NotNull public Repository getRepository() { return BaseFragmentTest.this.getRepository(); } } Sure enough, the decompiled Java code recursively links to the TestFragment when BaseFragment is in java and properly links to the right method when BaseFragment is in Kotlin.\nA simple way to fix this is to strongly refer the overridden method to point at the BaseFragmentTest class:\ninner class TestFragment : BaseFragment() { override fun getRepository(): Repository { return this@BaseFragmentTest.repository } } Fortunately Android Studio also warns you about recursion with an indicator:\nWrap-up # This post indicates an interesting case where methods/properties get linked incorrectly when inheriting from a Java class in Kotlin. Fortunately, Android Studio and the decompiled bytecode clearly indicate what is going wrong.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"1 November 2018","externalUrl":null,"permalink":"/blog/2018/11/01/kotlinstackoverflow/","section":"Blogs","summary":"Java interop is one of the best features of the Kotlin language, yet sometimes this also can cause unforeseen issues\u0026hellip;\nPuzzle # Disclaimer, the example below is a consequence of legacy code and only serves to demonstrate a Kotlin puzzler.","title":"Kotlin Stackoverflow error","type":"blog"},{"content":"","date":"1 November 2018","externalUrl":null,"permalink":"/tags/puzzle/","section":"Tags","summary":"","title":"Puzzle","type":"tags"},{"content":"","date":"1 November 2018","externalUrl":null,"permalink":"/tags/stackoverflow/","section":"Tags","summary":"","title":"Stackoverflow","type":"tags"},{"content":"","date":"5 October 2018","externalUrl":null,"permalink":"/tags/conference/","section":"Tags","summary":"","title":"Conference","type":"tags"},{"content":"","date":"5 October 2018","externalUrl":null,"permalink":"/tags/kotlinconf/","section":"Tags","summary":"","title":"Kotlinconf","type":"tags"},{"content":"Was really great visiting Kotlinconf this year and I wanted to do a quick post to link to all of it\u0026rsquo;s wonderful content.\nConference slides # While you will be able to find all recordings here, I often find it useful to be able to quickly scan through the slides. Hence I bundled everything I could already find from socials.\nAndroid suspenders by Chris Banes GraphQL powered by Kotlin by Annyce Davis Type safe build logic with the Gradle Kotlin DSL by Hans Dockter \u0026amp; Paul Merlin Annotation processing in a Kotlin world by Zac Sweers Beat the high-score: build a game using libGDX and Kotlin by David Wursteisen The Kotlin Type Hierarchy From Top to Bottom by Nat Pryce Writing Browser Extensions in Kotlin by Kirill Rakhman Kotlin and Spring Boot, a match made in heaven by Nicolas Frankel Effective multiplatform Kotlin development by Marcin Moskala Mathematical Modeling with Kotlin by Thomas Nield Live Coding Kotlin/Native Snake by Dmitry Kandalov A Multiplatform Delight by Jake Wharton and Alec Strong Graphics Programming with Kotlin by Romain Guy Creating Internal DSLs in Kotlin by Venkat Subramaniam Exploring Coroutines in Kotlin by Venkat Subramaniam Kotlin puzzlers by Anton Keks Android KTX: A dash of Kotlin makes all the difference! by Dan Kim Learn together. Not the same. by Amal Kakaiya and Maria Neumayer Speaker Deck Making Noise With Kotlin/Native by Josh Skeen Servers ❤️ Kotlin by Ryan Harter Server as a Function in Kotlin by Ivan Sanchez Building Data Science Workflows with Kotlin by Holger Brandl Dissecting the stdlib by Huyen Tue Dao Kotlin - a great fit for the Ethereum ecosystem by Marcus Ligi Painless Microservices in Kotlin by Fedor Korotkov Performant Multiplatform Kotlin Serialization by Eric Cochran iOS Architecture with Multiplatform by Kevin Galligan Writing Stream Processors in Kotlin by Mario Mueller What\u0026rsquo;s the big IDEA? Writing IntelliJ plugins for Kotlin by Alec Strong and Egor Andreevici Next Level DSLs by Aaron Sarazan Writing Your First Kotlin Compiler Plugin by Kevin Most Sealed classes opened my mind by Patrick Cousins Kotlin: The Next Frontier for Modern (Meta)Programming by Amanda Hinchman-Dominguez Functional Programming in Kotlin with Λrrow by Raúl Raja Martínez Credits # Many thanks to the JetBrains team for organizing such a delightful conference! To all sponsors for making this event possible. And to the entire Android community for being so awesome!\nHope to see you all next year!\nHelpful? Got extra slides? Hit me up on Mastodon.\n","date":"5 October 2018","externalUrl":null,"permalink":"/blog/2018/10/05/kotlinconf18/","section":"Blogs","summary":"Was really great visiting Kotlinconf this year and I wanted to do a quick post to link to all of it\u0026rsquo;s wonderful content.\nConference slides # While you will be able to find all recordings here, I often find it useful to be able to quickly scan through the slides.","title":"Kotlinconf 2018 slides","type":"blog"},{"content":"Kotlin is an incredibly enjoyable, concise and powerful programming language. Yet sometimes also a bit confusing\u0026hellip;\nPuzzle # Have a look at the simple class below. It simulates an ongoing operation by smoothly moving a progress bar from 0 to 100 over the course of 30 seconds:\nclass ProgressbarAnimator(private val progressBar: ProgressBar) : AnimatorUpdateListener { private lateinit var animator: ValueAnimator init { configureAnimator() animator.addUpdateListener { this } animator.start() } fun configureAnimator() { val endValue = (FPS * DURATION).toInt() progressBar.max = endValue animator = ValueAnimator.ofInt(0, endValue) animator.duration = DURATION animator.interpolator = LinearInterpolator() } override fun onAnimationUpdate(p: ValueAnimator?) { progressBar.progress = animator.animatedValue as Int } companion object { private const val FPS = 0.06 private const val DURATION = 30 * 1000L } } What do you think will happen if we instantiate one of these with a given progress bar?\nWell\u0026hellip; nothing! The progress bar doesn\u0026rsquo;t move at all.\nCan you spot what\u0026rsquo;s wrong? The error is in the following lines:\ninit { configureAnimator() animator.addUpdateListener { this } animator.start() } Any luck?\n\u0026hellip;\n\u0026hellip;\n\u0026hellip;\nWell this is the actual culprit:\nanimator.addUpdateListener { this } There is syntactically a very subtle, yet incredibly important difference between that line and this:\nanimator.addUpdateListener(this) If we change our init to the latter, then the progress bar works as expected!\nExplanation # One of the Kotlin features is that if the last argument of a method call is a lambda, you can move the lambda outside of the method invocation. (which is great for building DSLs)\nConsequently,\nanimator.addUpdateListener { this } is equivalent to\nanimator.addUpdateListener() { this } and even\nanimator.addUpdateListener({ this }) and by expanding the lambda, this\nanimator.addUpdateListener({ _ -\u0026gt; this }) So the reason why the progress bar wasn\u0026rsquo;t working is simple. Instead of registering itself as an AnimationUpdateListener, it actually registered a lambda, a new function to handle the animation updates.\nSo every animation update the lambda { _ -\u0026gt; this } was invoked instead of the onAnimationUpdate method. Thereby not doing anything, it just has the this object without any invocation on it.\nEquivalent to writing the following function:\nfun doNothing() { 5 } Perfectly valid syntax, but otherwise completely useless.\nWrap-up # A very subtle difference in syntax ({} instead of ()) can make a huge difference in what the code actually does. Kotlin is a very powerful programming language, but with great power comes great\u0026hellip;\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"25 September 2018","externalUrl":null,"permalink":"/blog/2018/09/25/kotlinpuzzler/","section":"Blogs","summary":"Kotlin is an incredibly enjoyable, concise and powerful programming language. Yet sometimes also a bit confusing\u0026hellip;\nPuzzle # Have a look at the simple class below.","title":"A little Kotlin puzzler","type":"blog"},{"content":"","date":"25 September 2018","externalUrl":null,"permalink":"/tags/lambda/","section":"Tags","summary":"","title":"Lambda","type":"tags"},{"content":"This is a post-mortem where the very dangerous permission, READ_PHONE_STATE, unintentionally sneaked into our app. Here\u0026rsquo;s how this could happen, how we debugged and finally how we solved it.\nPrologue # Sprint comes to an end and we\u0026rsquo;re happy to deliver a new release of our app. After rolling it out to our beta community without issues, we move ahead to production.\nWhile everything looks fine at first, after a while we see users complaining:\nHonestly we were completely taken aback by this\u0026hellip; But sure enough looking at the play store:\nRoot cause # If you ever run into a similar issue, the Android Studio merged manifest view is the way to go. Just open your manifest and click the Merged manifest tab at the bottom.\nSure enough, the READ_PHONE_STATE permission is there.\nUnfortunately, this view couldn\u0026rsquo;t help us find where the permission was merged from:\nDouble-clicking the permission led us back to normal manifest view Color coding palette is so subtle that we couldn\u0026rsquo;t see what color the permission was highlighted in Fortunately, the manifest merger also prints a log file to build/outputs/logs that describes where everything is merged from.\nThis file gave a clear answer:\nuses-permission#android.permission.READ_PHONE_STATE IMPLIED from /app/src/debug/AndroidManifest.xml:8:1-15:12 reason: hue.libraries.translations has a targetSdkVersion \u0026lt; 4 Wow\u0026hellip; That\u0026rsquo;s nasty!\nA while ago we decided to move all our translations to a new module, with an empty manifest and a bare-bones build.gradle file:\napply plugin: \u0026#39;com.android.library\u0026#39; android { compileSdkVersion Config.compileSdk } And because we didn\u0026rsquo;t explicitly set the targetSdk, a targetSdk of 1 is assumed and hence we end up with a dangerous permission!\nTo be fair, the documentation does warn you about this:\nBut still\u0026hellip; wow!\nSolution # While a solution could be to simply set the targetSdk in our translations module. This wouldn\u0026rsquo;t prevent something similar from happening in the future.\nTherefore we decided to set the targetSdk (and others) for all our modules in the top level build.gradle file. This also keeps submodule build.gradle files lean.\nsubprojects { afterEvaluate { project -\u0026gt; if (project.plugins.findPlugin(\u0026#39;android\u0026#39;) ?: project.plugins.findPlugin(\u0026#39;android-library\u0026#39;)) { android { buildToolsVersion Config.buildTools compileSdkVersion Config.compileSdk defaultConfig { minSdkVersion Config.minSdk targetSdkVersion Config.compileSdk } compileOptions { sourceCompatibility Config.javaVersion targetCompatibility Config.javaVersion } } } } } Additionally, we also wanted to protect ourselves against 3rd party library developers that could make this mistake. To do so, you can inform the manifest merger to remove the permission while merging by adding the following to your manifest:\n\u0026lt;uses-permission android:name=\u0026#34;android.permission.READ_PHONE_STATE\u0026#34; tools:node=\u0026#34;remove\u0026#34;/\u0026gt; That is overkill you say?\nWell, Firebase AND Google play services already made this booboo in the past.\n\u0026hellip; wow!\nWrap-up # Not explicitly setting your target SDK version will cause a dangerous permission to sneak into your app. Make sure you set the target SDK in every module and protect yourself from 3rd party libraries.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"2 August 2018","externalUrl":null,"permalink":"/blog/2018/08/02/phonestatepermission/","section":"Blogs","summary":"This is a post-mortem where the very dangerous permission, READ_PHONE_STATE, unintentionally sneaked into our app. Here\u0026rsquo;s how this could happen, how we debugged and finally how we solved it.","title":"How dangerous permissions sneak into apps","type":"blog"},{"content":"","date":"2 August 2018","externalUrl":null,"permalink":"/tags/manifest/","section":"Tags","summary":"","title":"Manifest","type":"tags"},{"content":"","date":"2 August 2018","externalUrl":null,"permalink":"/tags/modules/","section":"Tags","summary":"","title":"Modules","type":"tags"},{"content":"","date":"2 August 2018","externalUrl":null,"permalink":"/tags/permissions/","section":"Tags","summary":"","title":"Permissions","type":"tags"},{"content":"","date":"2 August 2018","externalUrl":null,"permalink":"/tags/post-mortem/","section":"Tags","summary":"","title":"Post-Mortem","type":"tags"},{"content":"","date":"16 July 2018","externalUrl":null,"permalink":"/series/android-studio-shortcuts/","section":"Series","summary":"","title":"Android Studio Shortcuts","type":"series"},{"content":"","date":"16 July 2018","externalUrl":null,"permalink":"/tags/androidstudio/","section":"Tags","summary":"","title":"Androidstudio","type":"tags"},{"content":"Not only can anything in Android Studio be controlled with a keyboard shortcut, it offers many more simple tricks to make you more productive.\nTo conclude this series, we will look at how you can control the interface, invoke every (!) action and point you to even more advanced features.\nTL;DR # I strongly suggest you look at the examples below, but a quick reference is always useful.\n⌥ + number: open/close views\n⇧ + ⌘ + ↑: enlarge view\n⇧ + ⌘ + ↓: shrink view\n⇧ + ⌘ + →: enlarge side view\n⇧ + ⌘ + ←: shrink side view\n⇧ + ⌘ + F12: close all views\n⇧ + ⌘ + ]: next tab\n⇧ + ⌘ + [: previous tab\n^ + ⇧ + →: text view (xml layout editing)\n^ + ⇧ + ←: design view (visual layout editing)\n⌥ + letter: invoke button\n⌘ + ⇧ + A: action lookup\nTaming the interface # Using your keyboard is always more efficient than using a mouse. This is because you can make use of all your fingers at the same time + you don\u0026rsquo;t have to switch between mouse and keyboard.\nWouldn\u0026rsquo;t it be cool if we never have to use our mouse again?\nFirst of all you can use ⌥ + number to open/close different Android Studio views (e.g. Logcat, Project view,\u0026hellip;)\nUse ⌥ + number to open/close different Android Studio views You can shrink/enlarge the views above using ⇧ + ⌘ + ↑ and ⇧ + ⌘ + ↓ respectively,\nUse ⇧ + ⌘ + ↑ and ⇧ + ⌘ + ↓ to shrink or enlarge views Note that this will also work with ⇧ + ⌘ + → and ⇧ + ⌘ + ← for side views.\nOr close all views with ⇧ + ⌘ + F12 to have a clutter free interface,\nUse ⇧ + ⌘ + F12 to close all views When you have multiple tabs open, ⇧ + ⌘ + [ and ⇧ + ⌘ + ] come in handy to cycle between tabs.\nUse ⇧ + ⌘ + [ and ⇧ + ⌘ + ] to cycle between tabs If you\u0026rsquo;re designing layouts, you can use ^ + ⇧ + → and ^ + ⇧ + ← to switch between design and text view.\nUse ^ + ⇧ + → and ^ + ⇧ + ← to switch between design and text view And whenever you have a dialog open you can use ⌥ to highlight what letters you can press to invoke the respective buttons. E.g. in the example below ⌥ + R is used to press the replace button.\nUse ⌥ to highlight what letters you can press to invoke the respective buttons Note that pressing ⌥ helps in a lot more situations such as in the find and replace window. (notice the subtle underline)\nPressing ⌥ reveals you can use ⌥ + p to replace the next occurrence Shortcut lookup # If there is one shortcut you should really remember, then that is ⌘ + ⇧ + A. That one allows you to invoke any Android Studio action using your keyboard.\nUse ⌘ + ⇧ + A to search for any action. Note that this also serves as a useful shortcut lookup tool. Next to every action the corresponding shortcut will be displayed (if there is one).\nAdditional reads # Android Studio is incredibly powerful and hence this blog post series couldn\u0026rsquo;t cover everything. However, if I piqued your interest, have a look at these references:\nUsing multicursor in Android studio by Kevin Pelgrims Permantent function keys in Android Studio with Macbook pro Touchbar By Georg Apitz Structural search and replace by Darren Android studio live templates by Retro Meier Postfix code completion by Vojtech Ruzicka\u0026rsquo;s Wrap up # Investing time to really learn Android Studio can mean a big productivity boost. Start with ⌘ + ⇧ + A, learn the corresponding shortcuts and challenge yourself to use your mouse less.\nThis was the last part in my series to get the most out of Android Studio.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"16 July 2018","externalUrl":null,"permalink":"/blog/2018/07/16/androidstudioshortcuts3/","section":"Blogs","summary":"Not only can anything in Android Studio be controlled with a keyboard shortcut, it offers many more simple tricks to make you more productive.\nTo conclude this series, we will look at how you can control the interface, invoke every (!","title":"Pro Android Studio - Taming the interface","type":"blog"},{"content":"","date":"16 July 2018","externalUrl":null,"permalink":"/tags/shortcuts/","section":"Tags","summary":"","title":"Shortcuts","type":"tags"},{"content":"Refactoring can be tedious and easily introduce bugs. The main reason for this is the number of manual steps involved: rename, move, copy-paste,\u0026hellip; So wouldn\u0026rsquo;t it make sense to automate this and have Android Studio do all the work for you?\nThis post will zoom in on the most useful refactoring options of Android Studio. Enabling you to refactor more confidently, introduce fewer bugs and increase overall quality as also variables, documentation, etc. will be updated.\nTL;DR # I strongly suggest you look at the examples below, but a quick reference is always useful.\n⌘ + D: duplicate line\n⌘ + backspace: delete line\n⌘ + ↑: move line up\n⌘ + ↓: move line down\n⇧ + ⌘ + ↑: move method up\n⇧ + ⌘ + ↓: move method down\n⇧ + F6: rename\n⌘ + F6: change method signature\nF6: move\n⌥ + ⌘ + V: extract variable\n⌥ + ⌘ + M: extract method\n⌥ + ⌘ + P: extract method parameter\n⌥ + ⌘ + F: extract property (or field)\n⌥ + ⌘ + C: extract constant (java only)\n⌥ + ⌘ + N: inline\n^ + T: open refactoring menu\n⌥ + enter: quick fix\nWindows equivalents can be found here.\nCode manipulation # In order to speed up development, you want to reduce the amount of typing to a minimum. While autocomplete definitely helps, sometimes it\u0026rsquo;s faster to directly manipulate lines:\n⌘ + D: duplicate line ⌘ + backspace: delete line These shortcuts will work regardless of the cursor position in the line.\nDuplicate and delete lines After duplicating you can simply move code up/down by using ⌘ + ↑ and ⌘ + ↓ for lines, or ⇧ + ⌘ + ↑ and ⇧ + ⌘ + ↓ for methods.\nMove lines and methods up/down Both combined provide a powerful way of extending code: you duplicate a line, edit it and move it to its location.\nQuick edit lines via duplicate and move Rename, update and move # Renaming classes is very involved: rename class definition, rename the file and update all references and documentation. Fortunately ⇧ + F6 does all of that for you.\nRename anything with ⇧ + F6 This doesn\u0026rsquo;t just work for classes, but also for methods, variables, fields,\u0026hellip;\nSimilarly ⌘ + F6 allows you to update the signature of a method. This is especially useful to add, remove or reorder new parameters to the method definition.\nChange method signature with ⌘ + F6 Note how you can specify a default value so all existing method consumers will be updated by Android Studio! Use ⌘ + ↑ and ⌘ + ↓ to quickly reorder parameters.\nFinally, you can move classes to their own file or to another package using F6. This works for all top-level declarations and Java static methods/constants.\nMove classes with F6 Refactoring # To clean up code it is often handy to convert values into variables with a meaningful name. This is easy using ⌥ + ⌘ + V.\nExtract variable with ⌥ + ⌘ + V Note that you can either replace one or all occurrences.\nSimilarly, you can extract code into a method with ⌥ + ⌘ + M and give it an easy to understand name.\nExtract method with ⌥ + ⌘ + M You can even convert a variable to a parameter that is injected into the method using ⌥ + ⌘ + P.\nExtract parameter with ⌥ + ⌘ + P If this makes another parameter obsolete, then it will be automatically removed from the method signature.\nSame holds true to create properties, by using ⌥ + ⌘ + F.\nExtract property with ⌥ + ⌘ + F Note that for Java you can also use ⌥ + ⌘ + C to extract a static final field. This isn\u0026rsquo;t available for Kotlin however.\nBesides extracting, you can also do the inverse operation: inlining ⌥ + ⌘ + N. This is available for almost everything you can extract: methods, variables, properties,\u0026hellip;\nInline method or variable with ⌥ + ⌘ + N Inlining gives you the option to inline it only in one place or everywhere. Plus you can optionally still keep the inlined variable or method.\nWhile the above refactorings are the most commonly used ones, Android Studio actually offers quite a lot more if you press ^ + T:\nAll refactoring options I strongly encourage you to experiment with these and learn how they work. Good knowledge of these can dramatically speed up your development and reduce mistakes.\nAndroid studio quick fixes # With ⌥ + enter Android Studio is able to quickly fix a number of common issues: add imports, remove unused method, remove unused parameter, restrict access modifiers,\u0026hellip;\nQuick fix problems with ⌥ + enter This quick fix option is significantly more powerful than you might think. Have a look at the function below:\nfun shouldFollowAuthorOnTwitter(isBadBlogPost: Boolean, hasReadArticle: Boolean): Boolean { val isBlogJeroen = true if (isBlogJeroen) { if (!isBadBlogPost \u0026amp;\u0026amp; hasReadArticle) { return true } } return false } Not easy to understand, is it?\nLet\u0026rsquo;s now use Android Studio to simplify this complex code for us.\nSimplify if statements Pretty cool, no?\nEven better: this procedure is 100% safe!!! This is because we\u0026rsquo;ve offloaded all correctness checks and code changes to our IDE.\nIf you\u0026rsquo;re interested in the next posts it\u0026rsquo;s probably best to follow me on Mastodon.\nWrap up # Refactoring can be tedious and easily introduce bugs. Therefore we should automate as much as we can using Android Studio.\nThis was part two of my series to get the most out of Android Studio.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"26 April 2018","externalUrl":null,"permalink":"/blog/2018/04/26/androidstudioshortcuts2/","section":"Blogs","summary":"Refactoring can be tedious and easily introduce bugs. The main reason for this is the number of manual steps involved: rename, move, copy-paste,\u0026hellip; So wouldn\u0026rsquo;t it make sense to automate this and have Android Studio do all the work for you?","title":"Pro Android Studio - Refactoring","type":"blog"},{"content":"Struggling to navigate your code? Getting lost in deep inheritance hierarchies? Hard time figuring out relations between classes? Let\u0026rsquo;s learn how to navigate code in Android Studio like a pro.\nBeing a skilled Android developer means getting the most out of the tools at your disposal. While there are plenty resources listing shortcuts, it\u0026rsquo;s often hard to make sense and master those.\nTherefore this series aims to be a practical guide with clear examples on how to better navigate and refactor code. It will effectively cover how I personally use Android Studio.\nTL;DR # I strongly suggest you look at the examples below, but a quick reference is always useful.\n⌘ + O: find class\n⌘ + ⌥ + O: find symbol\n⌘ + ⇧ + O: find file\n⇧ + ⌘ + T: go to/from test\n⌘ + ⌥ + F7: show usages\n⌘ + U: jump to superclass/defining method\n⌘ + ⌥ + B: jump to subclass/overridden method\n^ + H: show class hierarchy\n⌘ + F12: show methods\n⌘ + B: go to declaration\nF2: next error/warning\n⇧ + F2: previous error/warning\n⌘ + L: go to line\n⌘ + E: show recent files\n⌘ + [: to previous code position\n⌘ + ]: to next code position\n⌘ + ⇧ + backspace: to last code edit\nWindows equivalents can be found here.\nOpening classes and files # Better than search everywhere is telling Android Studio what you are looking for:\n⌘ + O: a class ⌘ + ⌥ + O: a symbol ⌘ + ⇧ + O: a file This makes search a lot faster and returns fewer, more relevant results!\nSearched for classes but needed a file? Just hit ⌘ + ⇧ + O while open to dynamically swap between modes. You can even use Camel Casing to quickly find AlbumActivityTest by typing AlAT or directly jump to a line number by adding :.\nOpen classes, symbols or files Already found the class you were looking for, but quickly want to go to the test? Go to the class declaration and use ⇧ + ⌘ + T. It even suggests to create a new test and also works from the test.\nNavigate between test and class with ⌘ + T Relationships between classes # If you want to figure out where a class is being used? ⌘ + ⌥ + F7 shows it in a handy pop over. Note that you can show the same info in the find tab using ⌘ + F7 for a more static view.\nShow class usages with ⌘ + ⌥ + F7 Inheritance hierarchies are typically easy to get lost in.\nDid you know you can use ⌘ + U to jump to the super class or ⌘ + ⌥ + B to go to a sub class? It even works for method overrides!\nNavigate between super- and subclasses Finally, ^ + H dumps out the entire class hierarchy in a handy overview.\nShow class hierarchy with ^ + H Structure of classes # Use ⌘ + F12 to show all methods and properties of a class. Like any other view in Android Studio, even this one is searchable.\nShow class methods and properties with ⌘ + F12 Come across a member in code? With ⌘ + B you can immediately jump to where it is defined. Tapping ⌘ + B a second time shows you where it is used.\nGo to declaration and show usages with ⌘ + B Be it a failing build due to multiple errors, or you scroll away from broken code under development. Compilation errors are common and can be hard to navigate to.\nUsing F2 and ⇧ + F2, however, will let you jump back and forth between all errors in a file. If there are none, those keys will do the same for all warnings.\nNavigate between errors/warnings in a file Know the exact line number? Then ⌘ + L is the shortcut for you.\nGo to a specific line in a file with ⌘ + L History # With all these new code navigation superpowers, there is one critical element missing: how do you find your way back to where you started?\nOne of the well-known options is to use ⌘ + E to list your recently opened files.\nList recently opened files with ⌘ + E However, when clicking through code you can also use ⌘ + [ and ⌘ + ] to take a step back or forth respectively.\nNavigate between previous visited code And finally, if you just want to continue coding where you left off, use ⌘ + ⇧ + backspace to jump to where you made the last code edit.\nNavigate to the last edited code with ⌘ + ⇧ + backspace If you\u0026rsquo;ve made it this far you should probably follow me on Mastodon.\nWrap up # This was part one of my series to get the most out of Android Studio, feel free to continue reading [the second part]({{ site.baseurl }}{% link blog/_posts/2018-04-26-androidstudioshortcuts2.md %}).\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\nSpecial thanks to Antonio Leiva, all gifs are made with code from his open source project Bandhook.\n","date":"22 February 2018","externalUrl":null,"permalink":"/blog/2018/02/22/androidstudioshortcuts/","section":"Blogs","summary":"Struggling to navigate your code? Getting lost in deep inheritance hierarchies? Hard time figuring out relations between classes? Let\u0026rsquo;s learn how to navigate code in Android Studio like a pro.","title":"Pro Android Studio - Code navigation","type":"blog"},{"content":"For the first time ever I have my year in review ready in time.\nI\u0026rsquo;m sure I\u0026rsquo;ll never forget 2017. Not only did we start building our dream house, but more importantly, our family grew to 4 people! Our baby girl Lene - ahum Toddler - became the big sister of our newborn son Wout. While having two kids is definitely very, very intense, it\u0026rsquo;s extraordinary to see them grow and a privilege to experience how fond they already are of each other.\nFor my career this was the most remarkable year so far as I:\nBecame a Google Developer Expert for Android Built up an internal app team and became the Lead Android developer at Philips Hue Started my own company Build IT bvba Further, I\u0026rsquo;m super proud of all my community efforts:\nSpoke at 4 big conferences + 5 local meetups Wrote 13 blog posts, exceeding my goal of 1 per month Grew my Twitter followers to more than 1850 Had the 12th most influential Android blog in the world Got 5 times featured in Android weekly and once in Kotlin weekly Gave the 8th highest rated talk at Devoxx Revamped my website with https, faster loading, and search But leave no mistake, my family is and will always be the most important thing in the world!\nLooking forward to next year, stuff is going to be intense for sure! We\u0026rsquo;ll complete the construction of our house, our daughter will start going to school, our son will likely learn how to walk,\u0026hellip; and I don\u0026rsquo;t want to miss a second of all that. Which means #latenightblogging. :)\nSo I\u0026rsquo;m not going to increase my community efforts, but instead, I\u0026rsquo;d like to experiment with data analytics to increase the impact of all my typical efforts.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"1 January 2018","externalUrl":null,"permalink":"/blog/2018/01/01/yearinreview/","section":"Blogs","summary":"For the first time ever I have my year in review ready in time.\nI\u0026rsquo;m sure I\u0026rsquo;ll never forget 2017. Not only did we start building our dream house, but more importantly, our family grew to 4 people!","title":"Year in review 2017","type":"blog"},{"content":"","date":"26 December 2017","externalUrl":null,"permalink":"/tags/macos/","section":"Tags","summary":"","title":"Macos","type":"tags"},{"content":"Tonight after a routine MacOS update (10.13.2) disaster struck and my Mac got stuck in an update boot loop. After a few hours of panic, reading online and trial \u0026amp; error I managed to resolve it. Here\u0026rsquo;s what I did in the hope it also helps someone else.\nSteps # From the \u0026ldquo;MacOS could not be installed on your computer\u0026rdquo; screen:\nPress and hold \u0026ldquo;option\u0026rdquo; key and click restart In the \u0026ldquo;Startup disk selection\u0026rdquo; screen, use the arrow keys to select your main hard drive (not the MacOS update) Wait for your Mac to boot normally Download the latest combo update directly from Apple. (this is a full system image, not an incremental update) Open and install the update Grab a snickers, this will take a while My environment: 2017 Macbook pro 15\u0026quot; Touch Bar with MacOS 10.13.1 (High Sierra) installed and tried to update to 10.13.2 using the App Store.\nIf this was helpful to you, consider buying me a coffee or thanking me on Mastodon!\n","date":"26 December 2017","externalUrl":null,"permalink":"/blog/2017/12/26/macosupdate/","section":"Blogs","summary":"Tonight after a routine MacOS update (10.13.2) disaster struck and my Mac got stuck in an update boot loop. After a few hours of panic, reading online and trial \u0026amp; error I managed to resolve it.","title":"MacOS update could not be installed","type":"blog"},{"content":"","date":"26 December 2017","externalUrl":null,"permalink":"/tags/troubleshooting/","section":"Tags","summary":"","title":"Troubleshooting","type":"tags"},{"content":"","date":"26 December 2017","externalUrl":null,"permalink":"/tags/update/","section":"Tags","summary":"","title":"Update","type":"tags"},{"content":"","date":"18 December 2017","externalUrl":null,"permalink":"/tags/fragment/","section":"Tags","summary":"","title":"Fragment","type":"tags"},{"content":"Do Fragment transactions and back navigation have no more secrets for you? Well then you should try to solve the mystery in this post, where a Fragment (literally) came to haunt us\u0026hellip;\nSeemingly simple Fragment transactions can sometimes have unintended side effects. While investigating, we\u0026rsquo;ll learn how Fragment transactions actually work.\nPart 1: the haunt # Let\u0026rsquo;s build a very straightforward app that shows all today\u0026rsquo;s calendar events for a particular user. To do so, users will obviously have to log in first.\nAssume now that the app consists out of a single screen that:\neither shows today\u0026rsquo;s events if user is logged in otherwise shows a placeholder + login button The login is a two-step flow that consists out of a UserNameFragment and a PasswordFragment. Afterwards, the app navigates back to the main screen to show the events.\nNote that for simplicity we don\u0026rsquo;t display the events when navigating back, but instead show the placeholder screen again after successful login.\nA simple implementation for all Fragment transactions could be:\ntransaction.replace(todayFragment) transaction.replace(userNameFragment).addToBackStack(null) transaction.replace(passwordFragment) Notice that we only add the UserNameFragment to the back stack! This way one single back would always take the user back to the TodayFragment, making it super easy to navigate back when log in was successful.\nfun onLoginSuccess() { activity.onBackPressed() } But that gives surprising results:\nThe PasswordFragment is back to haunt us!\nPart 2: investigative development # Let\u0026rsquo;s have another look at the sequence of transactions that takes place:\ntransaction.replace(todayFragment) transaction.replace(userNameFragment).addToBackStack(null) transaction.replace(passwordFragment) Since a replace is just a combination of remove() and add() we can rewrite this to:\ntransaction.remove(null).add(todayFragment) transaction.remove(todayFragment).add(userNameFragment).addToBackStack(null) transaction.remove(userNameFragment).add(passwordFragment) Now it is important to know that the FragmentTransactionManager only saves the FragmentTransactions that were executed, not the Fragments themselves!\nConsequently, when you press back in the PasswordFragment, it won\u0026rsquo;t show all Fragments that were present before the Transaction! Instead, it will revert the previous Transaction that was added to the back stack:\ntransaction.remove(todayFragment).add(userNameFragment).addToBackStack(null) Which will then be executed in reverse:\ntransaction.remove(userNameFragment).add(todayFragment) But because we are on the PasswordFragment, which has replaced the UserNameFragment, there is no UserNameFragment in this situation!\ntransaction.remove(null).add(todayFragment) Hence nothing is removed and the TodayFragment is added leaving the users with both the PasswordFragment and TodayFragment.\nPart 3: mystery solved # As a first stab, you could say that this problem is caused by transaction three not being added to the back stack. So why not also add that transaction and do a double back.\ntransaction.replace(todayFragment) transaction.replace(userNameFragment).addToBackStack(null)) transaction.replace(passwordFragment).addToBackStack(null)) fun onLoginSuccess() { activity.onBackPressed() activity.onBackPressed() } While simple, this actually won\u0026rsquo;t work! After calling onBackPressed() the first time, the fragment will be detached from its activity, causing a NullPointerException on accessing the activity for the second back press.\nBut even if that would\u0026rsquo;ve worked, it would still be a poor idea because this way the PasswordFragment has hardcoded in it that it\u0026rsquo;s preceded by exactly one Fragment. Should you ever change that, this would break.\nAlternatively you could assign a tag to the first addToBackStack invocation and add every transaction to the back stack:\ntransaction.replace(todayFragment) transaction.replace(userNameFragment).addToBackStack(\u0026#34;username\u0026#34;) transaction.replace(passwordFragment).addToBackStack(null) fun onLoginSuccess() { activity.supportFragmentManager.popBackStack(\u0026#34;username\u0026#34;, POP_BACK_STACK_INCLUSIVE) } That actually works! But unfortunately, the PasswordFragment still needs to know what the first screen of the login flow is\u0026hellip; This won\u0026rsquo;t just break easily, but it also makes it very complex to build dynamic login flows.\nSo what would be the clean way of setting it up?\nWell actually\u0026hellip; since all login screens together form a separate flow, why not just move them all to a single LoginActivity?\nThat has many advantages:\nDefault way of reusing app parts on Android Screens in the flow don\u0026rsquo;t know about each other Ability to pass back a result Better fits multi-module architectures Super simple back handling: activity.finish() \u0026hellip; Epilogue # Fragment transactions are a surprisingly simple concept of adding/removing and reversing those operations. When navigations become complex, consider moving parts of the flow to a separate activity.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below or check out the code on GitHub!\n","date":"18 December 2017","externalUrl":null,"permalink":"/blog/2017/12/18/fragmentback/","section":"Blogs","summary":"Do Fragment transactions and back navigation have no more secrets for you? Well then you should try to solve the mystery in this post, where a Fragment (literally) came to haunt us\u0026hellip;","title":"The curious case of haunting fragments","type":"blog"},{"content":"","date":"28 November 2017","externalUrl":null,"permalink":"/tags/coverage/","section":"Tags","summary":"","title":"Coverage","type":"tags"},{"content":"While you may be tempted to strive for 100% code coverage, that would be a horrible idea. Besides some code being hard to test, the concept of coverage is actually fundamentally limited.\nThis post will deep dive in what code coverage actually means, detail why you should never set coverage goals and help you get the most value out of this concept.\nApp coverage # Take a step back and try to answer the following question:\nIf your app has 100% code coverage, are you then sure everything will work as expected? (i.e. there are no bugs) Why/why not?\n\u0026hellip;\n\u0026hellip;\nWell obviously no! Because even if all your classes have 100% coverage, that still doesn\u0026rsquo;t mean they will correctly interact with each other.\nFor instance your JSON parser could get an unexpected response back from the web server. (Note that this is typically something you address with integration tests.)\nClass coverage # Let\u0026rsquo;s narrow down the scope and look at one single very focussed class e.g. a Calculator class.\npublic class Calculator { public int sum(int a, int b) { return a+b; } } If one single focussed class has 100% code coverage, are you then sure everything will work as expected for that class? (i.e. there are no bugs) Why/why not?\n\u0026hellip;\n\u0026hellip;\nMmmmm trickier\u0026hellip;\nBut the answer is still clearly no!\nThis is because code coverage doesn\u0026rsquo;t tell you anything about the quality of your tests. It only counts what lines of code are executed during tests and what aren\u0026rsquo;t.\nA good Calculator test (with 100% line coverage) would be:\n@Test public void sumOfOneAndThreeShouldBeFour() throws Exception { int result = new Calculator().sum(1,3); assertEquals(4, result) } But even the same test without assert would result in 100% line coverage:\n@Test public void sumOfOneAndThreeShouldBeFourWithoutAssert() throws Exception { int result = new Calculator().sum(1,3); } That test is just plain useless! It doesn\u0026rsquo;t prevent you from changing the implementation of sum() at all.\nCode coverage != quality of tests # So if we remove all asserts from our test suite, our code coverage would remain the same. Interesting\u0026hellip; what else is broken with code coverage?\nEven if you have asserts, code coverage doesn\u0026rsquo;t guarantee that you\u0026rsquo;ve covered your functionality. For instance if we change our Calculator class and hardcode the result of the sum:\npublic class Calculator { public int sum(int a, int b) { return 4; } } All above tests would still pass, code coverage would be 100% but your code doesn\u0026rsquo;t functionally do what it should. We would need to add multiple tests (covering the same line of code) to guarantee that.\nSo coverage doesn\u0026rsquo;t ensure your tests:\ndo an actual assert are complete (cover all functionality) Use for coverage # Hopefully it is clear now that you should never use code coverage as a goal or KPI (key performance indicator). This is because the tool can too easily be fooled and 100% coverage is in that regard meaningless.\nEven if coverage wouldn\u0026rsquo;t be flawed, it still would be a mistake to try and get 100% coverage. While everything can be tested, not everything is easy to test!\nThink about UI animations, communication between Threads, operations on filesystem,\u0026hellip;\nTrying to test complex things doesn\u0026rsquo;t just take way to much effort. The resulting tests usually also tend to be so complex that they will end up being a maintenance burden. Wasted effort with hardly any value in return.\nWell then, how should you use coverage?\nThe real value is in the evolution of code coverage over time.\nAssume the team is proficient in writing high quality tests and has the ambition to have everything well tested, then code coverage shouldn\u0026rsquo;t decrease right?\nWhy not use it to identify parts of your app that should get some extra testing love?\nOr how about automatically adding a coverage report to every pull request? This is something I do for all my open source projects.\nSo the next time your boss asks you to have 100% code coverage, you know what to do:\ngenerate all your tests using a tool claim your bonus go back to doing proper engineering and empower yourself with coverage to build something your proud of. Wrap-up # Code coverage can be an incredibly powerful tool to improve the quality of your code as long as you don\u0026rsquo;t blindly optimize for maximum coverage.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"28 November 2017","externalUrl":null,"permalink":"/blog/2017/11/28/coveragproblem/","section":"Blogs","summary":"While you may be tempted to strive for 100% code coverage, that would be a horrible idea. Besides some code being hard to test, the concept of coverage is actually fundamentally limited.","title":"The 100% code coverage problem","type":"blog"},{"content":"Had a blast visiting Droidcon UK this year and wanted to do a quick post to link to all of it\u0026rsquo;s wonderful content.\nConference slides # While you can find all recordings here, I often find it useful to be able to quickly scan through the slides. Hence I bundled everything I could already from socials.\nIoT from the trenches - How to build a connected product by Jeroen Mols The Creative Technologist! by Corey Latislaw Vector Workflows by Nick Butcher My app is smarter than your app by Erik Hellman Sinking your teeth into byte code by Jake Wharton Tips for Library Development from a Startup Developer by Lisa Wray Why do we need Clean Architecture by Igor Wojda Becoming a master window fitter by Chris Banes Multiplying your impact through mentoring by Jonathan Maltz Testing Android apps based on Dagger and RxJava by Fabio Collini Poor programming patterns and how to avoid them by Alice Yuan Building a \u0026ldquo;Minimum Viable Product\u0026rdquo; (MVP) with Face recognition and AR in Android by Raul Hernandez Lopez Bluetooth Low Energy on Android: Top Tips for the Tricky Bits by Stuart Kent Making Dogfood Builds Testable and Fun by Eric Cochran These are a few of my favourite (Android) Things by Marcos Placona About Memory Management in Fully Reactive Apps by Paco Estevez Doo z z z z z e by Ralf Wondratschek‏ OpenGL - A noob\u0026rsquo;s guide for Android developers by Benjamin Monjoie Through the looking-glass eyes of an Android by Adrián Catalán Travelling across Asia - Our journey from Java to Kotlin by Amal Kakaiya and Maria Neumayer Merge like it\u0026rsquo;s 2099 by Xavier Gouchet Poor programming patterns and how to avoid them by Alice Yuan Android Internals for Developers by Effie Barak Deep Android Integrations by Ty Smith When your app’s asleep by Britt Barak Modularizing Android Applications by Marvin Ramin Heat the neurons of your smartphone with Deep Learning by Qian Jin Kotlin Coroutines and Android sitting in a tree by Kai Koenig Hacking Android, a Hacker\u0026rsquo;s narrative by Chris Le Roy Commonly overlooked areas of security By Clive Lee Accessibility @ Scale by Mallika Potter Credits # Thanks to the Skills Matter team for organizing a top notch conference! To all sponsors for making this event possible. And to the entire Android community for being so awesome!\nHope to see you all next year!\nHelpful? Got extra slides? Hit me up on Mastodon.\n","date":"27 October 2017","externalUrl":null,"permalink":"/blog/2017/10/27/droidconuk/","section":"Blogs","summary":"Had a blast visiting Droidcon UK this year and wanted to do a quick post to link to all of it\u0026rsquo;s wonderful content.\nConference slides # While you can find all recordings here, I often find it useful to be able to quickly scan through the slides.","title":"Droidcon UK slides","type":"blog"},{"content":"","date":"27 October 2017","externalUrl":null,"permalink":"/tags/droidconuk/","section":"Tags","summary":"","title":"Droidconuk","type":"tags"},{"content":"","date":"13 September 2017","externalUrl":null,"permalink":"/tags/career/","section":"Tags","summary":"","title":"Career","type":"tags"},{"content":"This isn\u0026rsquo;t another post about the benefits of using Kotlin. Hell, I\u0026rsquo;m not even going to cover any of its language features. Nor will I try to convince you to make the switch.\nIn contrast, this post will talk career. How learning a new language makes you a better developer and ensures you stay relevant. And in that regards, Kotlin now presents a golden opportunity.\nWhy you should learn a new programming language # Predicting the future is nearly impossible. But 10 years ago (2007) there where no smartphone apps\u0026hellip; And 10 years before that (1997) well\u0026hellip; dot-com bubble anyone?\nSo how will the future look like in 10 years from now? Or 20 years?\nOnly sure thing is that you\u0026rsquo;ll still be working as retirement age continues to be raised.\nTwo things are likely to happen though:\nSoftware will become even more ubiquitous than today The platform you\u0026rsquo;re now developing for is no longer relevant Differently put: your software skills will still be needed, but you\u0026rsquo;ll have to switch programming languages several times along the way.\nSay what?\nLearning a new programming language isn\u0026rsquo;t easy! And I will have to do that multiple times? Even when I\u0026rsquo;m 40 or 50?\nYes, absolutely!\nBut here\u0026rsquo;s the thing: while there are hundreds of programming languages, programming concepts are finite.\nAnd with every language you learn, you pick up a couple extra of those concepts.\nSo while learning your first programming language is really time consuming. Your second will already go slightly smoother and after your third you\u0026rsquo;ll realize: \u0026ldquo;Hey Kotlin coroutines are like C# async/await, but then slightly different\u0026rdquo;.\nLearning a new language becomes easier with every language you learn. And every time you learn a new language, your horizon broadens and you pick up tons of new widely applicable software concepts.\nChallenges in learning a new language # While the previous statement may be true, you hardly ever learn a programming language alone.\nFor instance while learning Android you need to learn the core platform concepts (e.g. activity lifecycle), environment (e.g battery constraints), Android APIs, \u0026hellip;\nAnd that\u0026rsquo;s just to get you started. If you really want to get productive you\u0026rsquo;ll also have to figure out what 3rd party libraries to use, how to get the most out of the IDE and especially how to write tests effectively.\nSo imagine you want to learn how to build a web app:\nWhat technology do you use? Ruby on rails, Javascript,\u0026hellip;? What Javascript framework should you use? How does a DOM work? Do I use a text editor or are there any good IDE\u0026rsquo;s? How/where do I deploy my web app? How can I find the answers to my problems? \u0026hellip; That\u0026rsquo;s a lot to take in, right?\nLearning all of this at once can easily become a very frustrating experience. You\u0026rsquo;ll manage, I\u0026rsquo;m sure, but it will take you quite some time before you\u0026rsquo;ll become productive.\nWhy your next language should be Kotlin # Here\u0026rsquo;s where Kotlin enters the game. Suddenly every Android developer has gotten the opportunity to learn a new, modern language inside of his/her already familiar cocoon.\nYou\u0026rsquo;re already used to every Android problem you may encounter. You know the ins and outs of Android studio. And I\u0026rsquo;ll be damned if you\u0026rsquo;re not a StackOverflow wizard by now!\nSo grab the opportunity to learn a new language without it being too frustrating. Learn those extra programming concepts that will remain relevant throughout your entire career. Have your horizon broadened by new concepts and ways of thinking.\nI\u0026rsquo;m not saying you must learn Kotlin. But learning a new programming language is inevitable if you\u0026rsquo;re aspiring a technical career. And Kotlin presents a damn fine opportunity to keep your sanity while you\u0026rsquo;re at it.\nWrap-up # Learning a new programming language is essential in staying relevant as a software developer. Thanks to Kotlin, Android developers can now learn a new language without the frustration of all boilerplate around it.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"13 September 2017","externalUrl":null,"permalink":"/blog/2017/09/13/kotlinopportunity/","section":"Blogs","summary":"This isn\u0026rsquo;t another post about the benefits of using Kotlin. Hell, I\u0026rsquo;m not even going to cover any of its language features. Nor will I try to convince you to make the switch.","title":"The career opportunity called Kotlin","type":"blog"},{"content":"For years Android developers have been limited to Java 6 features. While RetroLambda or the experimental Jack toolchain would help, proper support from Google was notably missing.\nFinally, Android Studio 3.0 brings (backported!) support for most Java 8 features. Continue reading to learn how those work and why you should upgrade.\nEnabling java 8 features # While Android Studio already supported many features in the Jack toolchain, starting from Android Studio 3.0 they are supported in the default toolchain.\nFirst of all, make sure you disable Jack by removing the following from your main build.gradle:\nandroid { ... defaultConfig { ... // Remove the jackOptions if they exist jackOptions { enabled true } } } And add the following configuration instead:\nandroid { ... compileOptions { sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 } } Also make sure you have the latest Gradle plugin in your root build.gradle file:\nbuildscript { ... dependencies { classpath \u0026#39;com.android.tools.build:gradle:3.0.0-alpha7\u0026#39; } } Congratulations, you can now use most Java 8 features on all API levels!\nNote: In case you\u0026rsquo;re migrating from RetroLambda, the official documentation has a more extensive migration guide.\nLambda\u0026rsquo;s # Passing a listener to another class in Java 6 is quite verbose. A typical case would be where you add an OnClickListener to a View:\nbutton.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { doSomething(); } }); Lambda\u0026rsquo;s can dramatically simplify this to the following:\nbutton.setOnClickListener(view -\u0026gt; doSomething()); Notice that almost all boilerplate is removed: no access modifier, no return type and no method name!\nNow how do lambda\u0026rsquo;s actually work?\nThey are syntactic sugar that reduce the need for anonymous class creation whenever you have an interface with exactly one method. We call such interfaces functional interfaces and OnClickListener is an example:\n// A functional interface has exactly one method public interface OnClickListener { void onClick(View view); } Basically the lambda consists out of a three parts:\nbutton.setOnClickListener((view) -\u0026gt; {doSomething()}); declaration of all method arguments between brackets () an arrow -\u0026gt; code that needs to execute between brackets {} Note that in many cases even the brackets () and {} can be removed. For more details have a look at the official documentation.\nMethod references # Recall that lambda expressions remove a lot of boilerplate code for functional interfaces. Method references take that concept one step further when the lambda calls a method that already has a name.\nIn the following example:\nbutton.setOnClickListener(view -\u0026gt; doSomething(view)); All the lambda does is redirecting the work to an existing doSomething() method. In such a case, a method reference simplifies things further to:\nbutton.setOnClickListener(this::doSomething); Note that the referenced method must take exactly the same parameters as the functional interface:\n// functional interface public interface OnClickListener { void onClick(View view); } // referenced method: must take View as argument, because onClick() does private void doSomething(View view) { // do something here } So how do method references work?\nThey are again syntactic sugar to simplify a lambda expression that invokes an existing method. They can reference to:\n| static methods | MyClass::doSomething | | instance method of object | myObject::doSomething | | constructor | MyClass:: new | | instance method of any argument type | String::compare |\nFor more examples about this have a look at the official documentation.\nDefault interface Methods # Default methods make it possible to add new methods to an interface without breaking all classes that implement that interface.\nImagine if you have a MyView interface that is implemented by a MyFragment (typical MVP scenario):\npublic interface MyView { void showProgressbar(); } public class MyFragment implements MyView { @Override public void showProgressbar() { } } When you now want to add an extra method to MyView your code will no longer compile, until MyFragment also implements that new method. This is annoying, and can be even problematic when many classes are implementing said interface.\nTherefore Java 8 now allows you to define default methods that provide a standard implementation:\npublic interface MyView { void showProgressbar(); default void hideProgressbar() { // do something here } } So how do default methods work?\nJust define a method with the default keyword in the interface and provide an actual default method body.\nTo learn more about this feature, have a look at the official documentation.\nHow to get started # While this all might seem a bit overwhelming, Android Studio actually offers amazing quick fixes once you enable Java 8 features.\nJust use alt/option + enter to convert a functional interface to a lamba or a lambda to a method reference.\nThis is a great way to get familiar with these new features and allows you to write code like you\u0026rsquo;re used to. After enough quick fixes by Android Studio you\u0026rsquo;ll learn in what cases a lambda or method reference would be possible and start writing them yourself.\nSupported features # While not all Java 8 features have been backported yet, Android Studio 3.0 offers plenty more features:\nstatic interface methods type annotations repeating annotations try with resources (all versions, no longer min SDK 19) Java 8 APIs (e.g. stream) -\u0026gt; min SDK 24 Wrap-up # Thanks to Java 8 features, a lot of code can be simplified into lambda\u0026rsquo;s or method references. Android Studio auto convert is the easiest way to start learning these features.\nIf you\u0026rsquo;ve made it this far you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"21 July 2017","externalUrl":null,"permalink":"/blog/2017/07/21/java8language/","section":"Blogs","summary":"For years Android developers have been limited to Java 6 features. While RetroLambda or the experimental Jack toolchain would help, proper support from Google was notably missing.","title":"Embracing Java 8 language features","type":"blog"},{"content":"","date":"21 July 2017","externalUrl":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java","type":"tags"},{"content":"Upgrading to Android studio 3.0 territory will make building multi-module projects a lot faster, but it also means a breaking Gradle plugin API change unfortunately.\nThis blog post will detail all benefits of this change and guide you through the upgrade process.\nProblem situation # To understand the limitations of the old Gradle plugin 2.0 build system, consider the following project with multiple layers of modules:\nLooking at the bottom most module, there are basically two different changes you could make:\nImplementation change: internal change, doesn\u0026rsquo;t modify the external interface of the module Application binary interface (ABI) change: modify the external interface of the module Note: In what follows, all recompiled modules will be highlighted in red.\nImplementation change # Since the external interface of the module doesn\u0026rsquo;t change, Gradle will only recompile that module. All of its consuming modules will be left untouched.\nThere is no problem in this scenario.\nABI change # When the external interface of a module changes however, also the modules consuming that module directly need to be recompiled.\nBut those modules could be exposing parts of the bottom module directly through their own interface! So to be completely safe, they would also need to be recompiled. Same for the ones using those\u0026hellip; and those\u0026hellip; and\u0026hellip;\nHence Gradle would effectively need to recompile all modules.\nNow we do have a big problem: one code change causes all modules to be recompiled. The root cause for this is that Gradle doesn\u0026rsquo;t know if you leak the interface of a module through another one or not.\nAndroid Gradle plugin 3.0 to the rescue # The latest Android Gradle plugin now requires you to explicitly define if you leak a module\u0026rsquo;s interface. Based on that it can make the right choice on what it should recompile.\nAs such the compile dependency has been deprecated and replaced by two new ones:\napi: you leak the interface of this module through your own interface, meaning exactly the same as the old compile dependency implementation: you only use this module internally and does not leak it through your interface So now you can explicitly tell Gradle to recompile a module if the interface of a used module changes or not.\ndependencies { // recompile this module and all modules using this one // when legofy interface is modified api project(\u0026#39;:legofy\u0026#39;) // only recompile this module when landscapevideocamera interface is modified implementation project(\u0026#39;:landscapevideocamera:1.0.0\u0026#39;) } Migration guide # In theory you can simply replace all compile dependencies with api dependencies, but that would still cause everything to be recompiled:\nSo better approach is to replace all compile dependencies with implementation dependencies. And only where you leak a module\u0026rsquo;s interface, you should use api. That should cause a lot less recompilation.\nHopefully, this clarifies the ambiguity between api and implementation, as the official migration guide is quite cryptic.\nOther dependency configurations # As there was already a breaking change, the team also made use of the opportunity to finally give the other configurations proper names:\nprovided configuration is now compileOnly apk configuration is now runtimeOnly Just like before you can also combine these with your build variants: debugApi, testImplementation,\u0026hellip;\nOther migration items # Android Studio 3.0 packs tons of other improvements that have finally been addressed. My favorites are:\nall Google dependencies are available via an online Maven repository current build variant can now be passed through to your libraries, removing the need for publishNonDefault true \u0026hellip; For more information have a look at the complete migration guide.\nWrap-up # To build multi-module projects faster, the Android Gradle plugin needed a breaking API change. Always try to use the implementation dependency as this will cause fewer modules to be recompiled.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"14 June 2017","externalUrl":null,"permalink":"/blog/2017/06/14/androidstudio3/","section":"Blogs","summary":"Upgrading to Android studio 3.0 territory will make building multi-module projects a lot faster, but it also means a breaking Gradle plugin API change unfortunately.","title":"Implementation vs API dependency","type":"blog"},{"content":"","date":"31 May 2017","externalUrl":null,"permalink":"/tags/googleio/","section":"Tags","summary":"","title":"Googleio","type":"tags"},{"content":"Being my 2nd year at Google IO, I decided to do things differently: Besides taking notes during sessions, I also created a personal todo list. This contains all new (and even old) technologies I got triggered to look into.\nThis post won\u0026rsquo;t cover all big #io17 announcements, but instead tries to be an alternative, biased, inside scoop with my personal highlights.\nArchitecture # The most exciting announcement for me is that Google finally becomes opinionated about architecture. This will dramatical lower the bar for starting developers. If you\u0026rsquo;re already more seasoned however\u0026hellip; well .. rules are meant to be broken.\nMy todo list:\nRead and get inspired by the new architecture guide Learn how LifecycleObservers can simplify our codebase Investigate if ViewModels are a better fit for our current state persistence Strip out all font code and replace it with XML fonts Experiment with downloadable fonts Recommended videos:\nArchitecture components - introduction Architecture Components - Solving the Lifecycle Problem World class apps # Creating a globally awesome app can be quite challenging. Fortunately we now have some really interesting tools to help us out.\nMy todo list:\nInvestigate automatic APK splits. Here the Play console will automatically split APKs to minimize their size. This requires you to opt-in to Google play app signing, which is permanent! (for security reasons) Get approval to migrate services to Firebase, which is really becoming the best set of developer tools Migrate to Firebase analytics, that now supports custom parameters for events Replace crash reporting with Crashlytics (finally). That will become the default Firebase crash reporting since Google acquired Fabric. Integrate Firebase performance monitoring to automatically measures app performance. This gives you detailed statistics about startup, requests times,\u0026hellip; and allows you to filter those by country, devices, versions,\u0026hellip; all with zero effort! Look into Android vitals, a developer console feature to monitory overall app stability and performance. Recommended videos:\nGreat app performance with Firebase Android performance: UI Recommended posts:\nI/O 2017: Everything new in the Google Play Console What’s new from Firebase at Google I/O 2017 Introducing Firebase Performance Monitoring Build improvements # I\u0026rsquo;m definitely big on tooling and making builds cleaner and more efficient. Fortunately (and unsurprisingly) the tools team didn\u0026rsquo;t disappoint this year.\nMy todo list:\nMigrate to the Android Gradle 3.0 plugin, that includes some breaking changes to make building multi module projects faster. Use support libraries directly from the new Google Maven repository allprojects { repositories { jcenter() maven { url \u0026#39;https://maven.google.com\u0026#39; } } } Apply all Gradle build speed up tips Reduce APK size by explicitly defining supported languages (resConfigs) Recommended videos:\nSpeeding Up Your Android Gradle Builds What\u0026rsquo;s New in Android Development Tools Other # Besides the above themes, there are many more exciting areas to explore.\nMy todo list:\nStart a study group to learn Kotlin. It\u0026rsquo;s important to get the entire team up to speed with the basics, then defining a plan forward and start migrating. Add support for the super tall Galaxy S8 screen \u0026lt;meta-data android:name=\u0026#34;android.max_aspect\u0026#34; android:value=\u0026#34;2.1\u0026#34; /\u0026gt; Learn about Android instant apps Watch TDD on Android talk Get up to speed with Android O notification channels, as you must use these when targeting Android O or your notifications will be dropped. Investigate what\u0026rsquo;s needed to optimize apps for autofill Recommended videos:\nIntroduction to Kotlin Wrap-up # It\u0026rsquo;s always super inspiring to visit a conference, especially google IO. This year we got an impressive set of new developer tools/apis and I had the pleasure of meeting many interesting people. We\u0026rsquo;re lucky to have such a vibrant community!\nDo you like this format? Let me know in the comments below or on Mastodon.\n","date":"31 May 2017","externalUrl":null,"permalink":"/blog/2017/05/31/googleio17/","section":"Blogs","summary":"Being my 2nd year at Google IO, I decided to do things differently: Besides taking notes during sessions, I also created a personal todo list. This contains all new (and even old) technologies I got triggered to look into.","title":"My Google #io17 takeaways","type":"blog"},{"content":"After organizing Droidcon Paris for several year, the organizers decided to move on and experiment with a new format. This didn\u0026rsquo;t just result in a well organized conference, but also in a fresh new vibe whilst still feeling familiar.\nIn this post I\u0026rsquo;d like to share some general themes, my personal highlights and all of the slides I could gather from socials.\nDetails matter # Building a world class app doesn\u0026rsquo;t just require good engineering practices, but you literally have to handle details on every front.\nMy key takeaways:\nLearn and optimize your app launch time:adb shell am start -W \u0026lt;packagename\u0026gt;/. \u0026lt;activityname\u0026gt; Never share a file directly via an intent, always copy it first Prefer https:// as the scheme for direct links Hard-coded encryption keys can be easily found in byte code: grep for Ljavax/crypto API design is basically designing future regrets Productivity # As projects get more complex, it becomes crucial (for your own sanity) to have the right engineering practices in place. Try and leverage your continuous integration to automatically build, test and statically analyze your pull requests before merging.\nMy key takeaways:\nTestability must be taken into account from project start Many git conflicts can be resolved automatically with proper tooling Use pre launch reports before going to production Naming things is hard, yet super important Programming languages # Challenging the traditional way of app development has gotten a new spark thanks to Kotlin and the rise of other cross platform tools. There is definitely no silver bullet yet, but it\u0026rsquo;s good to see the community stay open minded.\nMy key takeaways:\nEvery Android developer hates WebViews With incremental builds, Kotlin compiles as fast as Java React native is JavaScript rendered to a native UI(not ready for primetime yet, wait for 1.0 version) Any Android dev can develop for Android Things (runs Activities!) Organizer recap # Relive the conference through the organizers eyes, they did a great job at summarizing each day. Clicking each moment will expand more details.\nAndroid Makers 2017 - Day 1 Android Makers - Day 2 Conference slides # While the conference organizers will publish all slides very soon, I can image that quite a few people are already looking for a sneak preview. Hence I bundled everything I could already gather from socials.\nThe ART of organizing resources by Jeroen Mols Remote, lonely and productive by David González Launch Screens: From a Tap to Your App by Cyril Mottier The evolution of Android notification by Jeremie Martinez Deep Android Integrations by Ty Smith Android Design Tools : New features and tools for rapid UI development by Nicolas Roard Develop a weather app with Kotlin by Laurent Baresse Merge like it\u0026rsquo;s 2099 by Xavier Gouchet RxJava est mort, vive RxJava 2 by David Wursteisen Taking care of your UI tests by Florian Mierzejewski Dependency Injection in Android - Best Practices by Vasiliy Zukanov Toothpick: a fresh approach to Dependency Injection on Android by Stéphane Nicolas and Daniel Molinero Reguera Streamlining Payments on Mobile by Mathieu Calba Heat the Neurons of Your Smartphone with Deep Learning by Qian Jin and Yoann Benoit Testable Android Architecture by Chuck Greb Develop your next app with kotlin by Arnaud Giuliani Make or brake… using Gradle by Stanojko Markovik Getting the most of Android obfuscation tools by Renaud Boulard Intro to Google Assistant and Actions on Google by Elaine Dias Batista and Wajdi Ben Rabah Actions on Google workshop by Elaine Dias Batista and Wajdi Ben Rabah Modern Android: How to ditch Activities \u0026amp; Fragments by Fabien Devos Kotlin in the real world by Rémi Pradal One Year of Clean Architecture - The Good, The Bad and The Bob by Gabriel Adgeg and Dorian Lamande IotCeption - Energy Measurement of Android Things on Raspberry PI 3 with Arduino Uno by Olivier Philippot Le root : un inconnu chez soi? by Bruce Bujon ExoPlayer, player multimédia pour vos applications et la réalité virtuelle by Julien Salvi Le design mobile c’est pas facile by Quentin Sallat Credits # Thanks to the entire Android Makers team for organizing a great conference and to all sponsors for supporting. Hope to see you all next year!\n","date":"11 April 2017","externalUrl":null,"permalink":"/blog/2017/04/11/androidmakers17/","section":"Blogs","summary":"After organizing Droidcon Paris for several year, the organizers decided to move on and experiment with a new format. This didn\u0026rsquo;t just result in a well organized conference, but also in a fresh new vibe whilst still feeling familiar.","title":"Android Makers FR recap","type":"blog"},{"content":"","date":"11 April 2017","externalUrl":null,"permalink":"/tags/androidmakers/","section":"Tags","summary":"","title":"Androidmakers","type":"tags"},{"content":"","date":"8 March 2017","externalUrl":null,"permalink":"/tags/crashes/","section":"Tags","summary":"","title":"Crashes","type":"tags"},{"content":"Too many times I\u0026rsquo;ve seen developers trying to avoid crashes at all cost. But are unhandled exceptions really that bad? And are null checks really the answer?\nActually, sometimes you want your app to crash. This post will explain why and give some practical tips.\nPrologue # In this post I focus on null checks for simplicity, but this can easily be generalized to any other edge case.\nThe null check architecture # Let\u0026rsquo;s say we have a simple application that shows a list of sports player:\npublic void showPlayers(List\u0026lt;Player\u0026gt; soccerPlayers) { // some awesome code here } In a happy scenario, this will work, but what happens if the list is null?\nObviously can add an infamous null check:\npublic void showPlayers(List\u0026lt;Player\u0026gt; soccerPlayers) { if (soccerPlayers == null) return; // some awesome code here } All settled!\nOh wait\u0026hellip; the list can also be empty:\npublic void showPlayers(List\u0026lt;Player\u0026gt; soccerPlayers) { if (soccerPlayers == null || soccerPlayers.isEmpty()) return; // some awesome code here } And what about the five layers of architecture soccerPlayers gets passed through below the UI? Should we also duplicate our checks in each of those layers in those?\nBefore you know it you\u0026rsquo;ll have null checks everywhere!\nThe null check problem # Obviously, null checks clutter your code significantly.\nBut that\u0026rsquo;s not the only problem! Because once you\u0026rsquo;re used to using them, you\u0026rsquo;ll use them everywhere!\npublic void showPlayers(List\u0026lt;Player\u0026gt; soccerPlayers) { if (soccerPlayers == null) return; if (myRecyclerView == null) return; if (myRecyclerView.getAdapter() == null) return; // some awesome code here } Even when you don\u0026rsquo;t need them, you\u0026rsquo;ll still add them!\nLet that sink in for a second\u0026hellip;\nWhat is the exact problem here?\nAn \u0026ldquo;innocent\u0026rdquo; null check can easily mask a bigger, more fundamental issue\nShould soccerPlayers actually ever be null there in the first place? Or is it the responsibility of the lower levels of your app to return an empty list instead?\nAnd what should happen when the soccerPlayers is actually null? Surely showing the user a completely blank screen by doing a return, right?\nThe latter actually means that your app will stop working \u0026ldquo;silently\u0026rdquo; in production without you having any way of detecting that!\nCrashes to the rescue # If an app gets into a state it wasn\u0026rsquo;t designed for, it should crash. There is no general way of handling that.\nMethods shouldn\u0026rsquo;t check their inputs for every possible scenario that can theoretically occur. Instead, you should carefully consider what the input can actually be and only prepare for that.\nIf your app gets in a state you didn\u0026rsquo;t design it for, wouldn\u0026rsquo;t that be something you would like to know ASAP?\nWell in come our beloved exceptions!\nUnhandled exceptions are great because they:\nnotify you immediately by crashing the app highlight the problem instead of dying silently have a trace to pinpoint the problem are automatically backed up to your crashreporting This obviously doens\u0026rsquo;t mean that your app should crash for your users! All I\u0026rsquo;m saying is that if there is a problem in my app, I\u0026rsquo;d rather know about it by getting a crash report instead of not knowing.\nCrash or not, for the end user it\u0026rsquo;s the same: their app is broken.\nAnd be reassured, you won\u0026rsquo;t start bothering users with more crashes! Before rolling out to production you still have several safety nets: developer testing, QA department, beta testing, staged rollout,\u0026hellip;\nSo even with this strategy, you can still get to 99,9% crash free users.\n@molsjeroen @Jan_Joris we have maybe 100s of throw new IllegalStateException in our code base and our crash-free rate is 99.9%\n\u0026mdash; Said Tahsin Dane (@tasomaniac) 9 maart 2017 Practical tips # To clarify this approach and to help you kickstart implementing it:\nAlways design your app to be robust against any input outside of your control: responses from webservices, data entered in UI, incoming intents,\u0026hellip; Ensure data integrity at the point of entry in your app. This way invalid data (null, empty,\u0026hellip;) cannot occur anywhere else in your app and you don\u0026rsquo;t have to check for it. If you\u0026rsquo;re unsure a certain error situation can occur somewhere, assume it won\u0026rsquo;t! During testing you\u0026rsquo;ll find out (RuntimeException) if you\u0026rsquo;re right. If a certain method cannot be called in production, can only be called once,\u0026hellip; throw an IllegalStateException. Always test thoroughly before shipping to all your users. You\u0026rsquo;ll catch the feared \u0026ldquo;crashes\u0026rdquo; before your users do. Wrap-up # Instead of being afraid of crashes, you should embrace them to find errors in your apps fasters. Crashes not only make errors immediately visible, they also offer a convenient way of debugging them via the stacktrace.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"8 March 2017","externalUrl":null,"permalink":"/blog/2017/03/08/appcrash/","section":"Blogs","summary":"Too many times I\u0026rsquo;ve seen developers trying to avoid crashes at all cost. But are unhandled exceptions really that bad? And are null checks really the answer?","title":"Why your app should crash","type":"blog"},{"content":"If you can code, you can also write unit tests. Writing awesome tests on the other hand is a different story. Don\u0026rsquo;t fool yourself: Unit testing code is production code that you will need to maintain, refactor and build upon for years to come.\nThis blogpost aims at providing three very simple rules that will significantly ramp up your testing game. Every rule is followed by pragmatic tips so you can easily start implementing.\n1. Run ludicrously fast # The only reason you write unit tests is to run them. This has two benefits:\nconfirm that something is working properly detect when something stopped working In summary, tests are your safety net, the main weapon against regression. They make sure bugs remain fixed and allow you to refactor your code.\nThere is one caveat however: for tests to do their job, you need to run them!\nEvery time they run, they give you feedback about the code. And the shorter you can get your feedback loop, the sooner you\u0026rsquo;ll notice bugs and the easier (=cheaper) it will be to fix. That means you don\u0026rsquo;t just want to run them before every release, nor on a daily basis, but literally after every change you make.\nThe more you run your test, the more value you\u0026rsquo;ll get from them.\nNow the less time you have to wait for your tests to run, the more often you\u0026rsquo;re going to run them. Consequently for you to run your tests often, they need to run fast\u0026hellip; ludicrously fast.\nNot in one minute, not even in 10 seconds, but your entire test suite should pass in less than a second!\nThis means you\u0026rsquo;ll have to:\nrun your tests on a JVM instead of on a device only test isolated pieces of business logic don\u0026rsquo;t include UI, database or network tests in your main test suite don\u0026rsquo;t use wait/sleep statements in tests 2. Small and focussed tests # Always write your tests with failures in mind. This means explicitly designing your tests to catch bugs in your apps.\nGiven a bug, would you prefer:\none bug -\u0026gt; multiple tests fail one bug -\u0026gt; exactly one test fails Bingo, the second one, because that simplifies debugging. In case of a failing test you just look at the test name to see what went wrong.\n@Test public void logInShouldFailWithWrongPassword() throws Exception { // Test code } For every bug, exactly one test must fail. The root cause of failure should be described by the test name.\nThis forces you to only check for one thing per test and will lead to smaller tests that are easier to understand, easier to explain and easier to maintain.\nThat\u0026rsquo;s why a good test should be small (=few lines of code) and focussed (=only test for one thing), just like any other method in our codebase.\nThis means you\u0026rsquo;ll have to:\nwrite tests with only one single assert/verify statement have more small tests instead of fewer big ones clearly describe the cause of failure in test names 3. 100% reliable # Tests are your safety net, so whenever that tells you something is wrong\u0026hellip; you\u0026rsquo;ll have to take it seriously. That means dropping everything to go and fix that failing test.\nObviously that\u0026rsquo;s quite frustrating as you\u0026rsquo;re eager to build a feature and suddenly you have to start fire fighting somewhere else.\nNow imagine analyzing the problem for a couple of hours, not finding anything wrong, rerunning the tests (out of desperation) and every test suddenly passes\u0026hellip;\nThe most frustrating thing for a developer is waisting time on random errors that are fixed by a clean or IDE restart\nAnd if more tests behave the same way\u0026hellip; you\u0026rsquo;ll loose trust in your entire test suite. You stop taking failures seriously and stop having the benefits from your test suit altogether.\nThat\u0026rsquo;s why all your test need to be 100% reliable and only fail when there is actually a problem.\nThis means you\u0026rsquo;ll have to:\nrun your tests on a JVM (connection to device can break) mock network communication during tests move UI/integration tests out of your unit test suite Wrap-up # The more you run your unit tests, the more value you\u0026rsquo;ll get from them. Awesome unit tests facilitate exactly that by being fast, focussed and super reliable.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"16 February 2017","externalUrl":null,"permalink":"/blog/2017/02/16/unittests/","section":"Blogs","summary":"If you can code, you can also write unit tests. Writing awesome tests on the other hand is a different story. Don\u0026rsquo;t fool yourself: Unit testing code is production code that you will need to maintain, refactor and build upon for years to come.","title":"Write awesome unit tests","type":"blog"},{"content":"","date":"17 January 2017","externalUrl":null,"permalink":"/tags/mockito/","section":"Tags","summary":"","title":"Mockito","type":"tags"},{"content":"The Mockito team is on fire lately! Not only did they add support to mock final classes and methods, but now they allow running Mockito directly onto an actual Android device.\nTime to convert our Mockito 1.x projects to 2.x!\nHistory # It has always been possible to run Mockito on Android devices and emulators. This however required using a tool called Dexmaker to help Mockito generate classes in the Android virtual machine.\nWhile this approach worked fine, there was one big caveat: Dexmaker wasn\u0026rsquo;t actively maintained. Consequently it was only compatible with Mockito 1.x so you couldn\u0026rsquo;t use the new stuff while running tests on an Android device.\nFurther this extra dependency made your build.gradle look like this:\ndependencies { ... testCompile \u0026#39;org.mockito:mockito-core:2.6.3\u0026#39; androidTestCompile \u0026#39;org.mockito:mockito-core:1.10.19\u0026#39; androidTestCompile \u0026#39;com.crittercism.dexmaker:dexmaker:1.4\u0026#39; androidTestCompile \u0026#39;com.crittercism.dexmaker:dexmaker-dx:1.4\u0026#39; androidTestCompile \u0026#39;com.crittercism.dexmaker:dexmaker-mockito:1.4\u0026#39; } Notice the 2.x version for the unit tests and the 1.x version for the instrumentation tests.\nFortunately, Mockito 2.6.0 changed that:\nWe have just released Mockito 2.6 with native support for Android. On Android, just use the mockito-android dependency. Test code stays!\n\u0026mdash; Rafael Winterhalter (@rafaelcodes) 12 januari 2017 Mockito 2.6.0+ # The latest release added a new artifact mockito-android next to the existing mockito-core artifact.\nSo to convert your existing instrumentation tests, just remove the Dexmaker dependencies and replace the mockito-core dependency with its mockito-android equivalent:\ndependencies { ... testCompile \u0026#39;org.mockito:mockito-core:2.6.3\u0026#39; androidTestCompile \u0026#39;org.mockito:mockito-android:2.6.3\u0026#39; } Simple, elegant and future proof!\nFinally, please be aware that Mockito 2.x has some behavior changes. The one you\u0026rsquo;re most likely going to run into while migrating is that anyX() and any(SomeType.class) matchers now reject null values.\nWrap-up # Finally Mockito has first class support for Android instrumentation tests! I\u0026rsquo;ve also updated my Mockito sample project where you can see how it works and learn more about how to use Mockito.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"17 January 2017","externalUrl":null,"permalink":"/blog/2017/01/17/mockitoandroid/","section":"Blogs","summary":"The Mockito team is on fire lately! Not only did they add support to mock final classes and methods, but now they allow running Mockito directly onto an actual Android device.","title":"Using Mockito 2.x on Android","type":"blog"},{"content":"It\u0026rsquo;s that time of the year again to do a little personal retrospective.\n2016 passed by so quickly! I had a fantastic time playing around with (and taking care of) my wife and daughter. It\u0026rsquo;s really astonishing to see how much a baby can learn and grow in a year.\nBeing a father also helps putting things into perspective and rediscover the little pleasures in live. For example, there is literally no better cure for stress than coming home, being greeted by a happy smile and laying down on the floor playing with your own kid. :)\nBesides that, I actually found more time than expected to grow technically. As such I:\nWrote 11 blogposts, almost meeting my goal of 1 per month Got featured in Android weekly a whopping 9 times Appeared on Android dialogs Spoke at 5 big conferences + 1 local meetup Grew my twitter followers to more than 750 Gathered over 1000 stars on Github Gained \u0026gt;2000 reputation on stackoverflow Built a new Github library MockitoCollectionMatchers Visited Google IO (finally!) Built 2 green field side projects! Made plans for building a house Taught my daughter how to fist bump and say Yolo #awesomedad Next year construction of our dream house will start, so time will once again be a scarce resource. And since I don\u0026rsquo;t want to give in on quality time with my daughter, I\u0026rsquo;ll just try to keep up my current blogging and speaking efforts. However, it would be really cool if I could speak at a conference outside Europe!\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"9 January 2017","externalUrl":null,"permalink":"/blog/2017/01/09/yearinreview/","section":"Blogs","summary":"It\u0026rsquo;s that time of the year again to do a little personal retrospective.\n2016 passed by so quickly! I had a fantastic time playing around with (and taking care of) my wife and daughter.","title":"Year in review 2016","type":"blog"},{"content":"Due to its clean simple api, Mockito has become world\u0026rsquo;s most popular Java mocking framework. After having covered all of its basics, it\u0026rsquo;s time to spice things up and start extending Mockito.\nThis blogpost will demonstrate the power of custom Mockito matchers.\nProblem sketch # Imagine a very simple example where a button in the UI sends a message to a User object that in its turn does the a WebService call.\nWe now want to verify that the User calls the sendMessages() method on the WebService with the appropriate arguments.\nTraditional test # The way to typically test such a scenario is to use an ArgumentCaptor that captures the ArrayList passed to sendMessages(). Next you can verify that the list contains the appropriate element.\n@Test public void sendMessage() throws Exception { User user = new User(mockWebService, USER_ID, PASSWORD); ArgumentCaptor\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; listArgumentCaptor = ArgumentCaptor.forClass(List.class); String expectedMessage = \u0026#34;Test message\u0026#34;; user.sendMessage(expectedMessage); verify(mockWebService).sendMessages(eq(user), listArgumentCaptor.capture()); List\u0026lt;String\u0026gt; messages = listArgumentCaptor.getValue(); String actualMessage = messages.get(0); assertEquals(expectedMessage, actualMessage); } I don\u0026rsquo;t even have to begin to explain how cumbersome this is!\nCustom matcher test # We can dramatically simplify this by writing our own Mockito matcher and use that as an argument in our test verification.\nFirst we create a class called ListContains that implements the ArgumentMatcher interface. Then add a constructor that get\u0026rsquo;s the expected element and implement the matches() method so it checks if the list contains that element.\npublic class ListContains\u0026lt;T\u0026gt; implements ArgumentMatcher\u0026lt;List\u0026gt; { private final T object; public ListContains(T object) { this.object = object; } public boolean matches(List list) { return list.contains(object); } public String toString() { //printed in verification errors return \u0026#34;[list doesn\u0026#39;t contain object]\u0026#34;; } } Note that toString() prints an error when the verification fails.\nTo make the matcher syntax more intuitive you should create a new class called ListMatchers that provides a easy to access the matcher.\npublic class ListMatchers { @Nullable public static \u0026lt;K\u0026gt; List listContains(K object) { return argThat(new ListContains\u0026lt;\u0026gt;(object)); } } With this new custom matcher, we can simplify the test to:\n@Test public void customMatchers() throws Exception { User user = new User(mockWebService, USER_ID, PASSWORD); String expectedMessage = \u0026#34;Test message\u0026#34;; user.sendMessage(expectedMessage); verify(mockWebService).sendMessages(listContains(expectedMessage)); } Pretty neat isn\u0026rsquo;t it?\nLibrary # After a great suggestion from Eugen Martynov, I\u0026rsquo;ve decided to create a library for all of these collection matchers on Github.\nAll you have to do is add Jitpack to your main build.gradle file:\nrepositories { maven { url \u0026#34;https://jitpack.io\u0026#34; } } And add a dependency on the library in your project build.gradle file:\ntestCompile \u0026#39;com.github.JeroenMols:MockitoCollectionMatchers:0.0.1\u0026#39; This is very much a work in progress, so expect more matchers to come soon!\nWrap-up # Custom matchers are a great way to simplify unit tests. In my Mockito sample project you can learn more about how to use Mockito and find other custom matcher examples.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"31 October 2016","externalUrl":null,"permalink":"/blog/2016/10/31/mockitomatchers/","section":"Blogs","summary":"Due to its clean simple api, Mockito has become world\u0026rsquo;s most popular Java mocking framework. After having covered all of its basics, it\u0026rsquo;s time to spice things up and start extending Mockito.","title":"Extending Mockito","type":"blog"},{"content":"Code coverage is an awesome way to motivate you and your team to write more tests. But did you know that simply enabling it slows down your build significantly?\nThis blogpost will detail why and offer an easy solution.\nImpact on build speed # Profiling your Gradle build speed can easily be done using the --profile option:\n./gradlew clean assembleDebug --profile When profiling a project recently, I noticed something surprising in the generated report:\nThe Jacoco task takes up almost 12 second, accounting for 14% of the build time!\nThat\u0026rsquo;s crazy! Especially because our build command isn\u0026rsquo;t even running any test.\nLooking at our build.gradle file it is clear that we\u0026rsquo;re not really doing anything exotic:\nbuildTypes { debug { ... testCoverageEnabled true } } Yet this still causes delays in all debug builds.\nThe solution # Ask yourself when do you need code coverage? At most after running unit tests, but probably only after running a CI build.\nHence we\u0026rsquo;re going to introduce a very simple flag -Pcoverage which we can add to the build command:\n./gradlew -Pcoverage clean connectedDebugAndroidTest All you need to do to make this work is a small modification to your build.gradle file:\nbuildTypes { debug { ... testCoverageEnabled (project.hasProperty(\u0026#39;coverage\u0026#39;) ? true : false) } } And now code coverage will run when you add the flag and won\u0026rsquo;t run when you don\u0026rsquo;t add it!\nNote that you can also add this flag to the test configuration in Android Studio if you also want to have coverage enabled while running tests locally.\nWrap-up # Code coverage is a great way to track your testing efforts. With help of a simple flag you can easily avoid it from slowing down your normal development builds.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"1 September 2016","externalUrl":null,"permalink":"/blog/2016/09/01/coveragecost/","section":"Blogs","summary":"Code coverage is an awesome way to motivate you and your team to write more tests. But did you know that simply enabling it slows down your build significantly?","title":"The hidden cost of code coverage","type":"blog"},{"content":"","date":"3 August 2016","externalUrl":null,"permalink":"/tags/copyright/","section":"Tags","summary":"","title":"Copyright","type":"tags"},{"content":"As die hard Android developers, copyright notices are usually not on top of our priority list. Yet large corporations always insist to add a copyright header. Why do they do that? Should you do that for your open source libraries?\nThis blog post will explain what copyright is and why it\u0026rsquo;s so important. Further it\u0026rsquo;ll also show how to easily add/update copyright notices to your code base.\nIntro to copyrights # According to wikipedia, copyright is:\n\u0026hellip;a legal right created by the law of a country that grants the creator of an original work exclusive rights for its use and distribution\nSimplified this means that when you create something \u0026ldquo;original\u0026rdquo;, people cannot simply use or copy that without your explicit permission.\nThis applies to art forms such as: literary works, music compositions, photographs,\u0026hellip; and the highest art form of all: computer software!\nHence every line of code you write is - besides a true piece of art - protected by copyright for the rest of your life. No action is needed to acquire this right, it\u0026rsquo;s implicitly granted on creation.\nNow obviously this is highly simplified and there are important exceptions, most notably \u0026ldquo;the right of quotation\u0026rdquo;. But it\u0026rsquo;s fair to state that anything you blog or code in your time is falls under copyright protection.\nWhat with the software I write for my employer?\nAll copyrights explicitly belong to your employer, unless you explicitly agree to other terms in your contact.\nLicenses # A software license is a \u0026ldquo;contract\u0026rdquo; that allows others from using your code. Restrictions may apply on how \u0026ldquo;it can be used\u0026rdquo; and explicit terms may be imposed prior to using it.\nCreating code # All code you write is by default copyright protected, even when not enforced by an explicit license. Therefore others are not allowed to use it, even if you make it publicly available on GitHub!\n\u0026hellip;the absence of a license means that the default copyright laws apply. This means that nobody else may reproduce, distribute, or create derivative works from your work.\nTherefore it is utterly important to explicitly state a license, otherwise all open source code you write is\u0026hellip; well\u0026hellip; useless.\nTo apply a license, simply distribute a license together with your source code e.g by putting a LICENSE file at the root of my repository. Further it is also a good idea to add a copyright notice on top of every file to avoid any confusion.\nThis is how I did it in the my library LandscapeVideoCamera.\nAnd at the top of every file:\nUsing code # There is a common misconception that open source equals free to use. In reality however, even seemingly innocent open source communities will take legal action if you infringe on their license. Hence care must be taken to comply with the license of all code you use.\nComplying to a license can range from:\nMaking all your code open source Only non commercial use Acknowledging the author \u0026hellip; Do carefully review the license of every piece of software you use and make sure you satisfy all of its terms.\nShould that not be acceptable for your use case, you can always contact the author and request him/her to purchase the same software under an alternative license.\nUnderstanding licenses # As you\u0026rsquo;re likely not a legal ninja, you must be wondering:\nHow do I pick the right license for my project? Given a license, where can I find its terms/restrictions? Well there is a great website explaining the ins and outs of various licenses: choosealicense.com.\nObviously if you work for a larger corporation like me, you should also involve your legal department.\nAdding/Updating licenses to your code # Fortunately Android studio can completely handle all hassle of adding copyright notices for you. It can even update existing notices should you decide to move to a different license or simply update the year.\nFirst of all go to \u0026ldquo;Preferences \u0026gt; Editor \u0026gt; Copyright \u0026gt; Copyright profiles\u0026rdquo; and press the plus icon to add a new profile. Give it a meaningful name and fill in your copyright notice.\nCopyright $today.year Jeroen Mols Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Note that you can use the flag $today.year to denote the current year.\nOptionally, the formatting pane allows you to tweak the copyright notice for every file type (Java, Xml, Groovy,\u0026hellip;)\nNow select the \u0026ldquo;default project copyright\u0026rdquo; in the main Copyright pane and you\u0026rsquo;re fancy new copyright will be added to every new file you create.\nTo update or add the notice to all your existing files, simply right click any file in the project pane and select \u0026ldquo;Update copyright\u0026hellip;\u0026rdquo;.\nThat\u0026rsquo;s it! You now have a one click way of ensuring your copyright notices are up to date.\nWrap-up # Copyright is not something to mess around with and you can face cause serious legal consequences if you don\u0026rsquo;t. Even your open source projects should have a proper copyright notice. Fortunately choosealicense.com and Android Studio help you choose and apply the correct license.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"3 August 2016","externalUrl":null,"permalink":"/blog/2016/08/03/copyright/","section":"Blogs","summary":"As die hard Android developers, copyright notices are usually not on top of our priority list. Yet large corporations always insist to add a copyright header.","title":"Why you should care about copyright","type":"blog"},{"content":"","date":"21 July 2016","externalUrl":null,"permalink":"/tags/cycling/","section":"Tags","summary":"","title":"Cycling","type":"tags"},{"content":"","date":"21 July 2016","externalUrl":null,"permalink":"/tags/howto/","section":"Tags","summary":"","title":"Howto","type":"tags"},{"content":"Cycling is all about exploring: visiting new places and making existing routes more fun with better streets. So there must be an app that allows to plan your route and start cycling right? Think again\u0026hellip; there is currently no solution that offers turn by turn navigation for cyclists.\nAs I had an old Android device laying around, I decided to repurpose that and convert it into a GPS that:\ntracks my activity imports gpx tracks created on my computer offers turn by turn navigation (screen + voice) This blogpost will detail how I use OsmAnd and Dropsync to create new tracks with minimal effort. Further I\u0026rsquo;ll also describe the gear I use in order to make this work.\nGear # To build your own GPS, you\u0026rsquo;ll need the following:\nAndroid phone - I use my Nexus 5, but any Android device will do Bicycle GPS mount - I use this one Rainproof case - I use these Create tracks # To explore new places, you need a great tool to create cycling routes. I personally use Strava because it has a \u0026ldquo;global Heatmap\u0026rdquo; and also supports \u0026ldquo;segments\u0026rdquo; where most people cycle. It is a great way to figure out popular cycling streets and help you plan a great route. Note that you can do all of this using a free account, but with a premium subscription you will get lots more.\nTo create routes, just go to \u0026ldquo;My routes\u0026rdquo; and select \u0026ldquo;Create new route\u0026rdquo;:\nThe global Heatmap indicates where most people cycle:\nSegments are often challenging parts to cycle, that contain a leaderboard:\nOnce you created a route, you can export it to a gpx file format. Note that it doesn\u0026rsquo;t matter which GPS you choose to do the export.\nConfigure OsmAnd # OsmAnd offers both turn by turn navigation and storing maps offline. This is ideal to save bandwidth or for phones without a sim card (like mine). It is completely free to use, but there is also a premium version if you want to support this awesome project.\nGetting it to work with gpx files is tricky and hence I will guide you through it.\nFirst of all install OsmAnd (or OsmAnd+). When you open the app, press \u0026ldquo;skip\u0026rdquo; and don\u0026rsquo;t download any maps. This is because they would end up in a private directory. Open the hamburger menu, go to \u0026ldquo;Settings\u0026rdquo; and open \u0026ldquo;General settings\u0026rdquo;.\nNow we\u0026rsquo;re going to change the directory in which OsmAnd stores all of its files. Use \u0026ldquo;Data storage folder\u0026rdquo;, click the \u0026ldquo;edit icon\u0026rdquo; and select \u0026ldquo;Shared memory\u0026rdquo; as the data storage folder. This will put all files in an \u0026ldquo;osmand\u0026rdquo; directory on the root of your internal storage. Accept the permission when promted to allow OsmAnd to create and write to that folder.\nNext go ahead and download the maps for the areas in which you will be cycling. When prompted for a storage folder, again select \u0026ldquo;Shared memory\u0026rdquo;.\nAutomatically sync tracks using Dropbox # Getting new tracks on your phone can be quite a hassle. Therefore we\u0026rsquo;ll automate this process so you can add new tracks to your phone by only using your computer.\nFirst of all, create a new folder in your Dropbox account called \u0026ldquo;Cycling\u0026rdquo;.\nThen install the app Dropsync (or Dropsync pro). Next configure it so that it automatically syncs any file you put in the Dropbox folder into the correct folder on the Android phone.\nOpen Dropsync, login with your Dropbox account and select \u0026ldquo;let me create my own folder pair\u0026rdquo;. As the local folder choose \u0026ldquo;osmand/tracks\u0026rdquo; and as the remote folder \u0026ldquo;Cycling\u0026rdquo;. Then select \u0026ldquo;Download mirror\u0026rdquo; as the sync method and enable sync. Save the changes and wait for the sync to complete.\nNow all you have to do is export a track from Strava, move it into the Dropbox folder and it will autmagically appear in OsmAnd on your GPS!\nTurn by turn navigation # Finally you\u0026rsquo;re ready to start using your synced tracks for turn by turn navigation.\nOpen OsmAnd and press the \u0026ldquo;globe\u0026rdquo; icon in the top left corner. Scroll down a bit and select \u0026ldquo;GPX track\u0026hellip;\u0026rdquo; to choose the track you want to display. Exit the screen and start navigation by pressing the \u0026ldquo;navigation\u0026rdquo; icon in the bottom left corner.\nEnjoy your turn by turn navigation!\nTips and tricks # I\u0026rsquo;ll update this section as I discover new handy features/tricks to make the GPS even more usefull.\nRemove the lockscreen: go to \u0026ldquo;Device Settings\u0026rdquo; \u0026gt; \u0026ldquo;Security\u0026rdquo; and set the \u0026ldquo;Screen lock\u0026rdquo; to \u0026ldquo;none\u0026rdquo;. This will enable you to simply press the power key to turn on your screen. Wrap-up # In a few very simple steps we created a complete cycling GPS solution that provides turn by turn navigation and offline maps. Creating tracks is done using Strava and export using a Dropbox folder so that they automatically appear on your GPS device.\nIf this was helpful to you, consider buying me a coffee or thanking me on Mastodon!\n","date":"21 July 2016","externalUrl":null,"permalink":"/blog/2016/07/21/cyclinggps/","section":"Blogs","summary":"Cycling is all about exploring: visiting new places and making existing routes more fun with better streets. So there must be an app that allows to plan your route and start cycling right?","title":"Turn Android into an awesome cycling GPS","type":"blog"},{"content":"","date":"24 June 2016","externalUrl":null,"permalink":"/tags/droidcon/","section":"Tags","summary":"","title":"Droidcon","type":"tags"},{"content":"At Droidcon Berlin 2016 I had a great time talking about testing using the Mockito framework. While the talk wasn\u0026rsquo;t recorded unfortunately, the great folks at Voice Republic recorded an audio version which you can listen to as a podcast or together with the slides.\nTalk # The past year has been huge for Android testing: Testing support lib, fast JVM unit tests,\u0026hellip; Having such great tools means writing tests is a breeze! All your apps currently have \u0026gt;80% code coverage, right? Yay! Or wait\u0026hellip; is it really? Is all your common Android logic (networking, databases,\u0026hellip;) tested? Do you isolate parts of your code base to keep your tests small? And what about providing relevant testing data?\nIn order to achieve this, you need to make use of mocks and stubs. And that\u0026rsquo;s exactly what this talk will be about: What is a mock? What\u0026rsquo;s the difference between a mock and a stub? Are mocks the only way to provide relevant data for your unit tests? What do I do with all the final classes/methods in the Android SDK? How do I architect my app to make it easier to test? \u0026hellip;\nAfter having adopted TDD as my main development workflow for almost a year now, I feel comfortable saying everything can be tested. Its just a matter of having someone experience show you how.\nCode # A fully working sample project with all principles is available on Github.\nbuild.gradle file indicating how to configure Mockito testCompile: for tests run on your computer in a JVM (src/test folder) androidTestCompile: for tests run on an Android device (src/androidTest folder) UserTest class demonstrating Mockito usage TLDR: JVM unit tests with mockito are easy to read and write UserTestAndroid class demonstrating Mockito usage on Android device TLDR: Mockito can be used on Android, but need to use V1 and dexmaker HandlerWrapper class indicating how to test final methods TLDR: Wrap final or statics methods with a different non static/final method TestUserData class indicating how to provide testing data for POJO objects TLDR: Override all methods with default values instead of creating a mock and stubbing them out Audience # ","date":"24 June 2016","externalUrl":null,"permalink":"/blog/2016/06/24/droidcondetalk/","section":"Blogs","summary":"At Droidcon Berlin 2016 I had a great time talking about testing using the Mockito framework. While the talk wasn\u0026rsquo;t recorded unfortunately, the great folks at Voice Republic recorded an audio version which you can listen to as a podcast or together with the slides.","title":"Testing made sweet with a Mockito","type":"blog"},{"content":"Having founded the entire Droidcon franchise in 2009, Droidcon Berlin is a magical conference to be at. Not only do they have an awesome lineup of speakers (including yours truly). But they also organize great after hour events. Further they\u0026rsquo;re the first conference ever where I didn\u0026rsquo;t have any Wi-Fi issues (looking at you #io16).\nAs there were four different tracks, it was obviously not possible to attend every session. But I did notice some general themes and would like to share my personal highlights with you.\nArchitecture # While Android is maturing as a platform, developers are also professionalizing their applications. Every growing apps mean that testability, maintenance and refactoring is only increasing in importance.\nMy key takeaways:\nMVP is a UI pattern not an architecture All dependencies should point in one direction Don\u0026rsquo;t be dogmatic Users don\u0026rsquo;t care about your architecture IoT # Interest in IoT products is steadily increasing, but as a developer it is still not easy to create IoT apps. Properly handling things like Bluetooth LE keeps on being plagued by device specific issues. And seemingly simple problems like properly handling a user sign in are still extremely complex.\nMy key takeaways:\nWhen using BT LE, only support API 21 or higher Handle all bluetooth LE callbacks on separate HandlerThread Firebase can handle all sign in complexity for you Designing for the next billion # Where we used to be educated that \u0026ldquo;a developer phone is not a user phone\u0026rdquo;, this message is now morphing towards people in emerging markets. Designing for such markets doesn\u0026rsquo;t only require functional changes like developing for offline first, but it even requires you to completely think your UX.\nMy key takeaways:\naccess to cheap fast internet is not a given battery life is even more precious in emerging countries understandable UX when smartphone is your first computer Other hot topics # Besides these, also a lot of attention was spent on testing and tooling. There were great talks about styling, theming and creating custom views. And many sessions also dived deeper into optimizing your apps performance. Bit unfortunate that there weren\u0026rsquo;t any more talks on the new Android N features.\nMy key takeaways:\nYou can use alpha values for button states in XML Use overlay themes instead of changing text colors Tests should be fast, focussed and reliable It maybe worth to convert an existing app to RXJava, but keep it contained to particular layers. (e.g. Webservice) Sketchnoting # Sketch notes are really awesome! In this, creative people summarize a talk into a very cool one pager. This doesn\u0026rsquo;t only look great, but it\u0026rsquo;s also by far the easiest way to get a high level view of a talk.\nAt Droidcon both Corey Leigh Latislaw and Teresa Holfeld were actively creating sketch notes. You should check their twitter feeds for the awesome content they created.\nJust a sample:\nOffline First by @glynn_bird at #droidconDe. #sketchnote pic.twitter.com/SkeriMsigT\n\u0026mdash; Corey Leigh Latislaw (@corey_latislaw) June 16, 2016 Themes and Styles demystified: talk by @chrisbanes #droidconDE #sketchnotes pic.twitter.com/mXNcW8lGRS\n\u0026mdash; Teresa Holfeld (@TeresaHolfeld) June 16, 2016 Thanks for both of them for creating such great summaries.\nConference slides # While the conference organizers will publish all slides very soon, I can image that quite a few people are already looking for a sneak preview. Hence I bundled everything I could already gather from socials.\nTesting made sweet with a Mockito by Jeroen Mols Reverse engineering is not just for hackers by Jon Reeve Refactoring Plaid - A reactive MVP approach by Hannes Dorfmann Android \u0026amp; IoT by Selim Salman Unit testing without Robolectric by Danny Preussler #Perfmatters for Android by Hasan Hosgel Life of Android Enterprise Developers in the age of Android for Work by Pietro Maggi The 2016 Android Developer Toolbox by Gautier Mechling Practical Bluetooth Low Energy on Android by Erik Hellman Contextual Communications And Why You Should Care by Marcos Placona Deep dive into Android Data Binding by Radek Piekarz Let\u0026rsquo;s get physical by Albrecht Noll and Pascal Welsch Testing Why? When? How? by Tomasz Polański Adopting RxJava on Airbnb Android by Felipe Lima Elegant?? Unit Testing by Pablo Guardiola Material design custom views by Said Tahsin Dane Android TV: Building apps with Google\u0026rsquo;s Leanback Library by Joe Birch Screenshot your Entire App by Edward Dale Little helpers for Android development with Kotlin by Kai Koenig Effective Android Development by Sergii Zhuk Android is the World Phone by Corey Latislaw Loving lean layouts by Huyen Tue Dao Let it flow - unidirectional data flow architecture on Android by Benjamin Augustin We\u0026rsquo;re all UX! by Lydia Selimalhigazi and Caroline Smith 10 ways to analyse runtime failure using Classy Shark by Boris Farber Credits # Thanks to the entire Droidcon Berlin team for organizing such a great conference and to all sponsors for their support. Keep up the awesome job!\n","date":"18 June 2016","externalUrl":null,"permalink":"/blog/2016/06/18/droidconde/","section":"Blogs","summary":"Having founded the entire Droidcon franchise in 2009, Droidcon Berlin is a magical conference to be at. Not only do they have an awesome lineup of speakers (including yours truly).","title":"Droidcon Berlin recap","type":"blog"},{"content":"As green field projects are a rare breed, chances are that you\u0026rsquo;ve inherited a legacy code base. If you\u0026rsquo;re as lucky as me, that code base has over 65k methods causing the build times to be boringly slow.\nToday I would like to show how you can visualize your current method count and understand what libraries are eating up the largest part of that. Next it\u0026rsquo;s time to reduce said method count and remove that nasty multidex solution once and for all.\nVisualizing method count # The easiest and most attractive way (imho) to visualize the method count is by using the Dexcount Gradle Plugin. Applying it to your project is as easy as adding a classpath dependency to your root build.gradle and applying the plugin to your App build.gradle.\n// root build.gradle file buildscript { repositories { jcenter() // or mavenCentral() } dependencies { classpath \u0026#39;com.getkeepsafe.dexcount:dexcount-gradle-plugin:0.5.0\u0026#39; } } // app build.gradle file (apply AFTER Android plugin) apply plugin: \u0026#39;com.getkeepsafe.dexcount\u0026#39; Running a normal project build ./gradlew assembleDebug will now print out the current method count in the console:\nand generate an interactive graphical report in the outputs folder build/outputs/dexcount/debugChart:\nClick the graphic above to interact with it.\nUsing the graphical representation of the method count for all packages in your app, it becomes really easy to find which libraries are consuming your precious method count. Some of the usual suspects are big monolithic libraries like Guava and the non-split-up Google play services. In the next section will see what we can do about these.\nReducing method count # Choosing the right libraries # Normally I recommend never to optimize unless you have a problem. But with method counts, I really advice you to consider the method count before you start using a library for two reasons:\nReplacing libraries in existing apps can be very challenging, if not almost impossible. Many developers are using huge libraries just to do simple things. (Strings.isNullOrEmpty() anyone?) Note that you don\u0026rsquo;t need to use a library for everything! There used to be a great website methodscount that told you the method count of a library before you start using it. This can really be helpful to avoid using \u0026ldquo;large libraries\u0026rdquo; which only add limited benefit to your app.\nReplacing existing libraries # Often there are multiple libraries accomplishing the same goals. Take for instance image loading:\nLibrary Method count Picasso 2.5.2 849 Universal Image Loader 1.9.5 1206 Glide 3.7.0 2879 Fresco 0.9.0 12984 Each of these libraries have their own benefits and features, so choose wisely and balance the features you are going to use versus the method count impact it will have.\nThat being said, replacing libraries in existing projects can be incredibly hard and may not even be feasible on the short term. Later I\u0026rsquo;ll suggest an alternative solution to reduce method count in existing libraries.\nRunning Proguard # Proguard is a great tool to strip out unused code from your app, but you typically only run it for release builds to save precious build time. If that\u0026rsquo;s not really an issue for you, by all means you can also enable Proguard for debug builds:\nbuildTypes { debug { minifyEnabled true proguardFiles getDefaultProguardFile(\u0026#39;proguard-android.txt\u0026#39;), \u0026#39;proguard-rules.pro\u0026#39; } } Reducing library size # If it\u0026rsquo;s not feasible to replace an existing library or to run Proguard all the time, then it becomes really interesting. Because if Proguard can strip out code during a release build, why not use it ahead of time to create a modified version of a library with fewer methods?\nWell this is possible, but you\u0026rsquo;ll have to manually specify which parts of the library you are going to use! This is because Proguard doesn\u0026rsquo;t have a context during library stripping of what methods your application will be needing and what not.\nLet\u0026rsquo;s reproduce one of the projects I recently started working on as an example. Guava was used throughout the app extensively, making it very hard/risky to remove. But because of the huge method count we were constantly flirting with the 65k method limit and had to enable multidex.\nFirst of all you need to know what parts of the library the app was actually using. This can easily be done by running the following command in your src folder.\ngrep -roh . -e \u0026#39;com.google.common.*\u0026#39; | sort | uniq This simply looks for all import statements starting with the library prefix (for Guava that is com.google.common), removes all clutter from the grep output, sorts it and takes all unique references.\nNext we\u0026rsquo;ll create a simple Proguard configuration that keeps all top level packages, without any obfuscation or optimizations.\n-dontoptimize -dontobfuscate -keep public class com.google.common.base.** { public *; } -keep public class com.google.common.collect.** { public *; } -keep public class com.google.common.primitives.** { public *; } -keep public class com.google.common.util.** { public *; } Now we\u0026rsquo;ll use a little Gradle script that takes a library as an input, runs Proguard on it an creates a new library as an output. If you\u0026rsquo;re interested I advice you look at the source code, which is based on a script by @mr_ligi. This Gradle script outputs a shrinked library version, which can be copied to the libs folder of your project.\nLooking at our example, this simple process saved us 4000 methods and we are only just above the dex method limit.\nBack to the drawing board, because this isn\u0026rsquo;t nearly enough! Turns out the collect package by itself has over 8000 methods, so I decided to just keep certain classes instead of the entire package.\nThis more aggressive approach will most likely cause some compile errors when you try to use the library in your app, so I had to iterate and add some extra classes until all of those were solved. The resulting Proguard configuration looks like this:\n-dontoptimize -dontobfuscate -keep public class com.google.common.base.** { public *; } -keep public class com.google.common.collect.Sets -keepclassmembers class com.google.common.collect.Sets** { *; } -keep public class com.google.common.collect.Collections2 -keepclassmembers class com.google.common.collect.Collections2** { *; } -keep public final class com.google.common.collect.Lists -keepclassmembers class com.google.common.collect.Lists** { *; } -keep public final class com.google.common.collect.Iterables -keepclassmembers class com.google.common.collect.Iterables** { *; } -keep public class com.google.common.collect.ImmutableList.** { public *; } -keep public class com.google.common.io.CharStreams { public *; } -keep public class com.google.common.collect.HashMultiset -keepclassmembers class com.google.common.collect.HashMultiset** { *; } -keep public class com.google.common.collect.HashBiMap -keepclassmembers class com.google.common.collect.HashBiMap** { *; } -keep public class javax.annotation.Nullable.** { public *; } -keep public class com.google.common.util.** { public *; } -keep public class com.google.common.primitives.** { public *; } Resulting in an extra decrease of almost 4500 methods, which brings the total removed methods to 8500!\nFurther our build times have not only improved because we no longer need multidexing, but also because the compiler now has less code to process.\nObviously your mileage will vary depending on what library you choose. For low coupled, highly cohesive libraries (like Guava), this technique works really well, but for other libraries it might not.\nDisclaimer\nThe technique presented above should be used with caution! Because instead of relying on Proguard to strip out what\u0026rsquo;s not needed, we\u0026rsquo;re now doing that manually, which is more error prone.\nWrap-up # Hitting the 65k method limit is a real pain, but choosing wisely what libraries you use can already bring you a long way. Fortunately there is a great tools like the Dexcount Gradle Plugin to help with these decisions.\nFor existing projects, always try to replace existing large method libraries with alternatives. If this is not feasible and you feel comfortably using Proguard, you can use the latter to preprocess and shrink existing libraries.\nA basic example project with everything in this blogpost integrated is available on GitHub.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"6 May 2016","externalUrl":null,"permalink":"/blog/2016/05/06/methodcount/","section":"Blogs","summary":"As green field projects are a rare breed, chances are that you\u0026rsquo;ve inherited a legacy code base. If you\u0026rsquo;re as lucky as me, that code base has over 65k methods causing the build times to be boringly slow.","title":"Efficiently reducing your method count","type":"blog"},{"content":"","date":"6 May 2016","externalUrl":null,"permalink":"/tags/methodcount/","section":"Tags","summary":"","title":"Methodcount","type":"tags"},{"content":"","date":"6 May 2016","externalUrl":null,"permalink":"/tags/proguard/","section":"Tags","summary":"","title":"Proguard","type":"tags"},{"content":"A conference about our favorite Green little robots? In sunny Italy? With great food and a party? Yeah, I can image how you must feel in case you missed it\u0026hellip; I on the other hand was fortunate enough to attend and speak at this awesome conference.\nWith over 770 attendees and four different tracks, it was obviously not possible to attend every session. But I did notice some general themes and would like to share my personal highlights with you.\nWe are all UX # The holy grail in app development is to have an amazing user experience. While app performance and feature set are obviously important, you must also understand your users, simplify main use cases and have a delightful design.\nDo you really think a developer or designer alone can create such a great UX? NO, off course not! They\u0026rsquo;ll both have to work together and synergize to really blow the users of their feet. We need more pairing between developers and designers folks!\nThe best advice I got was:\nA prototype is worth a thousand meetings. Five people to test your prototype with is the sweet spot. It\u0026rsquo;s enough to notice patterns, yet not too much to be a burden. Developers and designers should be transparent and open to learn from each other \u0026ldquo;How might we\u0026hellip;\u0026rdquo; is a great way to phrase problems as opportunities Optimizing layouts # Screens containing a lot of views can sometimes render slowly. Mostly caused by deeply nested view hierarchies and/or using RelativeLayouts as a root element. Using \u0026ldquo;heavy\u0026rdquo; layouts in lists or increased nesting makes these problems multiplicative instead of simply additive.\nWhen running into issues, first resolve to Lint and investigate all warnings. If the problem persist, Hierarchy viewer will help you understanding what\u0026rsquo;s going on. Always prefer simple solutions over complex ones and if you really really have to you can go - Facebook Style - replacing views with drawables.\nThe best advice in this track was:\nRendering times in Hierarchy Viewer are not reliable Optimize responsibly DEX diet # Hitting the DEX method limit or trying to improve your app security? As a real Proguard expert you created an amazing configuration and now all those problems are gone. Or are they?\nAnalyzing your own APK file is a must to verify what methods are actually stripped and what code is obfuscated. Who knows you might even find some duplicate dependencies (GSON anyone?), causing a further method count reduction. Thanksfully all of this has become a breeze thanks to tools like ClassyShark.\nThe best advice here was:\nBe restrictive using Proguard iso keeping entire packages IDE method count != dex method count Use methodscount.com to see how large a lib is before using it Other hot topics # Besides the three main themes, other topics varied from Kotlin, over library distribution to (MVP) architecture and app store optimizations. Awesome sources of inspiration, brought by even more awesome speakers.\nMy key takeaways:\nUse App invites to grow your user base If you don\u0026rsquo;t like testing your code, most likely customers won\u0026rsquo;t like testing your app either Italian food is awesome Conference slides # Distribute your libraries via Maven, even privately by Jeroen Mols Think like a designer by Nick Butcher Let it flow by Benjamin Augustin #Perfmatters for Android by Hasan Hosgel Android Library A-Z by Martin Liersch The bytecode mumbo-jumbo by Raimon Ràfols To ∞ (~65K) and beyond! by Sebastiano Gottardo Android data binding in action using MVVM pattern by Fabio Collini From Clockwork to smartwatch by Daniele Bonaldo Android internal library management by Kelly Shuster Reverse engineering is not just for hackers by Jon Reeve How to talk to your users by Alex Florescu Crafting Great Hypotheses by Hoang Huynh Building maintainable app with MVP and Dagger2 by Kristijan Jurković Build An Efficient REST Client On Android by Matteo Gazzurelli Chronicles of TDD by Luca Falsina Backend 4 Android developers by Antonio Mallia \u0026amp; Nicola Corti A realtime infrastructure for Android apps: Firebase may be what you need..and even more! by Alessandro Martellucci Evolving the Android core with Aspects by Carlo Pescio Android: It\u0026rsquo;s time to go to work! by Pietro Maggi Drive together not the same by Giovanni Laquidara A friend in need - A JS indeed by Yonatan Levin Application Architecture for Scaled Agile by Sangsoo Nam FLUX based clean architecure by Luca Bruzzone Engage and retain users in android world by Matteo Bonifazi Bonjour Android, it\u0026rsquo;s Zeroconf by Roberto Orgiu We\u0026rsquo;re all UX! by Lydia Selimalhigazi and Caroline Smith Mastering the NDK by Xavier Hallade BLE beacons, Eddystone and Physical Web by Alessio Cucini and Samuele Forconi World-Class Testing Development Pipeline for Android by Pedro Vicente Gómez Sánchez] ClassShark - Android and Java executables browser by Boris Farber Credits # Thanks to the entire Droidcon Italy team for organizing such a great conference and to all sponsers for their support.\n","date":"8 April 2016","externalUrl":null,"permalink":"/blog/2016/04/08/droidconit/","section":"Blogs","summary":"A conference about our favorite Green little robots? In sunny Italy? With great food and a party? Yeah, I can image how you must feel in case you missed it\u0026hellip; I on the other hand was fortunate enough to attend and speak at this awesome conference.","title":"Droidcon Italy recap","type":"blog"},{"content":"Do you remember the last time you had to dig into strings.xml to find the right String to use? Or that you manually had to go over all drawables to find the one you needed?\nWhenever we start a new project, we take a lot of care in setting up our architecture, CI, build flavors,\u0026hellip; But do you also have a strategy to name your resources?\nYou should! Because the lack of XML namespaces, makes managing Android resources tedious. And causes things to grow out of control easily, especially in large projects.\nSo let\u0026rsquo;s introduce a simple scheme that will solve your pains.\neasy lookup of any resource (autocomplete) logical, predictable names clean ordering of resources strongly typed resources This blogpost will explain the mechanism, its advantages, limitations and provide an easy to use cheat sheet.\nBasic principle # All resource names follow a simple convention.\nLet\u0026rsquo;s first describe every element briefly. After the advantages, we\u0026rsquo;ll see how this applies to each resource type.\n\u0026lt;WHAT\u0026gt; # Indicate what the resource actually represents, often a standard Android view class. Limited options per resource type. (e.g. MainActivity -\u0026gt; activity)\n\u0026lt;WHERE\u0026gt; # Describe where it logically belongs in the app. Resources used in multiple screens use all, all others use the custom part of the Android view subclass they are in. (e.g. MainActivity -\u0026gt; main, ArticleDetailFragment -\u0026gt; articledetail)\n\u0026lt;DESCRIPTION\u0026gt; # Differentiate multiple elements in one screen. (e.g. title)\n\u0026lt;SIZE\u0026gt; (optional) # Either a precise size or size bucket. Optionally used for drawables and dimensions. (e.g. 24dp, small))\nDownload and print the cheat sheet for easy reference.\nAdvantages # Ordering of resources by screen The WHERE part describes what screen a resource belongs to. Hence it is easy to get all IDs, drawables, dimensions,\u0026hellip; for a particular screen. Strongly typed resource IDs For resource IDs, the WHAT describes the class name of the xml element it belongs to. This makes is easy to what to cast your findViewById() calls to. Better resource organizing File browsers/project navigator usually sort files alphabetically. This means layouts and drawables are grouped by their WHAT (activity, fragment,..) and WHERE prefix respectively. A simple Android Studio plugin/feature can now display these resources as if they were in their own folder. More efficient autocomplete Because resource names are far more predictable, using the IDE\u0026rsquo;s autocomplete becomes even easier. Usually entering the WHAT or WHERE is sufficient to narrow autocomplete down to a limited set of options. No more name conflicts Similar resources in different screens are either all or have a different WHERE. A fixed naming scheme avoids all naming collisions. Cleaner resource names Overall all resources will be named more logical, causing a cleaner Android project. Tools support This naming scheme could be easily supported by the Android Studio offering features such as: lint rules to enforce these names, refactoring support when you change a WHAT or WHERE, better resource visualisation in project view,\u0026hellip; Layouts # Layouts are relatively simple, as there usually are only a few layouts per screen. Therefore the rule can be simplified to:\nWhere \u0026lt;WHAT\u0026gt; is one of the following:\nPrefix Usage activity contentview for activity fragment view for a fragment view inflated by a custom view item layout used in list/recycler/gridview layout layout reused using the include tag Examples:\nactivity_main: content view of the MainActivity fragment_articledetail: view for the ArticleDetailFragment view_menu: layout inflated by custom view class MenuView item_article: list item in ArticleRecyclerView layout_actionbar_backbutton: layout for an actionbar with a backbutton (too simple to be a customview) Strings # The \u0026lt;WHAT\u0026gt; part for Strings is irrelevant. So either we use \u0026lt;WHERE\u0026gt; to indicate where the string will be used:\nor all if the string is reused throughout the app:\nExamples:\narticledetail_title: title of ArticleDetailFragment feedback_explanation: feedback explanation in FeedbackFragment feedback_namehint: hint of name field in FeedbackFragment all_done: generic \u0026ldquo;done\u0026rdquo; string \u0026lt;WHERE\u0026gt; obviously is the same for all resources in the same view.\nDrawables # The \u0026lt;WHAT\u0026gt; part for Drawables is irrelevant. So either we use \u0026lt;WHERE\u0026gt; to indicate where the drawable will be used:\nor all if the drawable is reused throughout the app:\nOptionally you can add a \u0026lt;SIZE\u0026gt; argument, which can be an actual size \u0026ldquo;24dp\u0026rdquo; or a size qualifier \u0026ldquo;small\u0026rdquo;.\nExamples:\narticledetail_placeholder: placeholder in ArticleDetailFragment all_infoicon: generic info icon all_infoicon_large: large version of generic info icon all_infoicon_24dp: 24dp version of generic info icon IDs # For IDs, \u0026lt;WHAT\u0026gt; is the class name of the xml element it belongs to. Next is the screen the ID is in, followed by an optional description to distinguish similar elements in one screen.\nExamples:\ntablayout_main -\u0026gt; TabLayout in MainActivity imageview_menu_profile -\u0026gt; profile image in custom MenuView textview_articledetail_title -\u0026gt; title TextView in ArticleDetailFragment Dimensions # Apps should only define a limited set of dimensions, which are constantly reused. This makes most dimensions all by default.\nTherefore you should mostly use:\nand optionally use the screen specific variant:\nWhere \u0026lt;WHAT\u0026gt; is one of the following:\nPrefix Usage width width in dp height height in dp size if width == height margin margin in dp padding padding in dp elevation elevation in dp keyline absolute keyline measured from view edge in dp textsize size of text in sp Note that this list only contains the most used \u0026lt;WHAT\u0026gt;s. Other dimensions qualifiers like: rotation, scale,\u0026hellip; are usually only used in drawables and as such less reused.\nExamples:\nheight_toolbar: height of all toolbars keyline_listtext: listitem text is aligned at this keyline textsize_medium: medium size of all text size_menu_icon: size of icons in menu height_menu_profileimage: height of profile image in menu Known limitations # Screens need to have unique names\nTo avoid collisions in the \u0026lt;WHERE\u0026gt; argument, View (like) classes must have unique names. Therefore you cannot have a \u0026ldquo;MainActivity\u0026rdquo; and a \u0026ldquo;MainFragment\u0026rdquo;, because the \u0026ldquo;Main\u0026rdquo; prefix would no longer uniquely identify one \u0026lt;WHERE\u0026gt;.\nRefactoring not supported\nChanging class names does not change along resource names when refactoring. So if you rename \u0026ldquo;MainActivity\u0026rdquo; to \u0026ldquo;ContentActivity\u0026rdquo;, the layout \u0026ldquo;activity_main\u0026rdquo; won\u0026rsquo;t be renamed to \u0026ldquo;activity_content\u0026rdquo;. Hopefully Android Studio will one day add support for this.\nNot all resource types supported\nThe proposed scheme currently does not yet support all resource types. For some resources this is because they are less frequently used and tend to be very varied (e.g. raw and assets). For other resources this is because they are a lot harder to generalize (e.g. themes/styles/colors/animations).\nYour apps colors palette likely wants to reuse the terminology of your design philosophy. Animations can range from modest (fade) to very exotic. Themes and styles already have a naming scheme that allows you to implicitly inherit properties.\nWrap-up # That\u0026rsquo;s it! A clean simple and easy to use resource naming scheme. Don\u0026rsquo;t forget to download the cheat sheet for easy reference!\nEven though this scheme doesn\u0026rsquo;t (yet) cover all resource types, it does provide an easy to use solution for where most naming pain currently is. In a future blogpost I\u0026rsquo;ll also make a suggestion for the other ones.\nIf you\u0026rsquo;ve made it this far, you should probably follow me on Mastodon. Feel free leave a comment below!\n","date":"7 March 2016","externalUrl":null,"permalink":"/blog/2016/03/07/resourcenaming/","section":"Blogs","summary":"Do you remember the last time you had to dig into strings.xml to find the right String to use? Or that you manually had to go over all drawables to find the one you needed?","title":"A successful XML naming convention","type":"blog"},{"content":"","date":"7 March 2016","externalUrl":null,"permalink":"/tags/resources/","section":"Tags","summary":"","title":"Resources","type":"tags"},{"content":"","date":"5 February 2016","externalUrl":null,"permalink":"/tags/bitbucket/","section":"Tags","summary":"","title":"Bitbucket","type":"tags"},{"content":"As my previous blogposts already covered how to set up a private Maven repository, you might wonder \u0026ldquo;Why again a Maven blogpost?\u0026rdquo;. Well that\u0026rsquo;s a fair question and the answer is twofold:\nBackup mechanism, to ensure you never ever loose releases. Remote access outside of your local network (intranet). And Git implicitly solves both! :)\nI\u0026rsquo;ll demonstrate how to configure Bitbucket as a free private remote Maven repository and automate everything in one simple Gradle script.\nPreface # While you could use any Git repository (like GitHub), I choose Bitbucket as it offers free private repositories for small teams. Furthermore it has an API which we will need for some of the wizardry later on.\nAll source code is available on Github and can be used after some minor BitBucket configuration. You can find the Gradle script in a separate repository.\nBitbucket # Without any further a do, lets get to it and start configuring BitBucket.\nLogin to Bitbucket and create a new private repository called maven_repository.\nCheckout the repository locally, create a README.md file and commit that file to your local branch. Now push that branch to BitBucket, BUT make sure to push it to a remote branch called \u0026ldquo;releases\u0026rdquo;. (this is key, as the plugin we\u0026rsquo;ll use later on depends on this)\nTroubleshooting releases branch If you accidentally push your local branch to a remote called master, create a new branch locally called releases, push that to a remote releases and change your main branch in the BitBucket settings for that repository.\nYou can safely remove origin/master if you want.\nWagon-git # To upload Maven artifacts to a Git repository, we will use a Maven plugin called Wagon-git, which can hook into the existing Gradle DSL for Maven uploads.\nSimply add a new repository:\nrepositories { maven { url \u0026#34;https://raw.github.com/synergian/wagon-git/releases\u0026#34; } } And configure Maven like you would normally do, but with our BitBucket repository url in a particular format:\nuploadArchives { repositories.mavenDeployer { ... repository(url: \u0026#39;git:releases://git@bitbucket.org:\u0026#39; + COMPANY + \u0026#39;/\u0026#39; + REPOSITORY_NAME + \u0026#39;.git\u0026#39;) ... } } Where COMPANY is the name of your BitBucket organization and REPOSITORY_NAME is maven_repository.\nNow you can simply create a new release by running the following command:\n./gradlew assembleRelease uploadArchives And check BitBucket for the resulting artifacts.\nUnique versions only # As Git naturally allows you to override existing files, we will need to do something to prevent this from happening. Otherwise, you could have a v1.1.3 library, which is stable one day and full of bugs the next (because someone replaced it in the Maven repo). Not exactly what you want, right?\nWe will use the BitBucket API to verify if a particular release already exists:\ntask lookForArtifacts { doLast { ... def repositoryUrl = \u0026#39;https://api.bitbucket.org/1.0/repositories/\u0026#39; + COMPANY + \u0026#39;/\u0026#39; + REPOSITORY_NAME + \u0026#39;/raw/releases/\u0026#39; + artifactPath ... if (urlExists(repositoryUrl)) { throw new RuntimeException(\u0026#34;Artifact with version \u0026#34; + ARTIFACT_VERSION + \u0026#34; already exist - not executing uploadArchives\u0026#34;) } return true } } Quite simple actually: just reverse engineer the url of a particular release artifact and the see if we get a 200 response or not.\nFinally we ensure that we always run the previous task before running the Maven task:\nuploadArchives.dependsOn lookForArtifacts Running ./gradlew uploadArchives now successfully creates a release.\nConsuming artifacts # Add your Maven repository to the list of repositories in your main build.gradle file:\nallprojects { repositories { jcenter() maven { credentials { username USERNAME password PASSWORD } url \u0026#34;https://api.bitbucket.org/1.0/repositories/jeroenmols/maven_repository/raw/releases\u0026#34; } } } Note that we have to provide a username and password as we are connecting to a private repository.\nImportant\nMake sure not to put your username and password directly into the build.gradle file! That would be a major security risk. Instead have a look at this blogpost to learn how to securely provide a username and password.\nNow simply add a dependency on your library like you are used to and you\u0026rsquo;re ready.\ndependencies { ... compile \u0026#39;com.jeroenmols.awesomelibrary:awesomelibrary:1.0.0\u0026#39; } Putting it all together # To make your life a lot easier, I\u0026rsquo;ve created a Gradle script that does everything for you.\nSetting up your project is easy:\nAdd the following plugin to the top of the build.gradle file in your library folder apply from: \u0026#39;https://raw.githubusercontent.com/JeroenMols/GitAsMaven/master/publish-bitbucket.gradle\u0026#39; Create a gradle.properties file within your library folder with the following parameters: ARTIFACT_VERSION=\u0026lt;version_here\u0026gt; ARTIFACT_NAME=\u0026lt;libraryname_here\u0026gt; ARTIFACT_PACKAGE=\u0026lt;packagename_here\u0026gt; ARTIFACT_PACKAGING=aar //You could also use jar COMPANY=\u0026lt;bitbucket_team_company_here\u0026gt; //Username if not part of team REPOSITORY_NAME=\u0026lt;bitbucket_reponame_here\u0026gt; Create a gradle.properties file in the root of your project (or better in the global .gradle folder on your system) with the following parameters USERNAME=\u0026lt;username_here\u0026gt; PASSWORD=\u0026lt;password_here\u0026gt; Run the following command to upload a version to your Maven repository. ./gradlew uploadArchives Thats\u0026rsquo;s it!\nWrap-up # Configuring BitBucket or GitHub as a (private) Maven repository is quite easy and can be fully automated in a single Gradle script. Hopefully this blogpost has inspired many of you to start reusing more code.\nA basic example project with everything in this blogpost integrated is available on GitHub. Or you can also directly integrate the Gradle script into your library.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"5 February 2016","externalUrl":null,"permalink":"/blog/2016/02/05/wagongit/","section":"Blogs","summary":"As my previous blogposts already covered how to set up a private Maven repository, you might wonder \u0026ldquo;Why again a Maven blogpost?\u0026rdquo;. Well that\u0026rsquo;s a fair question and the answer is twofold:","title":"Git as a secure private Maven repository","type":"blog"},{"content":"Finally found the time to write my year in review. #insomnia\n2015 was a huge year for me! I even dare to say the biggest one of my life so far as I became a father of a lovely daughter Lene. Its really hard to over state how big of an impact that has on your life and how fantastic it is to see your own baby grow (and recognize parts of yourself in her). This obviously also explains my late year in review post. #perfectexcuse\nOn a technical level I also fared well and I\u0026rsquo;m very happy with what I\u0026rsquo;ve been able to accomplish:\nCreated an library with \u0026gt;500 stars on Github Started my own blog and website Featured blogpost in Android Weekly Spoke at my first conference Droidcon Paris Actively started using twitter and gained \u0026gt;100 followers Gained \u0026gt;1000 reputation on stackoverflow Landed a new job at Philips Hue Learned Xamarin and built a cross platform app Wrote the worlds latest year in review post Next year will be more challenging as my daughter has become a lot more effective at grabbing my attention than my laptop. However I want to increase my efforts contributing back to the community by speaking at more conferences and writing more blogposts. Finally I also want to visit Google IO, which is about time I got there, don\u0026rsquo;t you agree? ;)\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"29 January 2016","externalUrl":null,"permalink":"/blog/2016/01/29/yearinreview/","section":"Blogs","summary":"Finally found the time to write my year in review. #insomnia\n2015 was a huge year for me! I even dare to say the biggest one of my life so far as I became a father of a lovely daughter Lene.","title":"Year in review 2015","type":"blog"},{"content":"","date":"13 November 2015","externalUrl":null,"permalink":"/tags/ci/","section":"Tags","summary":"","title":"Ci","type":"tags"},{"content":"Wouldn\u0026rsquo;t you love to have your open source projects built automatically by a continuous integration server? And to have a detailed code coverage report for all your unit tests? Even when someone generated a pull request? And how about having cool badges to show off all of this?\nActually, all of this a breeze to set up, once you understand what works and what doesn\u0026rsquo;t. It is even completely free for open source projects!\nIn less than half an hour, this blogpost will add CI and code coverage to your projects, just like I did for my own library LandscapeVideoCamera. While this article focusses on Android, the material presented here can quite easily be extended to a broader scope.\nPreface # In order to keep things simple, I created a very basic project containing a Calculator class and some Android tests. This will make things easier to understand as we\u0026rsquo;ll add everything step by step to this project.\nLater on I will present a more elaborate (and usefull) example, namely my own open source library LandscapeVideoCamera. Some time ago, I test driven refactored this project completely resulting in respectable code coverage statistics.\nTravis # About # Travis is a feature rich online CI service which integrates nicely with a lot of existing services. One major advantage over Jenkins is that you can put the entire CI configuration file under version control. It is completely free for open source projects, although private repositories are also supported on a subscription basis.\nBasic configuration # In order to get started, go to travis-ci.org, login with your GitHub account and authorize Travis to access your repositories.\nNext, create a new file .travis.yml into the root of your project (note that this file will be hidden on Mac OSX/Linux systems). Open the file and specify the language of your project, in our case Android:\nlanguage: android Now Travis needs to know all dependencies in order to build the project. As such specify the build tools version and compile Android SDK version (note that this must match the compileSdkVersion of your build.gradle file!). While there is an option to use the latest build tools version, I recommend to declare an explicit version as this makes your builds more reproducible. Next specify all of the Android SDK manager dependencies your project needs so Travis can install them before building the project.\nandroid: components: - build-tools-22.0.1 - android-23 - extra-android-m2repository Note that our sample only depends on the AppCompat and design support library, hence there is only one extra defined extra-android-m2repository. In case your project uses other dependencies from the Android SDK, you can easily select them from the entire dependency list and add an extra item.\nExtra: listing Android SDK dependencies\nTo generate the above mentioned list of Android SDK components, simply run the following command on your local machine:\nandroid list sdk --no-ui --all --extended After, specify the exact Gradle command to run, in our case assembleDebug:\nscript: - ./gradlew assembleDebug Now that we have configured everything in the travis.yml file, we need to enable the project, so Travis will start listening to code changes. This can be done by going to your profile on Travis and flipping the appropriate slider.\nThis will result in the project being shown on the left hand side of your dashboard, while indicating that there are no builds.\nBuilds are automatically triggered whenever you push code to your GitHub repository or someone else creates a pull request. Therefore push some changes to GitHub and watch Travis pick them up automatically and start building your project.\nCongrats! You now have a fully working Continuous Integration server for your open source project.\nRunning Android unit tests # While running normal unit tests is straight forward, Android tests are a different story because they require an Android emulator to run on. And because Travis support for Android is still in beta, there are a couple of limitations to consider:\nOnly armeabi-v7a emulators are supported. The Android M emulator is not yet supported. Extra limitations of Travis Android support\nYou can skip this if you want, just some extra context\nFirst of all, Travis does not yet support HAXM to speed up intel emulators, so there is no speed up while using an x86 emulator. Even more, the latest x86_64 Android M emulator requires hardware acceleration, so that one simply cannot be used on Travis! For more information see issue 1419 and 1395 or check out this failing build.\nSecondly, Travis does not yet support the latest Android M emulator, causing the built-in android-wait-for-emulator script to time out while the emulator is booting. Therefore I recommend to use the android-22 emulator instead. For more information see this failing build.\nSo you\u0026rsquo;ll have to accept that builds will be slow (starting emulator + running test) and that you cannot use an Android M emulator. But if these are acceptable, read on and I\u0026rsquo;ll explain how to set up everything for running tests.\nFirst of all, define the Android version and processor architecture of the emulator by adding a new environment at the top of the travis.yml file:\nenv: matrix: - ANDROID_TARGET=android-22 ANDROID_ABI=armeabi-v7a Then, ensure that all dependencies for the Android emulator are installed, by adding both the platform version and emulator image to the components section. Note that it is important to add both, because the Android emulator will only install if the corresponding Android platform is installed (see this failing build).\nandroid: components: ... - android-22 - sys-img-armeabi-v7a-android-22 Now we need to create a new Android emulator and start it before our build. As starting takes a really long time, Travis offers a built-in android-wait-for-emulator script to facilitate this. Finally we need to unlock the emulator once started by sending a key event.\nbefore_script: - echo no | android create avd --force -n test -t $ANDROID_TARGET --abi $ANDROID_ABI - emulator -avd test -no-skin -no-audio -no-window \u0026amp; - android-wait-for-emulator - adb shell input keyevent 82 \u0026amp; After all of this configuration, all we need to do is change the Gradle command to run all of the tests and trigger a new build by pushing all these changes.\nscript: - ./gradlew connectedAndroidTest Taking things further # As mentioned in the introduction, Travis is a really feature rich CI service. Therefore this section provides some tips to take things even further.\nBuild notifications: Travis supports sending notifications via Slack, HipChat, email,\u0026hellip; whenever a built fails/succeeds.\nFor more information, have a look at the Travis documentation. notifications: email: - your.email@gmail.com Build status badge: Click the build badge on your Travis homepage to generate png/markdown/\u0026hellip; build badges.\nBranch information: Print which branch or pull request is being built.\nscript: - echo \u0026#34;Travis branch is $TRAVIS_BRANCH\u0026#34; - echo \u0026#34;Travis branch is in pull request $TRAVIS_PULL+REQUEST\u0026#34; More options: Have a look at the Travis documentation. Coveralls # About # Coveralls is a visually attractive online code coverage tool which provides detailed statistics such as line coverage and repository trends. Furthermore it allows you to show of your code coverage and encourages you to increase it. Like Travis, it is free for open source projects, but a subscription service is available for private repositories.\nEnabling Android code coverage # First of all, your Android project needs to be configured to generate code coverage reports. As such, ensure that you are using at least version 0.4 of the Android testing support library (there was an issue in version 0.3).\nThen add the flag testCoverageEnabled to the debug buildTypes in your main module\u0026rsquo;s build.gradle file, causing a code coverage report to be generated in the build/reports/coverage/ folder.\nandroid { ... buildTypes { debug { testCoverageEnabled true } } } At this point, you should be able to run gradle connectedAndroidTest and view an html and xml report in the above mentioned directory.\nBasic configuration # In order to get started, go to coveralls.io, login with your GitHub account and authorize Coveralls to access your repositories.\nNext, we\u0026rsquo;ll need to configure your build.gradle files to upload the coverage reports to Coveralls after each successful CI build. Therefore add a new classpath dependency to the root projects build.gradle file.\nbuildscript { ... dependencies { ... classpath \u0026#39;org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.4.0\u0026#39; } } Then we can apply the coveralls plugin, point it to the coverage reports directory and ensure it only runs on CI builds by adding the following to your main module\u0026rsquo;s build.gradle file:\napply plugin: \u0026#39;com.github.kt3k.coveralls\u0026#39; coveralls { jacocoReportPath = \u0026#34;${buildDir}/reports/coverage/debug/report.xml\u0026#34; } tasks.coveralls { dependsOn \u0026#39;connectedAndroidTest\u0026#39; onlyIf { System.env.\u0026#39;CI\u0026#39; } } Note that we also added a dependency on the connectedAndroidTest task as that is the one that will actually generate the code coverage report.\nLet\u0026rsquo;s now change the build task in the travis.yml so it runs the coveralls task after every build. While not strictly necessary to still define the connectedAndroidTest task, I prefer to do so as it makes it more explicit what Gradle will exactly be building.\nscript: ... - ./gradlew connectedAndroidTest coveralls Next we need to activate our GitHub repository in coveralls, so it picks up the output from the Gradle plugin. This can easily be done by clicking add repos on coveralls.io and flipping the switch on your repository.\nThis will result in the project being added to your dashboard without any builds.\nSimply trigger a Travis build by pushing some changes to start seeing code coverage results online.\nFinally you can easily add a badge to your repository by clicking the Badge urls button from the green banner in the detail view.\nCongratulations you know have attractive code coverage reports for your repository!\nWrap-up # Adding Travis CI and Coveralls code coverage to your project is fairly straightforward once you know what works and especially what doesn\u0026rsquo;t work. Hopefully this blogpost was able to remove a lot of those frustrating barriers of entry.\nA basic example project with everything in this blogpost integrated is available on GitHub. But in case you\u0026rsquo;re interested in a real life example, have a look at my Android library LandscapeVideoCamera, which actually has decent code coverage statistics.\nAs always you can reach me on Mastodon, or leave a comment below!\n","date":"13 November 2015","externalUrl":null,"permalink":"/blog/2015/11/13/traviscoveralls/","section":"Blogs","summary":"Wouldn\u0026rsquo;t you love to have your open source projects built automatically by a continuous integration server? And to have a detailed code coverage report for all your unit tests?","title":"Level up GitHub builds with CI and code coverage","type":"blog"},{"content":"","date":"13 August 2015","externalUrl":null,"permalink":"/tags/artifactory/","section":"Tags","summary":"","title":"Artifactory","type":"tags"},{"content":"My previous blog post described how to set up your own private Maven repository with Artifactory in 30 minutes. This second and final part will make things more interesting and take your setup to the next level.\nYou will learn how to:\nhandle library projects with dependencies securely provide username and password work with snapshot and release builds configure custom repositories manage user access All source code is available on Github as usual.\nNote that the material presented here can quite easily be extended to be applicable beyond Android.\nLibrary projects with dependencies # Imagine if your Android library project itself has dependencies. Then the application using the library wouldn\u0026rsquo;t be able to run unless it provides all dependencies the library requires.\nTo better understand this, consider the new AwesomeAdvancedLibrary which makes use of Guava to awesomize a String. The application using this library should be agnostic of this dependency. Hence we do not want to define two dependencies:\ndependencies { compile \u0026#39;com.jeroenmols.awesomeadvancedlibrary:awesomeadvancedlibrary:1.0.0\u0026#39; compile \u0026#39;com.google.guava:guava:18.0\u0026#39; } Instead one compile dependency should suffice to use the library.\nImportant note on including dependencies\nYou can skip this if you want, just some extra context\nIncluding dependencies in your library is not always a good idea, because this can lead to a dependency conflict while integrating. I only choose Guava to keep things simple, but it is actually a very bad example as it is a utility library. This means it\u0026rsquo;s quite likely that the app also needs it.\nA better example would be a universal analytics library offering a universal API to track analytics and redirecting all calls internally to one or more analytics providers. Here packaging dependencies makes sense, because the app never needs to talk to the dependency directly. It also hides implementation details, so the app doesn\u0026rsquo;t need to be modified when switching to a new provider.\nImagine if we would simply resort to the buildscript we had in my previous blogpost. At compile time the Guava dependency will not be included, because the would make the library unnecessarily large. Instead, the compiler will tell the library: \u0026ldquo;don\u0026rsquo;t worry about this dependency, the app will provide it for you.\u0026rdquo;\nThe app on the other hand wouldn\u0026rsquo;t have a clue which dependencies the library actually needs (how would it?) and hence the app will compile just fine. However, after starting the app and trying to access the library, the app would crash at runtime:\n08-09 20:49:46.096 28892-28892/? E/AndroidRuntime﹕ FATAL EXCEPTION: main Process: com.jeroenmols.awesomeadvancedapplication, PID: 28892 java.lang.NoClassDefFoundError: Failed resolution of: Lcom/google/common/base/CharMatcher; at com.jeroenmols.awesomeadvancedlibrary.AwesomeConvertor.toAwesome(AwesomeConvertor.java:11) To solve this, we need to ensure that the library pom.xml file contains the right dependencies by manually adding the pom.withXml{} element to the publishing task:\npublishing { publications { aar(MavenPublication) { groupId packageName version = libraryVersion artifactId project.getName() artifact(\u0026#34;$buildDir/outputs/aar/${project.getName()}-release.aar\u0026#34;) pom.withXml { def dependencies = asNode().appendNode(\u0026#39;dependencies\u0026#39;) configurations.getByName(\u0026#34;_releaseCompile\u0026#34;).getResolvedConfiguration().getFirstLevelModuleDependencies().each { def dependency = dependencies.appendNode(\u0026#39;dependency\u0026#39;) dependency.appendNode(\u0026#39;groupId\u0026#39;, it.moduleGroup) dependency.appendNode(\u0026#39;artifactId\u0026#39;, it.moduleName) dependency.appendNode(\u0026#39;version\u0026#39;, it.moduleVersion) } } } } } Note that while you can similarly add other repositories in this way to the pom.xml, Gradle itself won\u0026rsquo;t look for repositories in that file. Therefore if you use libraries from 3rd party repositories, you still need to add those repositories to the build.gradle of your app.\nSecurely provide username and password # Obviously we do not want to store a plain text username and password in any file that we check in to our version control system. So to make sure we hide those, create a gradle.properties file in the root of your project and add the following content:\nartifactory_username=admin artifactory_password=password Then in your build.gradle file, refer to the properties like this:\nusername = artifactory_username password = artifactory_password We have now obfuscated the password, so it is no longer in the build.gradle file, but people can still find it in the gradle.properties file under version control. To prevent this, you must do one of the following:\nDon\u0026rsquo;t add gradle.properties to your version control system. (add it to your .gitignore file instead) Move the gradle.properties to the base ~/.gradle folder on your hard drive. I personally recommend this approach as you can never accidentally check in your username and password. Working with Snapshot and Release builds # While the Artifactory Gradle plugin doesn\u0026rsquo;t have support for snapshot/release builds out of the box, it is easy to add this functionality by relying on the artifact version:\nFor release builds: use symantic versioning e.g. 1.0.0 For Snapshot builds: use symantic versioning with -SNAPSHOT suffix e.g. 1.0.0-SNAPSHOT Now you can direct each one to a different Artifactory repository by changing the repository key as follows:\nrepoKey = libraryVersion.endsWith(\u0026#39;SNAPSHOT\u0026#39;) ? \u0026#39;libs-snapshot-local\u0026#39; : \u0026#39;libs-release-local\u0026#39; On the application side you need to add two different Maven urls so you can refer to artifacts in both repositories.\nallprojects { repositories { maven { url \u0026#34;http://localhost:8081/artifactory/libs-release-local\u0026#34; } maven { url \u0026#34;http://localhost:8081/artifactory/libs-snapshot-local\u0026#34; } } } Referencing artifacts is exactly the same as before, just don\u0026rsquo;t forget to add the -SNAPSHOT suffix for snapshot artifacts.\nAlternatively we can also create a virtual repository in Artifactory which wraps around both repositories. This way the app only requires one URL, but does create a dependency on the existing Artifactory setup.\nLogin to Artifactory and go to admin \u0026gt; repositories \u0026gt; virtual Create a new virtual maven repository which contains both libs-release-local and libs-snapshot-local In the top level build.gradle of your application, replace the two previous URLS by the following: allprojects { repositories { maven { url \u0026#34;http://localhost:8081/artifactory/libs-local\u0026#34; } } } User access management # Currently everyone can both read and write to all your repositories. This is not a good idea, especially if your server is also connected to the internet. Therefore we are going to set up two different users: one to deploy artifacts and one to consume artifacts.\nIn order to do so, go to artifactory and login as admin. Now navigate to admin \u0026gt; security \u0026gt; general and make the following changes:\nset Allow Anonymous Access to false -\u0026gt; ensures only known Artifactory users can consume artifacts set Password Encryption Policy to REQUIRED -\u0026gt; ensures we don\u0026rsquo;t have to hardcode a plain text password in our build.gradle. press the encrypt button in the Password Encyption section -\u0026gt; encrypts all passwords If the app now tries to consume an artifact, it will get a 401 error: unauthorized. You can verify this yourself by clearing the gradle cache (to force a dependency download):\ngradle clean --refresh-dependencies Next, go to the Users pane and add two new user: consumer and deployer. Make sure not to add them to any group.\nNote that you probably also want to change your admin password at this stage. ;)\nNow go to the Permissions pane and add a new Consume Libraries permission. Set the Selected repositories to include the snapshot and release repository, and in the Users tab add the consumer user with read permissions.\nAdd a second permission: Deploy Libraries with the snapshot and release repository included. Here give the deployer user Deploy/Cache permission but not Delete/Overwrite as you never want to override an existing artifact!\nAll we need to do now is modify the Library and Application to make use of these new users. This is easy for the Library as you can simply replace the admin user with the deploy user in the gradle.properties file.\nFor the Application we will need to provide credentials to access the Maven repository. Here we will hard code the username and password in the top level build.gradle file because team members should be able to checkout and build the code without extra configuration.\nTherefore we will take some extra security precautions:\nUse a user with read access to only a small subset of our repositories: deploy. Check the code into a private repository, so the hardcoded password is protected by repository password. Use the encrypted version of the password instead of the plain text version: Login to artifactory as the consumer user\nNavigate to the user settings in the top right corner\nUnlock your profile with your password\nCopy the API key\nNow add the user authentication to the top level build.gradle file:\nallprojects { repositories { jcenter() // NOTE: configure your virtual repository and user in artifactory to make this work maven { url \u0026#34;http://localhost:8081/artifactory/libs-local\u0026#34; credentials { username \u0026#39;consumer\u0026#39; password \u0026#39;APA52uxnRkmxeRXmJqd7haMpwgg\u0026#39; } } } } And we are all set with authenticated access to our repositories.\nWrap-up # That\u0026rsquo;s a wrap to my two part blogpost about Artifactory! We made our previous repository a lot more secure, added support for dependencies and can now differentiate between release and snapshot artifacts.\nNo more excuses not to write reusable code!\nFeel free to leave a comment and don\u0026rsquo;t forget to check the full source code on Github.\n","date":"13 August 2015","externalUrl":null,"permalink":"/blog/2015/08/13/artifactory2/","section":"Blogs","summary":"My previous blog post described how to set up your own private Maven repository with Artifactory in 30 minutes. This second and final part will make things more interesting and take your setup to the next level.","title":"Getting the most out of Artifactory","type":"blog"},{"content":"Setting up your own Maven repository and uploading artifacts to it is quite a daunting task. As I went through this experience myself recently, I want to help others in setting up their own Maven repository via Artifactory and automate uploading artifacts using Gradle.\nIn less than 30 minutes you will have a fully operational private Maven repository and have configured your Gradle buildscripts to upload your Android library artifacts.\nNote that the material presented here can quite easily be extended to be applicable in a broader scope beyond Android.\nSetting up a Repository Manager # First of all we need to make sure we have an actual Maven repository to upload our artifacts to. According to Maven you should use a repository manager to do that:\nBest Practice - Using a Repository Manager\nA repository manager is a dedicated server application designed to manage repositories of binary components. The usage of a repository manager is considered an essential best practice for any significant usage of Maven.\nWhy Artifactory? # While there are some options available to choose from, I personally selected Artifactory because:\nClear and attractive UI Super fast configuration Gradle plugin User access control Free and open source For more information have a look at the alternatives, checkout this feature comparison matrix or review all of the Artifactory features.\nVerify you have Java SDK 8 # Before you get started, make sure that you have Java SDK 8 installed, or otherwise Artifactory won\u0026rsquo;t start. You can easily verify your Java version with java -version:\n$ java -version java version \u0026#34;1.8.0_51\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_51-b16) Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode) If it doesn\u0026rsquo;t output at least version 1.8.x, you should download and install a new Java SDK before you continue.\nNote that the error you get if you don\u0026rsquo;t have Java 8 looks a bit cryptic:\nAug 05, 2015 9:29:31 AM org.apache.catalina.core.StandardContext startInternal SEVERE: One or more listeners failed to start. Full details will be found in the appropriate container log file Install Artifactory # Thankfully this is incredibly easy to do. Just download the latest version of Artifactory, unpack the archive and run the artifactory executable for your platform.\nYou can easily verify your installation and start experimenting with its features by navigating to http://localhost:8081/artifactory/. For now, don\u0026rsquo;t worry about all of the settings, we will configure what we need later on.\nConfiguring Gradle to upload Android artifacts # Let\u0026rsquo;s upload a very simple archive by configuring a new Gradle task for our Android library project.\nIn your top level build.gradle file, add a reference to the repository of the Artifactory Gradle plugin:\nbuildscript { dependencies { classpath \u0026#34;org.jfrog.buildinfo:build-info-extractor-gradle:3.1.1\u0026#34; } } Next in your library we will need to apply two new plugins: one to prepare the Maven artifacts maven-publish and one to upload the archives to Artifactory com.jfrog.artifactory:\napply plugin: \u0026#39;com.jfrog.artifactory\u0026#39; apply plugin: \u0026#39;maven-publish\u0026#39; Every Maven artifact is identified by three different parameters:\nartifactId: the name of your library groupId: usually the package name of your library version: identifies different releases of the same artifact For the last two, we will explicitly define a variable in the build.gradle file.\ndef packageName = \u0026#39;com.jeroenmols.awesomelibrary\u0026#39; def libraryVersion = \u0026#39;1.0.0\u0026#39; The artifactId however needs to match the output filename of the assembleRelease task. Therefore we either have to rename the library module or explicitly specify the output filename. I personally prefer the first approach, which allows to get artifactId in the following way:\nproject.getName() // the ArtifactId Now we need to configure the maven-publish plugin so that it knows which artifacts to publish to Artifactory. For our purpose we will refer to the ***-release.aar file, generated by the assembleRelease task. Note that we can predict the name by taking the name of the Library project:\npublishing { publications { aar(MavenPublication) { groupId packageName version = libraryVersion artifactId project.getName() // Tell maven to prepare the generated \u0026#34;*.aar\u0026#34; file for publishing artifact(\u0026#34;$buildDir/outputs/aar/${project.getName()}-release.aar\u0026#34;) } } } Finally we need to configure the com.jfrog.artifactory plugin so it knows which repository to publish the artifacts to. For simplicity we will upload the artifact to the locally running Artifactory instance (http://localhost:8081/artifactory) and place it in the default libs-release-local repository. Note that the username admin and password password are hardcoded in this example, but we will provide a better solution for that later.\nartifactory { contextUrl = \u0026#39;http://localhost:8081/artifactory\u0026#39; publish { repository { // The Artifactory repository key to publish to repoKey = \u0026#39;libs-release-local\u0026#39; username = \u0026#34;admin\u0026#34; password = \u0026#34;password\u0026#34; } defaults { // Tell the Artifactory Plugin which artifacts should be published to Artifactory. publications(\u0026#39;aar\u0026#39;) publishArtifacts = true // Properties to be attached to the published artifacts. properties = [\u0026#39;qa.level\u0026#39;: \u0026#39;basic\u0026#39;, \u0026#39;dev.team\u0026#39;: \u0026#39;core\u0026#39;] // Publish generated POM files to Artifactory (true by default) publishPom = true } } } Deploying artifacts # Now that our Gradle buildscripts are properly configured we can easily publish artifacts to Artifactory by running the following command:\ngradle assembleRelease artifactoryPublish Notice how we first invoke assembleRelease before we invoke the actual artifactoryPublish task, because of the way we defined the artifacts to publish in the previous section.\nYou can very easily verify that the upload was successful by navigating to localhost:8081 and signing in with the default admin credentials.\nUsing the artifacts # To make use of the published artifacts in another project we have to add our Artifactory repository to the list of Maven repositories in your top level build.gradle file:\nallprojects { repositories { maven { url \u0026#34;http://localhost:8081/artifactory/libs-release-local\u0026#34; } } } After we can simply add the artifact as a dependency in the build.gradle file of our main project:\ndependencies { compile \u0026#39;com.jeroenmols.awesomelibrary:1.0.0\u0026#39; } Wrap-up # Congratulations! You now have a fully working Maven repository manager with a Gradle script to generate and upload your artifacts.\nIn the next [blog post]({{ site.baseurl }}{% link blog/_posts/2015-08-13-artifactory2.md %}) I will zoom in on more advanced topics like:\nLibrary projects with dependencies Configuring your own repositories User access management and rights Removing hardcoded username and password from build.gradle I have also uploaded a complete example on GitHub for your reference.\n","date":"6 August 2015","externalUrl":null,"permalink":"/blog/2015/08/06/artifactory/","section":"Blogs","summary":"Setting up your own Maven repository and uploading artifacts to it is quite a daunting task. As I went through this experience myself recently, I want to help others in setting up their own Maven repository via Artifactory and automate uploading artifacts using Gradle.","title":"A private Maven repository for Android in 30 min","type":"blog"},{"content":"For quite some months, I\u0026rsquo;ve been planning to create a website and start blogging about the things I\u0026rsquo;m passionate about. Last week, I finally decided to setup a portfolio and blog using GitHub pages and Jekyll.\nSince I\u0026rsquo;m an Android and not a web developer, the first blogging subject wasn\u0026rsquo;t hard to find: challenges I came across in setting up this website and blog.\nDisclaimer: Eventually I had to use a workaround - that\u0026rsquo;s why I don\u0026rsquo;t build websites professionally - but I strongly believe in a Just do It mentality and then learn/improve as you go.\nWhy Jekyll # Keeping it simple, I only had few requirements for my blog:\nResponsive website Easy to setup and maintain No lock-in: able to migrate to other platforms Support for pagination and comments First thing I learned was the difference between a static (e.g. Jekyll) and dynamic website (e.g. Wordpress) via a great presentation by @plusjade.\nThe main advantage of static websites is their loading speed because all pages are generated before they are served. Installing the generator on your local machine is simple, making it easy to test your site before deploying online. Posts are written in Markdown, so no HTML clutter nor extra tools needed. Just a text generator and Git to conveniently version all changes.\nProtip: One of my colleagues @inferis even gets spelling corrections via Pull request!\nAs GitHub pages natively supports Jekyll, I didn\u0026rsquo;t really spent much time on choosing which static site generator to use.\nSetting up # Installing Jekyll was really a breeze, I just had to run gem install Jekyll and then I could build my website using jekyll build or test it locally using jekyll serve.\nNote: both commands will generate your website in the _site folder, which you shouldn\u0026rsquo;t add to version control!\nInstead of making a new Jekyll site, I decided to fork two existing themes:\nHyde: a clean two-column theme for my Blog Freelancer: to have a cool portfolio Both themes offer quite some predefined customization options via the _config.yml file, but for advanced theming you can also directly edit the CSS files.\nMerging two Jekyll themes # Where I originally only wanted to have a blog, the Freelancer theme was just too cool to ignore. Consequently merging two themes was one of the first things I had to do.\nIt seemed most convenient to have my portfolio under my main url and to include my blog under a subfolder (i.e. jeroenmols.github.io/blog).\nTo do this I merged the blog theme into the portfolio (main) theme:\nAdd a subfolder blog/ with the index.html of my blog.\nMove all my portfolio posts and blog posts into separate folders:\nall portfolio posts went into portfolio/_posts all blog posts went into blog/_posts This allows to easily loop through all portfolio or blog posts separately:\n{{ \u0026quot;{% for post in site.categories.portfolio \u0026quot; }}%} {{ \u0026quot;{% for post in site.categories.blog \u0026quot; }}%} Move all files in _layouts and _includes from my blog into the corresponding folders of my portfolio theme.\nOptionally you can move files into subfolders to keep things clean (_includes/blog), as long as you also update all references to these files. (in _layouts/blog.html I now refer to my includes as blog/\u0026lt;original name\u0026gt;) Same holds true if you have naming conflicts (for instance two layouts with the same name), you can just rename one and update all references in all files using it. Move all other folders and files into the root of the main theme\nMerge the configurations from both _config.yml files\nAgain you can rename conflicting configurations (or merge duplicate ones) if you update all references. Fix all references to not found images/css/\u0026hellip; files in the blog theme. This is necessary because the original theme was assuming to run in the root directory, and now we moved it to a subdirectory blog/.\nI found that the best way to do this is to run jekyll build and have a look at the generated output in the _site directory. From this you can learn what\u0026rsquo;s wrong and fix it. After this I could run Jekyll serve and everything worked flawlessly!\n\u0026hellip;\nWait\u0026hellip;\n\u0026hellip;\nWhy are my portfolio posts also showing up in my blog?\n\u0026hellip;\nDamn you Jekyll!\nTurns out Jekyll does not support paginating categories and hence it will lump all posts it finds together, in my case both portfolio (unwanted) and blog (wanted). Even more, there is no plugin to add this functionality either! Pretty weird, and a huge limitation if you ask me.\nSo I did what every self-respecting programmer would do: pray to the Stackoverflow and GitHub gods. And my prayers where answered by a code snippet of benxtan, which I found in an issue tracker of a very old Jekyll pagination plugin. To enable this plugin, simply create a _plugins folder and copy the code snippet into a category_pagination.rb file.\nNote: the former plugin was no longer working, because it was referring to classes that were renamed/moved classes in newer Jekyll versions.\nGitHub and Jekyll plugins # My new shiny portfolio and blog were working locally, but when I pushed it to GitHub, the pagination again included both blog and portfolio posts. Turns out that GitHub doesn\u0026rsquo;t allow you to run custom Jekyll plugins except for a few that they have whitelisted.\nPlugins on GitHub Pages\nGitHub Pages is powered by Jekyll. However, all Pages sites are generated using the \u0026ndash;safe option to disable custom plugins for security reasons. Unfortunately, this means your plugins won’t work if you’re deploying to GitHub Pages.\nAt this point, I am/was completely stuck, because even if Jekyll would add support for category pagination, I would still need to wait for GitHub to update their Jekyll version.\nOnly option remaining was to directly push the generated _site directory into my repository and to disable the Jekyll generator on GitHub pages.\nNote that this is a really suboptimal solution, because this effectively means pushing a high amount of auto-generated files to your repo, frequently. So if anyone has a better suggestion to solve the pagination issue, please let me know!\nTo make this work, there are a couple of things you need to do:\nDisable Jekyll on GitHub pages by pushing an empty file with name .nojekyll to the root of your repo\nMove all auto generated content from the _site folder into the root of your repository, so that its index.html is displayed when someone browses to your main page.\nThis actually by itself imposes a new problem, namely where to put your Jekyll source code? I solved this by:\nmove all source files to a subfolder jekyll-source in my main repository\ngenerating all static pages into jekyll-source/_site using jekyll build\nremoving all files and folders from my root directory, except for the jekyll-source directory\ncopying the entire content of jekyll-source/_site into my root folder\nI know this is not a great solution, but it gets the job done, and I was able to automate all of this in a release script that you can run by calling .release from the jekyll-source folder.\nNote: I also considered two other options:\nUse a CNAME file to redirect my main url into a subfolder. This does not work, as the CNAME file can only be used for top-level domains. Use a placeholder index.html which redirect the main url into a subfolder. I didn\u0026rsquo;t use any of those mechanisms as that would unnecessarily complicate my website url.\nProtips # If you really want to make your site look spectacular:\nSite icon: add the following to the head of your index.html page: \u0026lt;link rel=\u0026quot;favicon-144-precomposed\u0026quot; sizes=\u0026quot;144x144\u0026quot; href=\u0026quot;\u0026lt;link_to_your_icon\u0026gt;\u0026quot;\u0026gt;\nSite toolbar/status bar color on Android: add the following to the head of your index.html page: \u0026lt;meta name=\u0026quot;theme-color\u0026quot; content=\u0026quot;\u0026lt;your_color_hex\u0026gt;\u0026quot;\u0026gt;\nConclusion # I\u0026rsquo;m glad that I finally got my portfolio and blog up and running. My current solution might not be the best one in the world, but it is automated, maintainable and I can easily add blog posts in the future. Don\u0026rsquo;t hesitate to look at my GitHub repo for the full source code. Hopefully the code and my post can help others to setup the same in the future.\nWould I use Jekyll again if I would start over? Probably yes.\nThe only real limitation I ran into was due to the paginator combining the posts from both my portfolio and blog. This caused me to disable Jekyll completely and push the generated site directly to GitHub pages. While this really sucked, using another static site generator would also have forced me to do this (because GitHub only supports Jekyll). Furthermore combining two themes is already quite advanced, and if you stick to just one theme Jekyll is actually very convenient to use.\n","date":"25 April 2015","externalUrl":null,"permalink":"/blog/2015/04/25/blog-creation/","section":"Blogs","summary":"For quite some months, I\u0026rsquo;ve been planning to create a website and start blogging about the things I\u0026rsquo;m passionate about. Last week, I finally decided to setup a portfolio and blog using GitHub pages and Jekyll.","title":"How I created my blog","type":"blog"},{"content":"\u003c!DOCTYPE html\u003e Redirecting to github.com/jeroenmols / github.com/jeroenmols ","externalUrl":null,"permalink":"/github/","section":"","summary":"\u003c!DOCTYPE html\u003e Redirecting to github.com/jeroenmols / github.com/jeroenmols ","title":"","type":"page"},{"content":"google-site-verification: google04708ab412557d23.html","externalUrl":null,"permalink":"/google04708ab412557d23/","section":"","summary":"google-site-verification: google04708ab412557d23.","title":"","type":"page"},{"content":"Jeroen Mols is a Google Developer Expert (GDE) in Android, the former lead Android developer at Philips Hue and an internationally recognized speaker. With a passion for complex systems and highly technical apps, Jeroen has helped realize four connected products and over 15 Android applications.\nExperienced in leading large teams, he can step beyond his developer role and provide technical leadership to others. He continuously challenges the status quo and mentors people surrounding him to grow. Shipping apps to millions of users, Jeroen has a thorough understanding of both the Android framework and how maintainable software should be crafted.\nNote that I\u0026rsquo;m a remote first developer and hence only pass by your office occasionally.\nWould you like to work togehter? Let\u0026rsquo;s talk!\nSend ","externalUrl":null,"permalink":"/about/","section":"About","summary":"Jeroen Mols is a Google Developer Expert (GDE) in Android, the former lead Android developer at Philips Hue and an internationally recognized speaker. With a passion for complex systems and highly technical apps, Jeroen has helped realize four connected products and over 15 Android applications.","title":"About","type":"about"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"I\u0026rsquo;m always eager to share my technical knowledge with fellow developers. Don\u0026rsquo;t hesitate to contact me on Twitter if you would like me to speak at your event!\nUpcoming talks # To be announced 2023 # Android Makers by Droidcon Paris - Staying passionate about your craft 2022 # Android Makers Paris - The definitive guide to Android library development 2021 # Droidcon Berlin - The definitive guide to Android library development 2020 # Mumbai App Developers Meetup (GDG) - The big rewrite GDG Jeddah - Getting the most out of Android KTX Dutch Android User Group - Getting the most out of Android KTX Android Makers Paris - Getting the most out of Android KTX Async Android - Powerful layout previews 2019 # Full Stack meetup Antwerp - Journey to painless releases: Continuous delivery for Philips Hue Android GDG Brussels - Successfully modularising your app Google Developer Experts Summit - Inclusive communication Mobiconf Krakow - Successfully modularising your app Droidcon Berlin - Write awesome unit tests mDevCamp Prague - Journey to painless releases: Continuous delivery for Philips Hue Android Android makers - Journey to painless releases: Continuous delivery for Philips Hue Android Fragmented Podcast - Should I Rewrite My App? 2018 # Devoxx - Write awesome unit tests Droidcon UK - The big rewrite Droidcon Italy - The big rewrite Android Makers Paris - The big rewrite Philips Research - Deep into the IoT trenches: how to build a connected product 2017 # Devoxx - Deep into the IoT trenches: how to build a connected product Droidcon UK - Deep into the IoT trenches: how to build a connected product Dutch Android User Group - Migrating to Android Studio 3.0 iCapps, June 2nd - Deep into the IoT trenches: how to build a connected product GDG Brussels, June 7th - Testing made sweet with a Mockito Mobel, June 14th - Lessons learned building connected IoT products Devoxx UK - Deep into the IoT trenches: how to build a connected product Dutch Android User Group - Testing made sweet with a Mockito Android Makers Paris - The ART of organizing resources 2016 # Devoxx - Testing made sweet with a Mockito Android dialogs - Connected products Big Android Barbeque Europe - Testing made sweet with a Mockito Big Android Barbeque Europe - Maven library distribution Droidcon Berlin - Testing made sweet with a Mockito Droidcon Italy - Distribute your libraries via Maven, even privately GDG Brussels - Automated library distribution to Maven 2015 # Droidcon Paris - Distributing to a public or private Maven repository ","externalUrl":null,"permalink":"/talks/","section":"Talks","summary":"I\u0026rsquo;m always eager to share my technical knowledge with fellow developers. Don\u0026rsquo;t hesitate to contact me on Twitter if you would like me to speak at your event!","title":"Talks","type":"talks"}]